<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>szza</title>
  
  <subtitle>look code art</subtitle>
  <link href="https://szza.github.io/atom.xml" rel="self"/>
  
  <link href="https://szza.github.io/"/>
  <updated>2023-09-26T06:34:57.838Z</updated>
  <id>https://szza.github.io/</id>
  
  <author>
    <name>fibonaccii</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>HashJoin: HashBuildOperator、HashProbeOperator 流程剖析</title>
    <link href="https://szza.github.io/2023/08/16/Pipeline/HashJoin/"/>
    <id>https://szza.github.io/2023/08/16/Pipeline/HashJoin/</id>
    <published>2023-08-16T02:00:01.000Z</published>
    <updated>2023-09-26T06:34:57.838Z</updated>
    
    <content type="html"><![CDATA[<p>HashJOIN 经过优化器后，生成的执行计划一般是右表是小表，用于 Build HashTable，左表是大表，用于 Probe HashTable。而左表必须等右表构建完 HashTable 才能执行 Probe 过程，因此 Build 和 Probe 之间存在一个依赖关系。</p><p>因此，在将 HashJoinNode 拆分为 Pipeline 时，会生成两条 Pipelines：</p><ul><li><p>Build Pipeline</p><p>  Build Pipeline 从表 t1 中读取所有符合条件的数据，并构建 HashTable。构建完成，则使 Probe Pipeline 解除阻塞，则从 blocked_driver_poller 中移除并添加到 ready_driver_queue 中，让 DriverExecutor 去执行 Probe。</p></li><li><p>Probe Pipeline  </p><p>  Probe Pipeline 则从表 t2 中不断获取数据，然后执行 probe。由于 Build 过程完成，HashTable 就可以确定了，那么 Probe 的过程是可以逐 chunk 执行，即从表 t2 每次读取一个 chunk 就可以执行一次 probe，因此 PipelineJob 是不会阻塞的。</p></li></ul><h2 id="HashJoinBuildOperator"><a href="#HashJoinBuildOperator" class="headerlink" title="HashJoinBuildOperator"></a>HashJoinBuildOperator</h2><h3 id="HashJoiner"><a href="#HashJoiner" class="headerlink" title="HashJoiner"></a>HashJoiner</h3><p>HashJOIN 是通过 HashJoiner 来实现的，HashJoinBuildOperator 和 HashJoinProbeOperator 共享一个 HashJoiner，通过 HashJoiner::_phase 来判断当时是 Build 还是 Probe 阶段，HashJoinProbeOperator 也是基于这个字段来解除阻塞。示意图如下：</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-HashJoin-1.svg?raw=true" alt="Pipeline-HashJoin-1"></p><h3 id="append-chunk-to-ht"><a href="#append-chunk-to-ht" class="headerlink" title="append_chunk_to_ht"></a>append_chunk_to_ht</h3><p>BuildOperator 通过 push_chunk 接口接收表 t1 数据，内部调用 HashJoiner::append_chunk_to_ht 函数来构建 hashTable，</p><p>注意：BuildOperator 的前一个 Operator 不一定就是 OlapScanOperator，也可能是 ExchangeSourceOperator。因为当 t1 数据量很大，无法在一个节点上构建完整的 HashTable 时，需要将 t1 的数据正交划分，再 ExchangeSink 发到多个节点上执行 HashJOIN，最后组合多个节点上 HashJOIN 的执行结果即可。</p><p>目前，一个 BuildOperator 最大行数不能超过 UINT32_MAX。push_chunk 的过程如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">HashJoinBuildOperator::push_chunk</span><span class="params">(RuntimeState* state, </span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _join_builder-&gt;<span class="built_in">append_chunk_to_ht</span>(state, chunk);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">HashJoiner::append_chunk_to_ht</span><span class="params">(RuntimeState* state, <span class="type">const</span> ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (_phase != HashJoinPhase::BUILD) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!chunk || chunk-&gt;<span class="built_in">is_empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">UNLIKELY</span>(_ht.<span class="built_in">get_row_count</span>() + chunk-&gt;<span class="built_in">num_rows</span>() &gt;= UINT32_MAX)) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">NotSupported</span>(strings::<span class="built_in">Substitute</span>(</span><br><span class="line">            <span class="string">&quot;row count of right table in hash join &gt; $0&quot;</span>, UINT32_MAX));</span><br><span class="line">    &#125;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 获取 key_columns</span></span><br><span class="line">        <span class="built_in">SCOPED_TIMER</span>(_build_conjunct_evaluate_timer);</span><br><span class="line">        _prepare_key_columns(_key_columns, chunk, _build_expr_ctxs);</span><br><span class="line">    &#125;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// copy chunk of right table</span></span><br><span class="line">        <span class="built_in">SCOPED_TIMER</span>(_copy_right_table_chunk_timer);</span><br><span class="line">        <span class="built_in">TRY_CATCH_BAD_ALLOC</span>(</span><br><span class="line">            _ht.<span class="built_in">append_chunk</span>(state, chunk, _key_columns));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="prepare-key-columns"><a href="#prepare-key-columns" class="headerlink" title="_prepare_key_columns"></a>_prepare_key_columns</h4><p>_prepare_key_columns 函数是基于 expr_ctxs 从 chunk 中提取出 join-key 对应的列，将结果保存到 key_columns。</p><p>只不过对于 only_null、const_column 两种类型的列有优化，因此特殊判断下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> HashJoiner::_prepare_key_columns(Columns&amp; key_columns, </span><br><span class="line">                                      <span class="type">const</span> ChunkPtr&amp; chunk,</span><br><span class="line">                                      <span class="type">const</span> std::vector&lt;ExprContext*&gt;&amp; expr_ctxs) &#123;</span><br><span class="line">    key_columns.<span class="built_in">resize</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; expr_ctx : expr_ctxs) &#123;</span><br><span class="line">        <span class="comment">// 从 chunk 中提取出 column</span></span><br><span class="line">        <span class="keyword">auto</span> column_ptr = </span><br><span class="line">            <span class="built_in">EVALUATE_NULL_IF_ERROR</span>(expr_ctx, expr_ctx-&gt;<span class="built_in">root</span>(), chunk.<span class="built_in">get</span>());</span><br><span class="line">        <span class="keyword">if</span> (column_ptr-&gt;<span class="built_in">only_null</span>()) &#123;</span><br><span class="line">            <span class="keyword">auto</span> column = </span><br><span class="line">                ColumnHelper::<span class="built_in">create_column</span>(expr_ctx-&gt;<span class="built_in">root</span>()-&gt;<span class="built_in">type</span>(), <span class="literal">true</span>);</span><br><span class="line">            column-&gt;<span class="built_in">append_nulls</span>(chunk-&gt;<span class="built_in">num_rows</span>());</span><br><span class="line">            key_columns.<span class="built_in">emplace_back</span>(column);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (column_ptr-&gt;<span class="built_in">is_constant</span>()) &#123;</span><br><span class="line">            <span class="keyword">auto</span> const_column = </span><br><span class="line">                ColumnHelper::<span class="built_in">as_raw_column</span>&lt;ConstColumn&gt;(column_ptr);</span><br><span class="line">            const_column-&gt;<span class="built_in">data_column</span>()-&gt;<span class="built_in">assign</span>(chunk-&gt;<span class="built_in">num_rows</span>(), <span class="number">0</span>);</span><br><span class="line">            key_columns.<span class="built_in">emplace_back</span>(const_column-&gt;<span class="built_in">data_column</span>());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            key_columns.<span class="built_in">emplace_back</span>(column_ptr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JoinHashTable-append-chunk"><a href="#JoinHashTable-append-chunk" class="headerlink" title="JoinHashTable::append_chunk"></a>JoinHashTable::append_chunk</h4><p>在 HashJoiner::_ht 中有个内存数据结构 _table_items 记录着 BuildOperator::push_chunk 的所有数据：当调用 JoinHashTable::append_chunk 函数时，即将 chunk 中的参与构建 HashTable 的列添加到 _table_items-&gt;key_columns 和 _table_items-&gt;build_chunk 中。</p><p>注意：当 join-keys 中还包含 value columns 时，该 join-keys[i] 不会再单独赋值数据，在构建 HashTable 时会直接从 build_chunk 中获取，不会单独分配内存</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">JoinHashTable::append_chunk</span><span class="params">(RuntimeState* state, <span class="type">const</span> ChunkPtr&amp; chunk, </span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">const</span> Columns&amp; key_columns)</span> </span>&#123;</span><br><span class="line">    Columns&amp; columns = _table_items-&gt;build_chunk-&gt;<span class="built_in">columns</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 chunk 中参与构建 HashTable 的 value 列数据添加到 build_chunk 中</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; _table_items-&gt;build_column_count; i++) &#123;</span><br><span class="line">        SlotDescriptor* slot = _table_items-&gt;build_slots[i].slot;</span><br><span class="line">        ColumnPtr&amp; column = chunk-&gt;<span class="built_in">get_column_by_slot_id</span>(slot-&gt;<span class="built_in">id</span>());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!columns[i]-&gt;<span class="built_in">is_nullable</span>() &amp;&amp; column-&gt;<span class="built_in">is_nullable</span>()) &#123;</span><br><span class="line">            <span class="comment">// upgrade to nullable column</span></span><br><span class="line">            columns[i] = NullableColumn::<span class="built_in">create</span>(</span><br><span class="line">                columns[i], NullColumn::<span class="built_in">create</span>(columns[i]-&gt;<span class="built_in">size</span>(), <span class="number">0</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        columns[i]-&gt;<span class="built_in">append</span>(*column);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将参与构建 HashTable 的 key 列数据添加到 key_columns 中</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; _table_items-&gt;key_columns.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="comment">// 如果 join-key 不在 build_chunk 中</span></span><br><span class="line">        <span class="keyword">if</span> (_table_items-&gt;join_keys[i].col_ref == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            <span class="comment">// upgrade to nullable column</span></span><br><span class="line">            <span class="keyword">if</span> (!_table_items-&gt;key_columns[i]-&gt;<span class="built_in">is_nullable</span>() </span><br><span class="line">                &amp;&amp; key_columns[i]-&gt;<span class="built_in">is_nullable</span>()) &#123;</span><br><span class="line">                <span class="type">size_t</span> row_count = _table_items-&gt;key_columns[i]-&gt;<span class="built_in">size</span>();</span><br><span class="line">                _table_items-&gt;key_columns[i] = NullableColumn::<span class="built_in">create</span>(</span><br><span class="line">                  _table_items-&gt;key_columns[i], NullColumn::<span class="built_in">create</span>(row_count, <span class="number">0</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            _table_items-&gt;key_columns[i]-&gt;<span class="built_in">append</span>(*key_columns[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="build-ht"><a href="#build-ht" class="headerlink" title="build_ht"></a>build_ht</h3><p>当 BuildOperator 的前一个 SourceOperator 数据已经全部 pulled，则会调用 HashJoinBuildOperator::set_finishing，在 set_finishing 函数中开始构建 HashTable。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">HashJoinBuildOperator::set_finishing</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    _is_finished = <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_join_builder-&gt;<span class="built_in">build_ht</span>(state));</span><br><span class="line">    <span class="comment">// build runtime bloomfilter ...</span></span><br><span class="line">    _join_builder-&gt;<span class="built_in">enter_probe_phase</span>();</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">HashJoiner::build_ht</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (_phase == HashJoinPhase::BUILD) &#123;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_build(state));</span><br><span class="line">        <span class="built_in">COUNTER_SET</span>(_build_buckets_counter,</span><br><span class="line">           <span class="built_in">static_cast</span>&lt;<span class="type">int64_t</span>&gt;(_ht.<span class="built_in">get_bucket_size</span>()));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JoinHashTable-build"><a href="#JoinHashTable-build" class="headerlink" title="JoinHashTable::build"></a>JoinHashTable::build</h4><p>JoinHashTable::build 函数则是基于内存中的 {key_columns, build_chunk} 开始构建 HashTable。这个构建 HashTable 的算法也不难，可以参考 <a href="https://zhuanlan.zhihu.com/p/593611907">StarRocks Hash Join 源码解析</a></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">JoinHashTable::build</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_table_items-&gt;build_chunk-&gt;<span class="built_in">upgrade_if_overflow</span>());</span><br><span class="line">    _table_items-&gt;has_large_column = _table_items-&gt;build_chunk-&gt;<span class="built_in">has_large_column</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果 join-key 包含在 build_chunk 中，则直接从 build_chunk 中获取</span></span><br><span class="line">    <span class="type">size_t</span> join_key_count = _table_items-&gt;join_keys.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; join_key_count; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_table_items-&gt;join_keys[i].col_ref != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            SlotId slot_id = _table_items-&gt;join_keys[i].col_ref-&gt;<span class="built_in">slot_id</span>();</span><br><span class="line">            _table_items-&gt;key_columns[i] = </span><br><span class="line">                _table_items-&gt;build_chunk-&gt;<span class="built_in">get_column_by_slot_id</span>(slot_id);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_upgrade_key_columns_if_overflow());</span><br><span class="line"></span><br><span class="line">    _hash_map_type = _choose_join_hash_map();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开始构建 HashTable</span></span><br><span class="line">    <span class="keyword">switch</span> (_hash_map_type) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M(NAME)                                                                                                       \</span></span><br><span class="line"><span class="meta">    case JoinHashMapType::NAME:                                                                                       \</span></span><br><span class="line"><span class="meta">        _##NAME = std::make_unique<span class="string">&lt;typename decltype(_##NAME)::element_type&gt;</span>(_table_items.get(), _probe_state.get()); \</span></span><br><span class="line"><span class="meta">        _##NAME-&gt;build_prepare(state);                                                                                \</span></span><br><span class="line"><span class="meta">        _##NAME-&gt;probe_prepare(state);                                                                                \</span></span><br><span class="line"><span class="meta">        _##NAME-&gt;build(state);                                                                                        \</span></span><br><span class="line"><span class="meta">        break;</span></span><br><span class="line">        <span class="built_in">APPLY_FOR_JOIN_VARIANTS</span>(M)</span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> M</span></span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="built_in">assert</span>(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="HashJoinProbeOperator"><a href="#HashJoinProbeOperator" class="headerlink" title="HashJoinProbeOperator"></a>HashJoinProbeOperator</h2><p>当 HashJoiner::build_ht 函数构建完 HashTable，会通过 HashJoiner::enter_probe_phase 函数主动进入 HashJoinPhase::PROBE 阶段。HashJoinProbeOperator::need_input 返回 true，解除阻塞，则会从 blocked_driver_poller 中剔除进入 ready poller 开始执行。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">HashJoiner::enter_probe_phase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    _short_circuit_break();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> old_phase = HashJoinPhase::BUILD;</span><br><span class="line">    _phase.<span class="built_in">compare_exchange_strong</span>(old_phase, HashJoinPhase::PROBE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">HashJoinProbeOperator::need_input</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _join_prober-&gt;<span class="built_in">need_input</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">HashJoiner::need_input</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _phase == HashJoinPhase::PROBE &amp;&amp; _probe_input_chunk == <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="push-chunk"><a href="#push-chunk" class="headerlink" title="push_chunk"></a>push_chunk</h3><p>进入 HashJoinPhase::Probe 阶段后，Probe Pipeline 阻塞点就在 t2 的 pull_chunk。</p><p>一旦 SourceOperator::pull_chunk 返回一个chunk，DriverExecutor 就会推动 Probe Pipeline 状态机前进: SourceOperator:::pull_chunk –&gt; HashJoinProbeOperator::push_chunk –&gt; HashJoinProbeOperator::pull_chunk </p><p>Probe HashTable 的过程就发生在 HashJoinProbeOperator::pull_chunk 过程中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">HashJoinProbeOperator::push_chunk</span><span class="params">(RuntimeState* state, <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line">    _join_prober-&gt;<span class="built_in">push_chunk</span>(state, chunk);</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HashJoiner::push_chunk</span><span class="params">(RuntimeState* state, ChunkPtr chunk)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(chunk &amp;&amp; !chunk-&gt;<span class="built_in">is_empty</span>());</span><br><span class="line">    <span class="built_in">DCHECK</span>(!_probe_input_chunk);</span><br><span class="line"></span><br><span class="line">    _probe_input_chunk = std::<span class="built_in">move</span>(chunk);</span><br><span class="line">    _ht_has_remain = <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">// 获取 probe 对应的 key-columns</span></span><br><span class="line">    _prepare_probe_key_columns();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="pull-chunk"><a href="#pull-chunk" class="headerlink" title="pull_chunk"></a>pull_chunk</h3><p>pull_chunk 函数就是一个 Probe HashTable 的过程，过程详解 <a href="https://zhuanlan.zhihu.com/p/593611907">StarRocks Hash Join 源码解析</a>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;vectorized::ChunkPtr&gt; <span class="title">HashJoinProbeOperator::pull_chunk</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _join_prober-&gt;<span class="built_in">pull_chunk</span>(state);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">StatusOr&lt;ChunkPtr&gt; <span class="title">HashJoiner::pull_chunk</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(_phase != HashJoinPhase::BUILD);</span><br><span class="line">    <span class="keyword">return</span> _pull_probe_output_chunk(state);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">StatusOr&lt;ChunkPtr&gt; HashJoiner::_pull_probe_output_chunk(RuntimeState* state) &#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(_phase != HashJoinPhase::BUILD);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> chunk = std::<span class="built_in">make_shared</span>&lt;Chunk&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_phase == HashJoinPhase::PROBE || _probe_input_chunk != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(_ht_has_remain &amp;&amp; _probe_input_chunk);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">TRY_CATCH_BAD_ALLOC</span>(</span><br><span class="line">                <span class="built_in">RETURN_IF_ERROR</span>(_ht.<span class="built_in">probe</span>(state, _key_columns, &amp;_probe_input_chunk, &amp;chunk, &amp;_ht_has_remain)));</span><br><span class="line">        <span class="keyword">if</span> (!_ht_has_remain) &#123;</span><br><span class="line">            _probe_input_chunk = <span class="literal">nullptr</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_filter_probe_output_chunk(chunk));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> chunk;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_phase == HashJoinPhase::POST_PROBE) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!_need_post_probe()) &#123;</span><br><span class="line">            <span class="built_in">enter_eos_phase</span>();</span><br><span class="line">            <span class="keyword">return</span> chunk;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">TRY_CATCH_BAD_ALLOC</span>(<span class="built_in">RETURN_IF_ERROR</span>(_ht.<span class="built_in">probe_remain</span>(state, &amp;chunk, &amp;_ht_has_remain)));</span><br><span class="line">        <span class="keyword">if</span> (!_ht_has_remain) &#123;</span><br><span class="line">            <span class="built_in">enter_eos_phase</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_filter_post_probe_output_chunk(chunk));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> chunk;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> chunk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Questtion"><a href="#Questtion" class="headerlink" title="Questtion"></a>Questtion</h2><p>StarRocks 中的 HashTable cache miss 比较高，效率没那么好？一个 cache-friendly HashTable 设计考量可以参考这篇论文 <a href="https://dl.acm.org/doi/10.14778/2850583.2850585">A Seven-Dimensional Analysis of Hashing Methods and its Implications on Query Processing</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;HashJOIN 经过优化器后，生成的执行计划一般是右表是小表，用于 Build HashTable，左表是大表，用于 Probe HashTable。而左表必须等右表构建完 HashTable 才能执行 Probe 过程，因此 Build 和 Probe 之间存在一个依赖</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Pipeline-Profile 分析</title>
    <link href="https://szza.github.io/2023/08/06/Pipeline/Pipeline-profile/"/>
    <id>https://szza.github.io/2023/08/06/Pipeline/Pipeline-profile/</id>
    <published>2023-08-06T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:31.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RuntimeProfile"><a href="#RuntimeProfile" class="headerlink" title="RuntimeProfile"></a>RuntimeProfile</h2><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://forum.mirrorship.cn/t/topic/5058">Pipeline-Profile 分析及优化指南: StarRocks 2.3+</a></li><li><a href="https://forum.mirrorship.cn/t/topic/4926">StarRocks开启Pipeline后并行度设置说明</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;RuntimeProfile&quot;&gt;&lt;a href=&quot;#RuntimeProfile&quot; class=&quot;headerlink&quot; title=&quot;RuntimeProfile&quot;&gt;&lt;/a&gt;RuntimeProfile&lt;/h2&gt;&lt;h2 id=&quot;Reference&quot;&gt;&lt;a hre</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>查询加速: QueryCache</title>
    <link href="https://szza.github.io/2023/08/05/Pipeline/StarRocks-QueryCache/"/>
    <id>https://szza.github.io/2023/08/05/Pipeline/StarRocks-QueryCache/</id>
    <published>2023-08-05T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:44.377Z</updated>
    
    <content type="html"><![CDATA[<p>输入数据源会被划分多个 Morsels，每个 morsel 都表征着一个要读取的数据源及其范围 {tablet_id, version}，这两个信息也包含在 scan_range 中。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/QueryCache-1.svg?raw=true" alt="QueryCache-1"></p><h2 id="enable-query-cache"><a href="#enable-query-cache" class="headerlink" title="enable_query_cache"></a>enable_query_cache</h2><p>在 query_cache 没有失效的情况下，N 个 MultiLaneOperator 之间的 lane 是一一对应的，数据流如下。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/QueryCache-2.svg?raw=true" alt="QueryCache-2"></p><p>一个 MultiLaneOperator 包含多个 MultiOperator::Lane，每个 MultiOperator::Lane 中都包含了一个 operator：一个 lane-chain 用于处理一个 morsel  数据。<br>将原本的的 一个 Operator 子划分为 _num_lanes 个，实现 tablet 内的并行，每当一个 lane-chain 处理完一个morsel的数据及其后续操作时（ last_chunk_received &#x3D; true，eof_sent &#x3D; true）会将结果缓存到 CacheMgr，供后续操作共享结果。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Lane</span> &#123;</span><br><span class="line">    pipeline::OperatorPtr processor;</span><br><span class="line">    <span class="type">int64_t</span> lane_owner;  <span class="comment">// tablet_id</span></span><br><span class="line">    <span class="type">int</span> lane_id;</span><br><span class="line">    <span class="type">bool</span> last_chunk_received; </span><br><span class="line">    <span class="type">bool</span> eof_sent;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Lane</span>(pipeline::OperatorPtr&amp;&amp; op, <span class="type">int</span> id)</span><br><span class="line">     : <span class="built_in">processor</span>(std::<span class="built_in">move</span>(op)), </span><br><span class="line">       <span class="built_in">lane_owner</span>(<span class="number">-1</span>),</span><br><span class="line">       <span class="built_in">lane_id</span>(id),</span><br><span class="line">       <span class="built_in">last_chunk_received</span>(<span class="literal">false</span>), </span><br><span class="line">       <span class="built_in">eof_sent</span>(<span class="literal">false</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// MultilaneOperator</span></span><br><span class="line">MultilaneOperator::<span class="built_in">MultilaneOperator</span>(pipeline::OperatorFactory* factory, </span><br><span class="line">                                     <span class="type">int32_t</span> driver_sequence,</span><br><span class="line">                                     <span class="type">size_t</span> num_lanes,</span><br><span class="line">                                     pipeline::Operators&amp;&amp; processors, </span><br><span class="line">                                     <span class="type">bool</span> can_passthrough)</span><br><span class="line">: pipeline::<span class="built_in">Operator</span>(factory, factory-&gt;<span class="built_in">id</span>(),</span><br><span class="line">                     factory-&gt;<span class="built_in">get_raw_name</span>(), </span><br><span class="line">                     factory-&gt;<span class="built_in">plan_node_id</span>(),</span><br><span class="line">                     driver_sequence),</span><br><span class="line">  _num_lanes(num_lanes),</span><br><span class="line">  _can_passthrough(can_passthrough) &#123;</span><br><span class="line">     _lanes.<span class="built_in">reserve</span>(_num_lanes);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; _num_lanes; ++i) &#123;</span><br><span class="line">        <span class="comment">// 每个 lane 对应着一个 operator</span></span><br><span class="line">        _lanes.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(processors[i]), i); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// MultilaneOperatorFactory</span></span><br><span class="line"><span class="function">pipeline::OperatorPtr <span class="title">MultilaneOperatorFactory::create</span><span class="params">(<span class="type">int32_t</span> degree_of_parallelism,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                       <span class="type">int32_t</span> driver_sequence)</span> </span>&#123;</span><br><span class="line">    pipeline::Operators processors;</span><br><span class="line">    processors.<span class="built_in">reserve</span>(_num_lanes);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; _num_lanes; ++i) &#123;</span><br><span class="line">        processors.<span class="built_in">push_back</span>(_factory-&gt;<span class="built_in">create</span>(</span><br><span class="line">            degree_of_parallelism * _num_lanes,</span><br><span class="line">             driver_sequence * _num_lanes + i));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;MultilaneOperator&gt;(<span class="keyword">this</span>, driver_sequence,</span><br><span class="line">                                               _num_lanes,</span><br><span class="line">                                               std::<span class="built_in">move</span>(processors), </span><br><span class="line">                                               _can_passthrough);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="disable-query-cache"><a href="#disable-query-cache" class="headerlink" title="disable_query_cache"></a>disable_query_cache</h2><p>当 disable_query_cache 时，就退化为基本的状态，即此时每个 MultiLaneOperator 内部实际上只有一个 operator 在发挥作用，最后一个 MultiLaneOperator 中只有一个 passthrough_chunk 传递数据。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/QueryCache-3.svg?raw=true" alt="QueryCache-3"></p><h2 id="push-chunk"><a href="#push-chunk" class="headerlink" title="push_chunk"></a>push_chunk</h2><p>CacheOperator 内部有个 CacheMgr。在 push chunk 时，根据 chunk 的 {rows, bytes} 大小来决定 query_cache 是否有效。</p><p>LaneArbiter 的作用类似于全局锁，在 ScanOperator、MultiLaneOperator、CacheOperator 之间共享，记录着当前 query_cache 是否失效。<br>每次向 CacheOperator 中 push chunk 之前，都会检测 chunk 的 rows 和 bytes 是否超过 {max_rows, max_bytes} 阈值：</p><ul><li><p>如果超过，则转变为 passthrough 模式，不再向 CacheMgr 中写入数据，直接使用 passthrough_chunk 来存储每次读取的数据</p><p>注意，变成 passthrough 模式后，CacheMgr 的数据仍在没有清除，仍可为后续的读取提供缓存。</p></li><li><p>没有超过，则继续向 CacheMgr 中写数据</p></li></ul><p>每个 chunk 都有一个 owner 信息：</p><ul><li>owner_id：即 tablet_id，从 哪个 table_id 读取到的，通过 owner_id 可以定位到具体的 lane。</li><li>is_last_chunk：是不是这个 morsel 的最后一个 chunk；</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> CacheOperator::_should_passthrough(<span class="type">size_t</span> num_rows, <span class="type">size_t</span> num_bytes) &#123;</span><br><span class="line">    <span class="keyword">return</span> _cache_param.entry_max_rows &lt;= <span class="number">0</span> || num_rows &gt; _cache_param.entry_max_rows ||</span><br><span class="line">           _cache_param.entry_max_bytes &lt;= <span class="number">0</span> || num_bytes &gt; _cache_param.entry_max_bytes;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">CacheOperator::push_chunk</span><span class="params">(RuntimeState* state, <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(chunk != <span class="literal">nullptr</span>);</span><br><span class="line">    <span class="keyword">if</span> (_lane_arbiter-&gt;<span class="built_in">in_passthrough_mode</span>()) &#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(_passthrough_chunk == <span class="literal">nullptr</span>);</span><br><span class="line">        _passthrough_chunk = chunk;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">auto</span> lane_owner = chunk-&gt;<span class="built_in">owner_info</span>().<span class="built_in">owner_id</span>();</span><br><span class="line">    <span class="built_in">DCHECK</span>(_owner_to_lanes.<span class="built_in">count</span>(lane_owner));</span><br><span class="line">    <span class="keyword">auto</span> lane_id = _owner_to_lanes[lane_owner];</span><br><span class="line">    <span class="keyword">auto</span>&amp; buffer = _per_lane_buffers[lane_id];</span><br><span class="line">    buffer-&gt;<span class="built_in">append_chunk</span>(chunk);</span><br><span class="line"></span><br><span class="line">     <span class="comment">// 检测是否超过限制</span></span><br><span class="line">    <span class="keyword">if</span> (_should_passthrough(buffer-&gt;num_rows, buffer-&gt;num_bytes)) &#123;</span><br><span class="line">        _lane_arbiter-&gt;<span class="built_in">enable_passthrough_mode</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, lane_id] : _owner_to_lanes) &#123;</span><br><span class="line">            _per_lane_buffers[lane_id]-&gt;<span class="built_in">set_passthrough</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (buffer-&gt;<span class="built_in">should_populate_cache</span>()) &#123;</span><br><span class="line">         <span class="comment">// 写入 cache</span></span><br><span class="line">        <span class="built_in">populate_cache</span>(lane_owner);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="populate-cache"><a href="#populate-cache" class="headerlink" title="populate_cache"></a>populate_cache</h3><p>在 push chunk 时，每次都会尝试调用 PerLaneBuffer::should_populate_cache 函数来 check 是否需要将填充 cache：</p><ul><li>cached_version 是 cache_mgr 中目前 cache 的版本，required_version 是目前需要的版本，cached_version &lt; required_version 说明 cache_mgr 中缓存的数据过时，需要填充新的数据；</li><li>PLBS_TOTAL：表征这个 lane 的数据读取完毕，此时会把这个 per_lane_buff 的数据填充到 cache_mgr 中；</li></ul><p>完整的判断条件如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">PerLaneBuffer::should_populate_cache</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> cached_version &lt; required_version &amp;&amp; </span><br><span class="line">           (state == PLBS_HIT_TOTAL || state == PLBS_TOTAL);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>填充 cache 的实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">CacheOperator::populate_cache</span><span class="params">(<span class="type">int64_t</span> tablet_id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> lane = _owner_to_lanes[tablet_id];</span><br><span class="line">    <span class="keyword">auto</span>&amp; buffer = _per_lane_buffers[lane];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> cache_key_suffix_it = _cache_param.cache_key_prefixes.<span class="built_in">find</span>(tablet_id);</span><br><span class="line">    <span class="keyword">if</span> (cache_key_suffix_it == _cache_param.cache_key_prefixes.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        <span class="comment">// uncacheable</span></span><br><span class="line">        buffer-&gt;state = PLBS_POPULATE;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::string cache_key = </span><br><span class="line">        _cache_param.digest + cache_key_suffix_it-&gt;second;</span><br><span class="line">    <span class="type">int64_t</span> current = <span class="built_in">GetMonoTimeMicros</span>();</span><br><span class="line">    <span class="keyword">auto</span> chunks = <span class="built_in">remap_chunks</span>(buffer-&gt;chunks, _cache_param.slot_remapping);</span><br><span class="line">    <span class="function">CacheValue <span class="title">cache_value</span><span class="params">(current, buffer-&gt;required_version, std::move(chunks))</span></span>;</span><br><span class="line">    <span class="comment">// If the cache implementation is global, </span></span><br><span class="line">    <span class="comment">// populate method must be asynchronous and try its best to</span></span><br><span class="line">    <span class="comment">// update the cache.</span></span><br><span class="line">    _cache_populate_bytes_counter-&gt;<span class="built_in">update</span>(buffer-&gt;num_bytes);</span><br><span class="line">    _cache_populate_chunks_counter-&gt;<span class="built_in">update</span>(buffer-&gt;chunks.<span class="built_in">size</span>());</span><br><span class="line">    _cache_populate_rows_counter-&gt;<span class="built_in">update</span>(buffer-&gt;num_rows);</span><br><span class="line">    _populate_tablets.<span class="built_in">insert</span>(tablet_id);</span><br><span class="line">     <span class="comment">// 缓存 mgr 中，超出容量时，kv会自动删除低优先级</span></span><br><span class="line">    _cache_mgr-&gt;<span class="built_in">populate</span>(cache_key, cache_value);</span><br><span class="line">    buffer-&gt;state = PLBS_POPULATE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="pull-chunk"><a href="#pull-chunk" class="headerlink" title="pull_chunk"></a>pull_chunk</h2><p>从 CacheOperator 中获取数据时：</p><ul><li>如果 query_cache 未失效， 则从 PerLaneBuffer 中获取；</li><li>否则直接从 passthrough_chunk 读取</li></ul><p>代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;vectorized::ChunkPtr&gt; <span class="title">CacheOperator::pull_chunk</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> opt_lane = _lane_arbiter-&gt;<span class="built_in">preferred_lane</span>();</span><br><span class="line">    <span class="keyword">if</span> (opt_lane.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">        <span class="keyword">auto</span> lane = opt_lane.<span class="built_in">value</span>();</span><br><span class="line">        <span class="keyword">auto</span>&amp; buffer = _per_lane_buffers[lane];</span><br><span class="line">        <span class="keyword">auto</span> chunk = _pull_chunk_from_per_lane_buffer(buffer);</span><br><span class="line">        <span class="keyword">if</span> (chunk != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> chunk;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, lane_id] : _owner_to_lanes) &#123;</span><br><span class="line">        <span class="keyword">auto</span>&amp; buffer = _per_lane_buffers[lane_id];</span><br><span class="line">        <span class="keyword">auto</span> chunk = _pull_chunk_from_per_lane_buffer(buffer);</span><br><span class="line">        <span class="keyword">if</span> (chunk != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> chunk;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">move</span>(_passthrough_chunk);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="pull-chunk-from-per-lane-buffer"><a href="#pull-chunk-from-per-lane-buffer" class="headerlink" title="_pull_chunk_from_per_lane_buffer"></a>_pull_chunk_from_per_lane_buffer</h3><p>当从 CacheOperator 中获取数据时，会从 PerLaneBufferPtr  中获取，如果 lane_id 中的数据已经读取完，则释放该 lane，让后续的 morsel 继续复用该lane继续提交任务。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vectorized::ChunkPtr CacheOperator::_pull_chunk_from_per_lane_buffer(PerLaneBufferPtr&amp; buffer) &#123;</span><br><span class="line">    <span class="keyword">if</span> (buffer-&gt;<span class="built_in">has_chunks</span>()) &#123;</span><br><span class="line">        <span class="keyword">auto</span> chunk = buffer-&gt;<span class="built_in">get_next_chunk</span>();</span><br><span class="line">        <span class="keyword">if</span> (buffer-&gt;<span class="built_in">can_release</span>()) &#123;</span><br><span class="line">            _lane_arbiter-&gt;<span class="built_in">release_lane</span>(chunk-&gt;<span class="built_in">owner_info</span>().<span class="built_in">owner_id</span>()); <span class="comment">// 类似于释放锁的逻辑</span></span><br><span class="line">            buffer-&gt;<span class="built_in">reset</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> chunk;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="pick-morsel"><a href="#pick-morsel" class="headerlink" title="_pick_morsel"></a>_pick_morsel</h2><p>在 <a href="https://szza.github.io/2023/07/07/Pipeline/MorselQueue_3/">Morsel 和 OlapScanOperator</a> 中讲过 pick_morsel 函数，但是省略了 QueryCache 部分。</p><p>从 MorselQueue 中获取一个  morsel 后，先要从 lane_arbiter 中获得一个 lane slot 才能执行。</p><ul><li>query_cache::AR_BUSY： 没有可执行的任务</li><li>query_cache::AR_PROBE：获得一个可用的 lane slot，先去 cache 中探测下，是否已经缓存过 {tablet_id, version} 的部分数据，如果已经缓存一部分，则后续只需要读取增量部分。</li><li>query_cache::AR_SKIP： 这个 lane 已经处理过；</li><li>query_cache::AR_IO：<ul><li>passthrough 模式，或者</li><li>query-cache 失效后进入 passthroguh 模式，此时可能仍有部分缓存数据，尝试读取。</li></ul></li></ul><p>这部分代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">Status ScanOperator::_pickup_morsel(RuntimeState* state, <span class="type">int</span> chunk_source_index) &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="comment">// 根据 morsel_queue 的策略，获取一个 mosel</span></span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> morsel, _morsel_queue-&gt;<span class="built_in">try_get</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_lane_arbiter != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">while</span> (morsel != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            <span class="comment">// 这个 morsel 对应的 tablet_id 和 version</span></span><br><span class="line">            <span class="keyword">auto</span> [lane_owner, version] = morsel-&gt;<span class="built_in">get_lane_owner_and_version</span>();</span><br><span class="line">            <span class="comment">// 这个 tablet 对应的 lane 是否被占据</span></span><br><span class="line">            <span class="keyword">auto</span> acquire_result = _lane_arbiter-&gt;<span class="built_in">try_acquire_lane</span>(lane_owner);</span><br><span class="line">            <span class="keyword">if</span> (acquire_result == query_cache::AR_BUSY) &#123;</span><br><span class="line">                <span class="comment">// 无可用的 lane</span></span><br><span class="line">                _morsel_queue-&gt;<span class="built_in">unget</span>(std::<span class="built_in">move</span>(morsel)); </span><br><span class="line">                <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (acquire_result == query_cache::AR_PROBE) &#123;</span><br><span class="line">                <span class="comment">// 首次探测 &#123;tablet_id, version&#125;</span></span><br><span class="line">                <span class="keyword">auto</span> hit = _cache_operator-&gt;<span class="built_in">probe_cache</span>(lane_owner, version);   </span><br><span class="line">                <span class="comment">// 初始化</span></span><br><span class="line">                <span class="built_in">RETURN_IF_ERROR</span>(_cache_operator-&gt;<span class="built_in">reset_lane</span>(state, lane_owner));</span><br><span class="line">                <span class="keyword">if</span> (!hit) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// hit 则从 cache 中获取，尽早跳出循环</span></span><br><span class="line">                <span class="keyword">auto</span> [delta_version, delta_rowsets] = </span><br><span class="line">                    _cache_operator-&gt;<span class="built_in">delta_version_and_rowsets</span>(lane_owner);</span><br><span class="line">                <span class="keyword">if</span> (!delta_rowsets.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                    <span class="comment">// 已经缓存的 version</span></span><br><span class="line">                    morsel-&gt;<span class="built_in">set_from_version</span>(delta_version); </span><br><span class="line">                    <span class="comment">// 对应的 rowsets</span></span><br><span class="line">                    morsel-&gt;<span class="built_in">set_rowsets</span>(delta_rowsets);      </span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="built_in">ASSIGN_OR_RETURN</span>(morsel, _morsel_queue-&gt;<span class="built_in">try_get</span>());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (acquire_result == query_cache::AR_SKIP) &#123;</span><br><span class="line">                <span class="built_in">ASSIGN_OR_RETURN</span>(morsel, _morsel_queue-&gt;<span class="built_in">try_get</span>());</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (acquire_result == query_cache::AR_IO) &#123;</span><br><span class="line">                <span class="keyword">auto</span> [delta_verrsion, delta_rowsets] = </span><br><span class="line">                    _cache_operator-&gt;<span class="built_in">delta_version_and_rowsets</span>(lane_owner);</span><br><span class="line">                <span class="keyword">if</span> (!delta_rowsets.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                    morsel-&gt;<span class="built_in">set_from_version</span>(delta_verrsion);</span><br><span class="line">                    morsel-&gt;<span class="built_in">set_rowsets</span>(delta_rowsets);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">       </span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="delta-version-and-rowsets"><a href="#delta-version-and-rowsets" class="headerlink" title="delta_version_and_rowsets"></a>delta_version_and_rowsets</h3><p>delta_version_and_rowsets 方法从 CacheOperator::_per_lane_buffers 中获得已经 scan 缓存的  {version, rowset} 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">std::tuple&lt;<span class="type">int64_t</span>, vector&lt;RowsetSharedPtr&gt;&gt; </span><br><span class="line">CacheOperator::<span class="built_in">delta_version_and_rowsets</span>(<span class="type">int64_t</span> tablet_id) &#123;</span><br><span class="line">    <span class="keyword">auto</span> lane_it = _owner_to_lanes.<span class="built_in">find</span>(tablet_id);</span><br><span class="line">    <span class="keyword">if</span> (lane_it == _owner_to_lanes.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(<span class="number">0</span>, vector&lt;RowsetSharedPtr&gt;&#123;&#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">auto</span>&amp; buffer = _per_lane_buffers[lane_it-&gt;second];</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(</span><br><span class="line">            buffer-&gt;cached_version + <span class="number">1</span>, buffer-&gt;rowsets);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="OlapChunkSource-init-olap-reader"><a href="#OlapChunkSource-init-olap-reader" class="headerlink" title="OlapChunkSource::_init_olap_reader"></a>OlapChunkSource::_init_olap_reader</h3><p>TabletReader 初始化时，即只读取增量部分。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Status OlapChunkSource::_init_olap_reader(RuntimeState* runtime_state) &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="comment">// 只读取增量数据部分</span></span><br><span class="line">    _reader = std::<span class="built_in">make_shared</span>&lt;TabletReader&gt;(_tablet, </span><br><span class="line">                                             <span class="built_in">Version</span>(_morsel-&gt;<span class="built_in">from_version</span>(), _version),</span><br><span class="line">                                             std::<span class="built_in">move</span>(child_schema),</span><br><span class="line">                                             _morsel-&gt;<span class="built_in">rowsets</span>());</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_reader-&gt;<span class="built_in">prepare</span>());</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_reader-&gt;<span class="built_in">open</span>(_params));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CacheOperator-probe-cache"><a href="#CacheOperator-probe-cache" class="headerlink" title="CacheOperator::probe_cache"></a>CacheOperator::probe_cache</h3><p>CacheMgr 是全局唯一的，在开启 QueryCache 的情况下，每次执行都会尝试去填充 CacheMgr，隐藏 cache 数据来自于两部分：</p><ul><li>当前 scan 任务填充的</li><li>之前执行任务填充的</li></ul><p>从 MorselQueue 中获得一个 mosel 之后，使用 morsel的 {tablet_id, version} 到CacheMgr中查询是否有缓存部分数据，基于缓存结果再设置 TabletReader 的参数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">CacheOperator::probe_cache</span><span class="params">(<span class="type">int64_t</span> tablet_id, <span class="type">int64_t</span> version)</span> </span>&#123; </span><br><span class="line">    _all_tablets.<span class="built_in">insert</span>(tablet_id);</span><br><span class="line">    <span class="comment">// allocate lane and PerLaneBuffer for tablet_id</span></span><br><span class="line">    <span class="type">int64_t</span> lane = _lane_arbiter-&gt;<span class="built_in">must_acquire_lane</span>(tablet_id);</span><br><span class="line"></span><br><span class="line">    _owner_to_lanes[tablet_id] = lane;</span><br><span class="line">    <span class="keyword">auto</span>&amp; buffer = _per_lane_buffers[lane];</span><br><span class="line">    buffer-&gt;<span class="built_in">reset</span>();</span><br><span class="line">    buffer-&gt;lane = lane;</span><br><span class="line">    buffer-&gt;required_version = version;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_cache_param.force_populate </span><br><span class="line">        || !_cache_param.cache_key_prefixes.<span class="built_in">count</span>(tablet_id)) &#123;</span><br><span class="line">        buffer-&gt;state = PLBS_MISS;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// probe cache</span></span><br><span class="line">    <span class="type">const</span> std::string&amp; cache_key = </span><br><span class="line">        _cache_param.digest + _cache_param.cache_key_prefixes.<span class="built_in">at</span>(tablet_id);</span><br><span class="line">    <span class="keyword">auto</span> probe_status = _cache_mgr-&gt;<span class="built_in">probe</span>(cache_key);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Cache MISS when failed to probe</span></span><br><span class="line">    <span class="keyword">if</span> (!probe_status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        buffer-&gt;state = PLBS_MISS;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span>&amp; cache_value = probe_status.<span class="built_in">value</span>();</span><br><span class="line">    <span class="keyword">if</span> (cache_value.version == version) &#123;</span><br><span class="line">        <span class="comment">// Cache HIT_TOTAL when cached version equals to required version</span></span><br><span class="line">        buffer-&gt;state = PLBS_HIT_TOTAL;     <span class="comment">// 完全缓存</span></span><br><span class="line">        buffer-&gt;cached_version = cache_value.version;</span><br><span class="line">        <span class="keyword">auto</span> chunks = <span class="built_in">remap_chunks</span>(</span><br><span class="line">            cache_value.result, _cache_param.reverse_slot_remapping);</span><br><span class="line">        _update_probe_metrics(tablet_id, chunks);</span><br><span class="line">        buffer-&gt;chunks = std::<span class="built_in">move</span>(chunks);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cache_value.version &gt; version) &#123;</span><br><span class="line">        <span class="comment">// It rarely happens that required version is less that cached version,</span></span><br><span class="line">        <span class="comment">// the required version become stale when the query is postponed to be</span></span><br><span class="line">        <span class="comment">// processed because of some reasons, </span></span><br><span class="line">        <span class="comment">// for examples, non-deterministic query scheduling, network congestion etc. </span></span><br><span class="line">        <span class="comment">// make queries be executed out-of-order. so we must prevent stale result </span></span><br><span class="line">        <span class="comment">// from replacing fresh cached result.</span></span><br><span class="line">        buffer-&gt;state = PLBS_MISS;</span><br><span class="line">        buffer-&gt;cached_version = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Incremental updating cause the cached value become stale, </span></span><br><span class="line">        <span class="comment">// It is a very critical and complex situation.</span></span><br><span class="line">        <span class="comment">// here we support a multi-version cache mechanism.</span></span><br><span class="line">        <span class="comment">// 处理部分缓存</span></span><br><span class="line">        _handle_stale_cache_value(tablet_id, cache_value, buffer, version); </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// return true on cache hit, false on cache miss</span></span><br><span class="line">    <span class="keyword">if</span> (buffer-&gt;state == PLBS_HIT_TOTAL) &#123;</span><br><span class="line">        _lane_arbiter-&gt;<span class="built_in">mark_processed</span>(tablet_id);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (buffer-&gt;state == PLBS_HIT_PARTIAL) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="handle-stale-cache-value-for-non-pk"><a href="#handle-stale-cache-value-for-non-pk" class="headerlink" title="_handle_stale_cache_value_for_non_pk"></a>_handle_stale_cache_value_for_non_pk</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> CacheOperator::_handle_stale_cache_value_for_non_pk(<span class="type">int64_t</span> tablet_id, CacheValue&amp; cache_value,</span><br><span class="line">                                                         PerLaneBufferPtr&amp; buffer, <span class="type">int64_t</span> version) &#123;</span><br><span class="line">    <span class="comment">// Try to reuse partial cache result when cached version is less than </span></span><br><span class="line">    <span class="comment">// required version, delta versions should be captured at first.</span></span><br><span class="line">    <span class="keyword">auto</span> status = StorageEngine::<span class="built_in">instance</span>()-&gt;<span class="built_in">tablet_manager</span>()-&gt;<span class="built_in">capture_tablet_and_rowsets</span>(</span><br><span class="line">            tablet_id, cache_value.version + <span class="number">1</span>, version);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Cache MISS if delta versions are not captured,</span></span><br><span class="line">    <span class="comment">//  because aggressive cumulative compactions.</span></span><br><span class="line">    <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        buffer-&gt;state = PLBS_MISS;</span><br><span class="line">        buffer-&gt;cached_version = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Delta versions are captured, several situations </span></span><br><span class="line">    <span class="comment">// should be taken into consideration.</span></span><br><span class="line">    <span class="keyword">auto</span>&amp; [tablet, rowsets, rowsets_acq_rel] = status.<span class="built_in">value</span>();</span><br><span class="line">    <span class="keyword">auto</span> all_rs_empty = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">auto</span> min_version = std::numeric_limits&lt;<span class="type">int64_t</span>&gt;::<span class="built_in">max</span>();</span><br><span class="line">    <span class="keyword">auto</span> max_version = std::numeric_limits&lt;<span class="type">int64_t</span>&gt;::<span class="built_in">min</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; rs : rowsets) &#123;</span><br><span class="line">        all_rs_empty &amp;= !rs-&gt;<span class="built_in">has_data_files</span>();</span><br><span class="line">        min_version = std::<span class="built_in">min</span>(min_version, rs-&gt;<span class="built_in">start_version</span>());</span><br><span class="line">        max_version = std::<span class="built_in">max</span>(max_version, rs-&gt;<span class="built_in">end_version</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Version <span class="title">delta_versions</span><span class="params">(min_version, max_version)</span></span>;</span><br><span class="line">    buffer-&gt;tablet = tablet;</span><br><span class="line">    <span class="keyword">auto</span> has_delete_predicates = tablet-&gt;<span class="built_in">has_delete_predicates</span>(delta_versions);</span><br><span class="line">    <span class="comment">// case 1: there exist delete predicates in delta versions, </span></span><br><span class="line">    <span class="comment">// or data model can not support multiversion cache and </span></span><br><span class="line">    <span class="comment">// the tablet has non-empty delta rowsets;</span></span><br><span class="line">    <span class="comment">// then cache result is not reuse, so cache miss.</span></span><br><span class="line">    <span class="keyword">if</span> (has_delete_predicates || (!_cache_param.can_use_multiversion &amp;&amp; !all_rs_empty)) &#123;</span><br><span class="line">        buffer-&gt;state = PLBS_MISS;</span><br><span class="line">        buffer-&gt;cached_version = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 当前cache的版本</span></span><br><span class="line">    buffer-&gt;cached_version = cache_value.version; </span><br><span class="line">    <span class="keyword">auto</span> chunks = <span class="built_in">remap_chunks</span>(cache_value.result, _cache_param.reverse_slot_remapping);</span><br><span class="line">    _update_probe_metrics(tablet_id, chunks);</span><br><span class="line">    <span class="comment">// 从 cache_mgr 中获得的存量</span></span><br><span class="line">    buffer-&gt;chunks = std::<span class="built_in">move</span>(chunks); </span><br><span class="line">    <span class="comment">// case 2: all delta versions are empty rowsets, so the cache result is hit totally.</span></span><br><span class="line">    <span class="keyword">if</span> (all_rs_empty) &#123;</span><br><span class="line">        buffer-&gt;state = PLBS_HIT_TOTAL;</span><br><span class="line">        buffer-&gt;chunks.<span class="built_in">back</span>()-&gt;<span class="built_in">owner_info</span>().<span class="built_in">set_last_chunk</span>(<span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// case 3: otherwise, the cache result is partial result of per-tablet computation,</span></span><br><span class="line">    <span class="comment">// so delta versions must be scanned and merged </span></span><br><span class="line">    <span class="comment">// with cache result to generate total result.</span></span><br><span class="line">    buffer-&gt;state = PLBS_HIT_PARTIAL;</span><br><span class="line">    <span class="comment">// 当前cache的版本</span></span><br><span class="line">    buffer-&gt;rowsets = std::<span class="built_in">move</span>(rowsets); </span><br><span class="line">    buffer-&gt;rowsets_acq_rel = std::<span class="built_in">move</span>(rowsets_acq_rel);</span><br><span class="line">    buffer-&gt;num_rows = <span class="number">0</span>;</span><br><span class="line">    buffer-&gt;num_bytes = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; chunk : buffer-&gt;chunks) &#123;</span><br><span class="line">        buffer-&gt;num_rows += chunk-&gt;<span class="built_in">num_rows</span>();</span><br><span class="line">        buffer-&gt;num_bytes += chunk-&gt;<span class="built_in">bytes_usage</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    buffer-&gt;chunks.<span class="built_in">back</span>()-&gt;<span class="built_in">owner_info</span>().<span class="built_in">set_last_chunk</span>(<span class="literal">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="LaneArbiter"><a href="#LaneArbiter" class="headerlink" title="LaneArbiter"></a>LaneArbiter</h2><p>在 CacheOperator 中创建，然后以指针形式分享给 ScanOperator、MultiLaneOperator。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/QueryCache-4.svg?raw=true" alt="QueryCache-4"></p><p>LaneArbiter 类似于锁的作用，共有 _nun_lanes 个 slots，可以同时有 num_lane 个任务并发执行：</p><ul><li>try_acquire_lane： 执行任务前，先通过 try_acquire_lane 函数来获取 slot</li><li>release_lane： 执行任务结束，再使用 release_lane 函数来是否 slot</li></ul><h3 id="try-acquire-lane"><a href="#try-acquire-lane" class="headerlink" title="try_acquire_lane"></a>try_acquire_lane</h3><p>在获取scan任务之前，先通过 try_acquire_lane 来获得一个 slot：</p><ul><li>in_passthrough_mode &#x3D;&#x3D; true，则不考虑 query—cache</li><li>_processed.count(lane_owner) 为 1 则这个 lane_owner 已经处理完，不再考虑</li><li>_acquire_lane 函数从 _assignments 数组中获得一个处于 LANE_UNASSIGNED 状态的 lane，返回值<ul><li>NO_FREE_LANE: 表示没有可用的 slot，返回 AcquireResult::AR_BUSY</li><li>NEW_LANE_BIT: 则表示存在可用的 slot，返回 AcquireResult::AR_PROBE</li><li>otherwise，相同的 lane_onwer 再次获取 lane</li></ul></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AcquireResult <span class="title">LaneArbiter::try_acquire_lane</span><span class="params">(LaneOwnerType lane_owner)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">in_passthrough_mode</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> AcquireResult::AR_IO;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/// 已处理过</span></span><br><span class="line">    <span class="keyword">if</span> (_processed.<span class="built_in">count</span>(lane_owner)) &#123;</span><br><span class="line">        <span class="keyword">return</span> AcquireResult::AR_SKIP;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/// 尚未处理</span></span><br><span class="line">    <span class="keyword">auto</span> lane = _acquire_lane(lane_owner);</span><br><span class="line">    <span class="keyword">if</span> (lane == NO_FREE_LANE) &#123;</span><br><span class="line">        <span class="keyword">return</span> AcquireResult::AR_BUSY;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">if</span> ((lane &amp; NEW_LANE_BIT) == NEW_LANE_BIT) &#123;</span><br><span class="line">        <span class="keyword">return</span> AcquireResult::AR_PROBE;</span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> AcquireResult::AR_IO;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="release-lane"><a href="#release-lane" class="headerlink" title="release_lane"></a>release_lane</h3><p>当 CacheOperator::_per_lane_buffers 中的数据读完完毕，会调用  LaneArbiter::release_lane 函数，来标志某个 lane 已经处理完毕。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">LaneArbiter::release_lane</span><span class="params">(LaneOwnerType lane_owner)</span> </span>&#123;</span><br><span class="line">    _processed.<span class="built_in">insert</span>(lane_owner);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; _assignment : _assignments) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_assignment.lane_owner == lane_owner) &#123;</span><br><span class="line">            _assignment = LANE_UNASSIGNED; <span class="comment">// 设置为初始化状态</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="PipelineDriver-prepare"><a href="#PipelineDriver-prepare" class="headerlink" title="PipelineDriver::prepare"></a>PipelineDriver::prepare</h3><p>将 CacheOperator 融入到 PipelineDriver 中</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">PipelineDriver::prepare</span><span class="params">(RuntimeState* runtime_state)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line"></span><br><span class="line">    <span class="type">ssize_t</span> cache_op_idx = <span class="number">-1</span>;</span><br><span class="line">    query_cache::CacheOperatorPtr cache_op = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="comment">// 在一个 pipeline 中寻找 CacheOperator 的位置</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; _operators.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cache_op = std::<span class="built_in">dynamic_pointer_cast</span>&lt;query_cache::CacheOperator&gt;(_operators[i]);</span><br><span class="line">            cache_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            cache_op_idx = i;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cache_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        query_cache::LaneArbiterPtr lane_arbiter = cache_op-&gt;<span class="built_in">lane_arbiter</span>();</span><br><span class="line">        query_cache::MultilaneOperators multilane_operators;</span><br><span class="line">        <span class="comment">// CacheOperator 之前的 operator 都被 wapper 在 MultilaneOperator 或者 OlapScanOperator</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; cache_op_idx; ++i) &#123;</span><br><span class="line">            <span class="keyword">auto</span>&amp; op = _operators[i];</span><br><span class="line">            <span class="comment">// 在 pipeline_builder 中构建的对应的 factory</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">auto</span>* multilane_op = <span class="built_in">dynamic_cast</span>&lt;query_cache::MultilaneOperator*&gt;(op.<span class="built_in">get</span>()); </span><br><span class="line">                multilane_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                multilane_op-&gt;<span class="built_in">set_lane_arbiter</span>(lane_arbiter);</span><br><span class="line">                multilane_operators.<span class="built_in">push_back</span>(multilane_op);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">auto</span>* olap_scan_op = <span class="built_in">dynamic_cast</span>&lt;OlapScanOperator*&gt;(op.<span class="built_in">get</span>()); </span><br><span class="line">                       olap_scan_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                olap_scan_op-&gt;<span class="built_in">set_lane_arbiter</span>(lane_arbiter);</span><br><span class="line">                <span class="comment">// 设置 cache_operator</span></span><br><span class="line">                olap_scan_op-&gt;<span class="built_in">set_cache_operator</span>(cache_op);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        cache_op-&gt;<span class="built_in">set_multilane_operators</span>(std::<span class="built_in">move</span>(multilane_operators));</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;输入数据源会被划分多个 Morsels，每个 morsel 都表征着一个要读取的数据源及其范围 {tablet_id, version}，这两个信息也包含在 scan_range 中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/szza/szz</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>MPP: ExchangeSourceOperator 设计详解</title>
    <link href="https://szza.github.io/2023/08/02/Pipeline/ExchangeNode_2/"/>
    <id>https://szza.github.io/2023/08/02/Pipeline/ExchangeNode_2/</id>
    <published>2023-08-02T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:13.294Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ExchangeSourceOperator"><a href="#ExchangeSourceOperator" class="headerlink" title="ExchangeSourceOperator"></a>ExchangeSourceOperator</h2><h3 id="DataStreamMgr-create-recvr"><a href="#DataStreamMgr-create-recvr" class="headerlink" title="DataStreamMgr::create_recvr"></a>DataStreamMgr::create_recvr</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">PassThroughChunkBuffer* <span class="title">DataStreamMgr::get_pass_through_chunk_buffer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> TUniqueId&amp; query_id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _pass_through_chunk_buffer_manager.<span class="built_in">get</span>(query_id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::shared_ptr&lt;DataStreamRecvr&gt; <span class="title">DataStreamMgr::create_recvr</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        RuntimeState* state, <span class="type">const</span> RowDescriptor&amp; row_desc,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> TUniqueId&amp; fragment_instance_id, PlanNodeId dest_node_id,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> num_senders, <span class="type">int</span> buffer_size, </span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::shared_ptr&lt;RuntimeProfile&gt;&amp; profile, <span class="type">bool</span> is_merging,</span></span></span><br><span class="line"><span class="params"><span class="function">        std::shared_ptr&lt;QueryStatisticsRecvr&gt; sub_plan_query_statistics_recvr,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">bool</span> is_pipeline, <span class="type">int32_t</span> degree_of_parallelism, <span class="type">bool</span> keep_order)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> recvr = std::<span class="built_in">make_shared</span>&lt;DataStreamRecvr&gt;(</span><br><span class="line">                <span class="keyword">this</span>, state, row_desc, </span><br><span class="line">                fragment_instance_id, dest_node_id, num_senders, is_merging,</span><br><span class="line">                buffer_size, profile, std::<span class="built_in">move</span>(sub_plan_query_statistics_recvr),</span><br><span class="line">                is_pipeline, degree_of_parallelism,</span><br><span class="line">                keep_order,</span><br><span class="line">                <span class="built_in">get_pass_through_chunk_buffer</span>(state-&gt;<span class="built_in">query_id</span>())));</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> bucket = <span class="built_in">get_bucket</span>(fragment_instance_id);</span><br><span class="line">    <span class="keyword">auto</span>&amp; receiver_map = _receiver_map[bucket];</span><br><span class="line">    <span class="function">std::lock_guard&lt;Mutex&gt; <span class="title">l</span><span class="params">(_lock[bucket])</span></span>;</span><br><span class="line">    <span class="keyword">auto</span> iter = receiver_map.<span class="built_in">find</span>(fragment_instance_id);</span><br><span class="line">    <span class="keyword">if</span> (iter == receiver_map.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        receiver_map.<span class="built_in">emplace</span>(fragment_instance_id, std::<span class="built_in">make_shared</span>&lt;RecvrMap&gt;());</span><br><span class="line">        iter = receiver_map.<span class="built_in">find</span>(fragment_instance_id);</span><br><span class="line">        _fragment_count += <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    iter-&gt;second-&gt;<span class="built_in">emplace</span>(dest_node_id, recvr);</span><br><span class="line">    _receiver_count += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> recvr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ExchangeNode-set-num-senders"><a href="#ExchangeNode-set-num-senders" class="headerlink" title="ExchangeNode::set_num_senders"></a>ExchangeNode::set_num_senders</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set senders of exchange nodes before pipeline build</span></span><br><span class="line">std::vector&lt;ExecNode*&gt; exch_nodes;</span><br><span class="line">plan-&gt;<span class="built_in">collect_nodes</span>(TPlanNodeType::EXCHANGE_NODE, &amp;exch_nodes);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span>* exch_node : exch_nodes) &#123;</span><br><span class="line">    <span class="type">int</span> num_senders = <span class="built_in">FindWithDefault</span>(params.per_exch_num_senders, exch_node-&gt;<span class="built_in">id</span>(), <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">down_cast</span>&lt;ExchangeNode*&gt;(exch_node)-&gt;<span class="built_in">set_num_senders</span>(num_senders);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="DataStreamRecvr"><a href="#DataStreamRecvr" class="headerlink" title="DataStreamRecvr"></a>DataStreamRecvr</h3><ul><li><p>is_merging 为 true 时，num_queues 为 num_senders，而 num_sender_per_queue 就是 1</p><p>  此时，_sender_queues 中有 num_queues 个 PipelineSenderQueue，每个 1 中只有一个 ChunkQueue。</p></li><li><p>is_merging 为 false 时，num_queue 为 1，而 num_sender_per_queue 为 num_senders</p><p>  此时，_sender_queues 中只有 1 个 PipelineSenderQueue，每个 PipelineSenderQueue 中有 dop 个 ChunkQueue。</p></li></ul><p>is_merging 只有在 Sort 时才会为 true，下面先视为 false。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">DataStreamRecvr::<span class="built_in">DataStreamRecvr</span>(DataStreamMgr* stream_mgr, RuntimeState* runtime_state,</span><br><span class="line">                                 <span class="type">const</span> RowDescriptor&amp; row_desc,</span><br><span class="line">                                 <span class="type">const</span> TUniqueId&amp; fragment_instance_id,</span><br><span class="line">                                 PlanNodeId dest_node_id, <span class="type">int</span> num_senders,</span><br><span class="line">                                 <span class="type">bool</span> is_merging, <span class="type">int</span> total_buffer_limit,</span><br><span class="line">                                 std::shared_ptr&lt;RuntimeProfile&gt; profile,</span><br><span class="line">                                 std::shared_ptr&lt;QueryStatisticsRecvr&gt; sub_plan_query_statistics_recvr,</span><br><span class="line">                                 <span class="type">bool</span> is_pipeline, <span class="type">int32_t</span> dop, <span class="type">bool</span> keep_order,</span><br><span class="line">                                 PassThroughChunkBuffer* pass_through_chunk_buffer)</span><br><span class="line">        : _mgr(stream_mgr),</span><br><span class="line">          _fragment_instance_id(fragment_instance_id),</span><br><span class="line">          _dest_node_id(dest_node_id),</span><br><span class="line">          _total_buffer_limit(total_buffer_limit),</span><br><span class="line">          _row_desc(row_desc),</span><br><span class="line">          _is_merging(is_merging),</span><br><span class="line">          _num_buffered_bytes(<span class="number">0</span>),</span><br><span class="line">          _profile(std::<span class="built_in">move</span>(profile)),</span><br><span class="line">          _instance_profile(runtime_state-&gt;<span class="built_in">runtime_profile_ptr</span>()),</span><br><span class="line">          _query_mem_tracker(runtime_state-&gt;<span class="built_in">query_mem_tracker_ptr</span>()),</span><br><span class="line">          _instance_mem_tracker(runtime_state-&gt;<span class="built_in">instance_mem_tracker_ptr</span>()),</span><br><span class="line">          _sub_plan_query_statistics_recvr(std::<span class="built_in">move</span>(sub_plan_query_statistics_recvr)),</span><br><span class="line">          _is_pipeline(is_pipeline),</span><br><span class="line">          _degree_of_parallelism(dop),</span><br><span class="line">          _keep_order(keep_order),</span><br><span class="line">          _pass_through_context(pass_through_chunk_buffer, fragment_instance_id, dest_node_id) &#123;</span><br><span class="line">    <span class="comment">// Create one queue per sender if is_merging is true.</span></span><br><span class="line">    <span class="type">int</span> num_queues = is_merging ? num_senders : <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> num_sender_per_queue = is_merging ? <span class="number">1</span> : num_senders;</span><br><span class="line">    _sender_queues.<span class="built_in">reserve</span>(num_queues);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_queues; ++i) &#123;</span><br><span class="line">        SenderQueue* queue = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="keyword">if</span> (_is_pipeline) &#123;</span><br><span class="line">            queue = _sender_queue_pool.<span class="built_in">add</span>(<span class="keyword">new</span> <span class="built_in">PipelineSenderQueue</span>(</span><br><span class="line">                                                <span class="keyword">this</span>,</span><br><span class="line">                                                num_sender_per_queue,</span><br><span class="line">                                                is_merging ? <span class="number">1</span> : dop));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//..</span></span><br><span class="line">        &#125;</span><br><span class="line">        _sender_queues.<span class="built_in">push_back</span>(queue);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Initialize the counters</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    _pass_through_context.<span class="built_in">init</span>();</span><br><span class="line">    <span class="keyword">if</span> (runtime_state-&gt;<span class="built_in">query_options</span>().__isset.transmission_encode_level) &#123;</span><br><span class="line">        _encode_level = runtime_state-&gt;<span class="built_in">query_options</span>().transmission_encode_level;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DataStreamRecvr::PipelineSenderQueue::<span class="built_in">PipelineSenderQueue</span>(</span><br><span class="line">    DataStreamRecvr* parent_recvr, <span class="type">int32_t</span> num_senders, <span class="type">int32_t</span> degree_of_parallism)</span><br><span class="line">        : <span class="built_in">SenderQueue</span>(parent_recvr),</span><br><span class="line">          _num_remaining_senders(num_senders),</span><br><span class="line">          _chunk_queues(degree_of_parallism),</span><br><span class="line">          _chunk_queue_states(degree_of_parallism) &#123;</span><br><span class="line">    <span class="keyword">if</span> (parent_recvr-&gt;_is_merging) &#123;</span><br><span class="line">        _producer_token = std::<span class="built_in">make_unique</span>&lt;ChunkQueue::<span class="type">producer_token_t</span>&gt;(_chunk_queues[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="transmit-chunk"><a href="#transmit-chunk" class="headerlink" title="transmit_chunk"></a>transmit_chunk</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DataStreamMgr::transmit_chunk</span><span class="params">(<span class="type">const</span> PTransmitChunkParams&amp; request, ::google::protobuf::Closure** done)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> PUniqueId&amp; finst_id = request.<span class="built_in">finst_id</span>();</span><br><span class="line">    TUniqueId t_finst_id;</span><br><span class="line">    t_finst_id.hi = finst_id.<span class="built_in">hi</span>();</span><br><span class="line">    t_finst_id.lo = finst_id.<span class="built_in">lo</span>();</span><br><span class="line">    std::shared_ptr&lt;DataStreamRecvr&gt; recvr = <span class="built_in">find_recvr</span>(t_finst_id, request.<span class="built_in">node_id</span>());</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(recvr == <span class="literal">nullptr</span>, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (request.<span class="built_in">has_query_statistics</span>()) &#123;</span><br><span class="line">        recvr-&gt;<span class="built_in">add_sub_plan_statistics</span>(request.<span class="built_in">query_statistics</span>(), request.<span class="built_in">sender_id</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">DeferOp <span class="title">op</span><span class="params">([&amp;eos, &amp;recvr, &amp;request]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">if</span> (request.eos()) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">            recvr-&gt;remove_sender(request.sender_id(), request.be_number());</span></span></span><br><span class="line"><span class="params"><span class="function">        &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (request.<span class="built_in">chunks_size</span>() &gt; <span class="number">0</span> || request.<span class="built_in">use_pass_through</span>()) &#123;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(recvr-&gt;<span class="built_in">add_chunks</span>(request, request.<span class="built_in">eos</span>() ? <span class="literal">nullptr</span> : done));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="DataStreamRecvr-add-chunks"><a href="#DataStreamRecvr-add-chunks" class="headerlink" title="DataStreamRecvr::add_chunks"></a>DataStreamRecvr::add_chunks</h4><p>BE 在接受到 <em>transmit_chunk</em> RPC 后，就会调用 DataStreamRecvr::add_chunks 函数来处理请求。先基于 sender_id 将定位到具体的 SenderQueue，即 _sender_queues[sender_id]</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DataStreamRecvr::add_chunks</span><span class="params">(<span class="type">const</span> PTransmitChunkParams&amp; request, ::google::protobuf::Closure** done)</span> </span>&#123;</span><br><span class="line">    MemTracker* prev_tracker = tls_thread_status.<span class="built_in">set_mem_tracker</span>(_instance_mem_tracker.<span class="built_in">get</span>());</span><br><span class="line">    <span class="function">DeferOp <span class="title">op</span><span class="params">([&amp;] &#123; tls_thread_status.set_mem_tracker(prev_tracker); &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">SCOPED_TIMER</span>(_process_total_timer);</span><br><span class="line">    <span class="built_in">SCOPED_TIMER</span>(_sender_total_timer);</span><br><span class="line">    <span class="built_in">COUNTER_UPDATE</span>(_request_received_counter, <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> sender_id = _is_merging ? request.<span class="built_in">sender_id</span>() : <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// Add all batches to the same queue if _is_merging is false.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_keep_order) &#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(_is_pipeline);</span><br><span class="line">        <span class="keyword">return</span> _sender_queues[sender_id]-&gt;<span class="built_in">add_chunks_and_keep_order</span>(request, done);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> _sender_queues[sender_id]-&gt;<span class="built_in">add_chunks</span>(request, done);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="PipelineSenderQueue-add-chunks"><a href="#PipelineSenderQueue-add-chunks" class="headerlink" title="PipelineSenderQueue::add_chunks"></a>PipelineSenderQueue::add_chunks</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">bool</span> keep_order&gt;</span><br><span class="line">Status DataStreamRecvr::PipelineSenderQueue::<span class="built_in">add_chunks</span>(<span class="type">const</span> PTransmitChunkParams&amp; request,</span><br><span class="line">                                                        ::google::protobuf::Closure** done) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">bool</span> use_pass_through = request.<span class="built_in">use_pass_through</span>();</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(_is_cancelled || _num_remaining_senders &lt;= <span class="number">0</span>, Status::<span class="built_in">OK</span>());</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(<span class="built_in">try_to_build_chunk_meta</span>(request));</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> total_chunk_bytes = <span class="number">0</span>;</span><br><span class="line">    _is_pipeline_level_shuffle = </span><br><span class="line">        request.<span class="built_in">has_is_pipeline_level_shuffle</span>() &amp;&amp; request.<span class="built_in">is_pipeline_level_shuffle</span>();</span><br><span class="line"></span><br><span class="line">    ChunkList chunks = use_pass_through</span><br><span class="line">        ? <span class="built_in">get_chunks_from_pass_through</span>(request.<span class="built_in">sender_id</span>(), total_chunk_bytes)</span><br><span class="line">        : <span class="built_in">get_chunks_from_request</span>&lt;<span class="literal">false</span>&gt;(request, total_chunk_bytes)));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">RETURN_IF</span>(_is_cancelled, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// remove the short-circuited chunks</span></span><br><span class="line">    <span class="keyword">if</span> (_is_pipeline_level_shuffle) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> iter = chunks.<span class="built_in">begin</span>(); iter != chunks.<span class="built_in">end</span>();) &#123;</span><br><span class="line">            <span class="keyword">if</span> (_chunk_queue_states[iter-&gt;driver_sequence].is_short_circuited) &#123;</span><br><span class="line">                total_chunk_bytes -= iter-&gt;chunk_bytes;</span><br><span class="line">                chunks.<span class="built_in">erase</span>(iter++);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            iter++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!chunks.<span class="built_in">empty</span>() &amp;&amp; done != <span class="literal">nullptr</span> &amp;&amp; _recvr-&gt;<span class="built_in">exceeds_limit</span>(total_chunk_bytes)) &#123;</span><br><span class="line">        chunks.<span class="built_in">back</span>().closure = *done;</span><br><span class="line">        chunks.<span class="built_in">back</span>().queue_enter_time = <span class="built_in">MonotonicNanos</span>();</span><br><span class="line">        *done = <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp;&amp; chunk : chunks) &#123;</span><br><span class="line">        <span class="type">int</span> driver_seq = _is_pipeline_level_shuffle ? chunk.driver_sequence : <span class="number">0</span>;</span><br><span class="line">        <span class="type">size_t</span> chunk_bytes = chunk.chunk_bytes;</span><br><span class="line">        <span class="keyword">auto</span>* closure = chunk.closure;</span><br><span class="line">        _chunk_queues[driver_seq].<span class="built_in">enqueue</span>(std::<span class="built_in">move</span>(chunk));</span><br><span class="line">        _chunk_queue_states[driver_seq].blocked_closure_num += closure != <span class="literal">nullptr</span>;</span><br><span class="line">        _total_chunks++;</span><br><span class="line">        <span class="keyword">if</span> (_chunk_queue_states[driver_seq].is_short_circuited) &#123;</span><br><span class="line">            <span class="built_in">short_circuit</span>(driver_seq);</span><br><span class="line">        &#125;</span><br><span class="line">        _recvr-&gt;_num_buffered_bytes += chunk_bytes;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="pull-chunk"><a href="#pull-chunk" class="headerlink" title="pull_chunk"></a>pull_chunk</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;vectorized::ChunkPtr&gt; <span class="title">ExchangeSourceOperator::pull_chunk</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> chunk = std::<span class="built_in">make_unique</span>&lt;vectorized::Chunk&gt;();</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_stream_recvr-&gt;<span class="built_in">get_chunk_for_pipeline</span>(&amp;chunk, _driver_sequence));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">eval_runtime_bloom_filters</span>(chunk.<span class="built_in">get</span>());</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">move</span>(chunk);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="DataStreamRecvr-get-chunk-for-pipeline"><a href="#DataStreamRecvr-get-chunk-for-pipeline" class="headerlink" title="DataStreamRecvr::get_chunk_for_pipeline"></a>DataStreamRecvr::get_chunk_for_pipeline</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DataStreamRecvr::get_chunk_for_pipeline</span><span class="params">(std::unique_ptr&lt;vectorized::Chunk&gt;* chunk,</span></span></span><br><span class="line"><span class="params"><span class="function">                                               <span class="type">const</span> <span class="type">int32_t</span> driver_sequence)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(!_is_merging);</span><br><span class="line">    <span class="built_in">DCHECK_EQ</span>(_sender_queues.<span class="built_in">size</span>(), <span class="number">1</span>);</span><br><span class="line">    vectorized::Chunk* tmp_chunk = <span class="literal">nullptr</span>;</span><br><span class="line">    Status status = _sender_queues[<span class="number">0</span>]-&gt;<span class="built_in">get_chunk</span>(&amp;tmp_chunk, driver_sequence);</span><br><span class="line">    chunk-&gt;<span class="built_in">reset</span>(tmp_chunk);</span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="PipelineSenderQueue-get-chunk"><a href="#PipelineSenderQueue-get-chunk" class="headerlink" title="PipelineSenderQueue::get_chunk"></a>PipelineSenderQueue::get_chunk</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">Status DataStreamRecvr::PipelineSenderQueue::<span class="built_in">get_chunk</span>(vectorized::Chunk** chunk, <span class="type">const</span> <span class="type">int32_t</span> driver_sequence) &#123;</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(_is_cancelled, Status::<span class="built_in">Cancelled</span>(<span class="string">&quot;Cancelled&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="type">size_t</span> index = _is_pipeline_level_shuffle ? driver_sequence : <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">auto</span>&amp; chunk_queue = _chunk_queues[index];</span><br><span class="line">    <span class="keyword">auto</span>&amp; chunk_queue_state = _chunk_queue_states[index];</span><br><span class="line"></span><br><span class="line">    ChunkItem item;</span><br><span class="line">    <span class="keyword">if</span> (!chunk_queue.<span class="built_in">try_dequeue</span>(item)) &#123;</span><br><span class="line">        chunk_queue_state.unpluging = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">DeferOp <span class="title">defer_op</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">auto</span>* closure = item.closure;</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">if</span> (closure != <span class="literal">nullptr</span>) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">            MemTracker* prev_tracker = tls_thread_status.set_mem_tracker(</span></span></span><br><span class="line"><span class="params"><span class="function">                ExecEnv::GetInstance()-&gt;process_mem_tracker());</span></span></span><br><span class="line"><span class="params"><span class="function">            DeferOp op([&amp;] &#123; tls_thread_status.set_mem_tracker(prev_tracker); &#125;);</span></span></span><br><span class="line"><span class="params"><span class="function">            closure-&gt;Run();</span></span></span><br><span class="line"><span class="params"><span class="function">            chunk_queue_state.blocked_closure_num--;</span></span></span><br><span class="line"><span class="params"><span class="function">        &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (item.chunk_ptr == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        ChunkUniquePtr chunk_ptr = std::<span class="built_in">make_unique</span>&lt;vectorized::Chunk&gt;();</span><br><span class="line">        faststring uncompressed_buffer;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_deserialize_chunk(item.pchunk, chunk_ptr.<span class="built_in">get</span>(), &amp;uncompressed_buffer));</span><br><span class="line">        *chunk = chunk_ptr.<span class="built_in">release</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        *chunk = item.chunk_ptr.<span class="built_in">release</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    _total_chunks--;</span><br><span class="line">    _recvr-&gt;_num_buffered_bytes -= item.chunk_bytes;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://www.zhihu.com/collection/853861081">StarRocks Exchange 算子源码解析</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ExchangeSourceOperator&quot;&gt;&lt;a href=&quot;#ExchangeSourceOperator&quot; class=&quot;headerlink&quot; title=&quot;ExchangeSourceOperator&quot;&gt;&lt;/a&gt;ExchangeSourceOperat</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>MPP: ExchangeSinkOperator 详解 RPC 有序性保证和数据 shuffle</title>
    <link href="https://szza.github.io/2023/08/01/Pipeline/ExchangeNode_1/"/>
    <id>https://szza.github.io/2023/08/01/Pipeline/ExchangeNode_1/</id>
    <published>2023-08-01T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:10.445Z</updated>
    
    <content type="html"><![CDATA[<p>前面几篇所述都单个 FragmentInstance 内的执行流。StarRocks 是 MPP 架构，并发执行多个 FragmentInstances。因此就涉及到多个 FragmentInstances 之间数据通信，FragmentExecutor 在构造每个 PipelineDriver 时，最后一个 Operator 肯定是 Sink。如果 Sink 的对端是另一个 FragmentInstance，则 Sink 会是 ExchangeSinkOperator，接受端使用 ExchangeSourceOperator 来接受数据。</p><blockquote><p>后续还有个优化版本 LocalExchangeSinkOperator、LocalExchangeSourceOperator</p></blockquote><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-FragmentInstance-1.svg?raw=true" alt="Pipeline-FragmentInstance-1"></p><p>StarRocks 输入输出的 Buffer 都是所有 PipelineDrivers 共享的，这也符合论文 <a href="https://szza.github.io/2023/04/02/Paper/Morsel-Driven-Parallelism">Morsel-Driven-Parallelism</a> 所述的设计。</p><p>同样，ExchangeSinkOperator 中的 SinkBuffer 也是在所有 PipelineDrivers 间共享。从构造 ExchangeSinkOperatorFactory 到 ExchangeSinkOperator 如下。</p><h2 id="create-exchange-sink"><a href="#create-exchange-sink" class="headerlink" title="create_exchange_sink"></a>create_exchange_sink</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">std::shared_ptr&lt;ExchangeSinkOperatorFactory&gt; _create_exchange_sink_operator(</span><br><span class="line">    PipelineBuilderContext* context, <span class="type">const</span> TDataStreamSink&amp; stream_sink,</span><br><span class="line">    <span class="type">const</span> DataStreamSender* sender, <span class="type">size_t</span> dop) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> fragment_ctx = context-&gt;<span class="built_in">fragment_context</span>();</span><br><span class="line">    <span class="type">bool</span> is_dest_merge = stream_sink.__isset.is_merge &amp;&amp; stream_sink.is_merge;</span><br><span class="line">    TPartitionType part_type = sender-&gt;<span class="built_in">get_partition_type</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> is_pipeline_level_shuffle = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">int32_t</span> dest_dop = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span> (part_type == TPartitionType::HASH_PARTITIONED ||</span><br><span class="line">        part_type == TPartitionType::BUCKET_SHUFFLE_HASH_PARTITIONED) &#123;</span><br><span class="line">        dest_dop = stream_sink.dest_dop;</span><br><span class="line">        is_pipeline_level_shuffle = <span class="literal">true</span>;</span><br><span class="line">        <span class="built_in">DCHECK_GT</span>(dest_dop, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 1. 构造 sink_buffer </span></span><br><span class="line">    std::shared_ptr&lt;SinkBuffer&gt; sink_buffer = std::<span class="built_in">make_shared</span>&lt;SinkBuffer&gt;(</span><br><span class="line">        fragment_ctx, sender-&gt;<span class="built_in">destinations</span>(), is_dest_merge, dop);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;ExchangeSinkOperatorFactory&gt;(</span><br><span class="line">            context-&gt;<span class="built_in">next_operator_id</span>(), stream_sink.dest_node_id,</span><br><span class="line">            sink_buffer, <span class="comment">// 传递给 ExchangeSinkOperatorFactory</span></span><br><span class="line">            sender-&gt;<span class="built_in">get_partition_type</span>(),</span><br><span class="line">            sender-&gt;<span class="built_in">destinations</span>(), is_pipeline_level_shuffle,</span><br><span class="line">            dest_dop, sender-&gt;<span class="built_in">sender_id</span>(),</span><br><span class="line">            sender-&gt;<span class="built_in">get_dest_node_id</span>(), sender-&gt;<span class="built_in">get_partition_exprs</span>(),</span><br><span class="line">            !is_dest_merge &amp;&amp; sender-&gt;<span class="built_in">get_enable_exchange_pass_through</span>(),</span><br><span class="line">            sender-&gt;<span class="built_in">get_enable_exchange_perf</span>() &amp;&amp; !context-&gt;has_aggregation,</span><br><span class="line">            fragment_ctx, sender-&gt;<span class="built_in">output_columns</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 ExchangeSinkOperator</span></span><br><span class="line"><span class="function">OperatorPtr <span class="title">ExchangeSinkOperatorFactory::create</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int32_t</span> degree_of_parallelism, <span class="type">int32_t</span> driver_sequence)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;ExchangeSinkOperator&gt;(</span><br><span class="line">            <span class="keyword">this</span>, _id, _plan_node_id,</span><br><span class="line">            driver_sequence,  <span class="comment">// 具体的 PipelineDriver</span></span><br><span class="line">            _buffer,          <span class="comment">// 传递给所有的 PipelineDrivers</span></span><br><span class="line">            _part_type,</span><br><span class="line">            _destinations,</span><br><span class="line">            _is_pipeline_level_shuffle,</span><br><span class="line">            _num_shuffles_per_channel,</span><br><span class="line">            _sender_id, _dest_node_id,</span><br><span class="line">            _partition_expr_ctxs,</span><br><span class="line">            _enable_exchange_pass_through,</span><br><span class="line">            _enable_exchange_perf,</span><br><span class="line">            _fragment_ctx,</span><br><span class="line">            _output_columns);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h2><p>ExchangeSinkOperator 构造函数中的 <em>_destinations</em> 表示所有的对端，即 Sink 的接受者，每一个 _destinations[i] 都被封装为一个 ExchangeSinkOperator::Channel 对象，并通过 Channel 对象向对端发送 RPC，但是内部通过 SinkBuffer::_try_to_send_rpc 函数发出去的。</p><p>此外，Channel 对象还可以判断是否与对端在同一个BE进程中，如果在一个 BE 进程中，则不用 PRC 跨进程通信，转而使用共享内存的方式。</p><p>Channel 构造函数如下：</p><ul><li>_brpc_dest_addr: 对端 BE 的 bRPC 监听地址 ipport</li><li>_fragment_instance_id: 对端 BE 上的 fragment_instance</li><li>_dest_node_id: 接受数据的 ExchangeSourceOperator 所属的 ExchangeNode id</li></ul><p>这三个信息就可以唯一确定谁接受消息。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Channel</span>(ExchangeSinkOperator* parent, </span><br><span class="line">    <span class="type">const</span> TNetworkAddress&amp; brpc_dest,</span><br><span class="line">    <span class="type">const</span> TUniqueId&amp; fragment_instance_id,</span><br><span class="line">    PlanNodeId dest_node_id, </span><br><span class="line">    <span class="type">int32_t</span> num_shuffles,</span><br><span class="line">    <span class="type">bool</span> enable_exchange_pass_through,</span><br><span class="line">    <span class="type">bool</span> enable_exchange_perf,</span><br><span class="line">    PassThroughChunkBuffer* pass_through_chunk_buffer)</span><br><span class="line">    : _parent(parent),</span><br><span class="line">      _brpc_dest_addr(brpc_dest),</span><br><span class="line">      _fragment_instance_id(fragment_instance_id),</span><br><span class="line">      _dest_node_id(dest_node_id),</span><br><span class="line">      _enable_exchange_pass_through(enable_exchange_pass_through),</span><br><span class="line">      _enable_exchange_perf(enable_exchange_perf),</span><br><span class="line">      _pass_through_context(pass_through_chunk_buffer,</span><br><span class="line">                            fragment_instance_id,</span><br><span class="line">                            dest_node_id),</span><br><span class="line">      _chunks(num_shuffles) &#123; &#125;</span><br></pre></td></tr></table></figure><h3 id="Channel-is-local"><a href="#Channel-is-local" class="headerlink" title="Channel::is_local"></a>Channel::is_local</h3><p>is_local 函数用于判断和对端是否在 同一个 BE 进程中。此外，_enable_exchange_pass_through 是由于 FE 传递过来的参数，可以由用户更改是否开启 PassThrough 模式，默认值为 true。若 _enable_exchange_pass_through 为 true，且和对端在一个 BE 进程中，则 _use_pass_through 为 true，后续数据传输就不走 RPC 了，而是通过 <strong>_pass_through_context</strong> 在两个 FragmentInstance 之间传递数据。</p><blockquote><p>这个设计就是通过共享内存在多线程间传递数据</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> ExchangeSinkOperator::Channel::<span class="built_in">is_local</span>() &#123;</span><br><span class="line">    <span class="keyword">if</span> (BackendOptions::<span class="built_in">get_localhost</span>() != _brpc_dest_addr.hostname) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (config::brpc_port != _brpc_dest_addr.port) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> ExchangeSinkOperator::Channel::_check_use_pass_through() &#123;</span><br><span class="line">    <span class="keyword">if</span> (!_enable_exchange_pass_through) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">is_local</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> ExchangeSinkOperator::Channel::_prepare_pass_through() &#123;</span><br><span class="line">    _pass_through_context.<span class="built_in">init</span>();</span><br><span class="line">    _use_pass_through = _check_use_pass_through();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="PTransmitChunkParams"><a href="#PTransmitChunkParams" class="headerlink" title="PTransmitChunkParams"></a>PTransmitChunkParams</h3><p>在讲解 Channel::send_one_chunk 发送消息之前，先说下传输数据的 proto 格式。如下 PTransmitChunkParams 就是数据传输协议。</p><ul><li>eos: 表示本次 PRC 是否是最后一个 chunk</li><li>sequence: 本次 RPC 请求的序号</li><li>chunks: RPC 是批量发送模式，chunks 中包含了多次 RPC 数据</li><li>use_pass_through: false 时对端从 chunks 中反序列得到数据，true 时从共享内存中获得数据</li><li>is_pipeline_level_shuffle: 其赋值见上文的 _create_exchange_sink_operator 函数</li><li>driver_sequences: 在 <em>is_pipeline_level_shuffle</em> 为 true 时生效。此时和 driver_sequences_size 和 chunks_size 一样，每个 chunk[i] 直接写入 driver_sequences[i] 对应的 PipelineDriver 的输入源。</li></ul><p>全部字段如下。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">PTransmitChunkParams</span> &#123;</span><br><span class="line">    <span class="comment">// non-change member</span></span><br><span class="line">    <span class="keyword">optional</span> PUniqueId finst_id = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">optional</span> <span class="type">int32</span> node_id = <span class="number">2</span>;</span><br><span class="line">    <span class="comment">// Id of this fragment in its role as a sender.</span></span><br><span class="line">    <span class="keyword">optional</span> <span class="type">int32</span> sender_id = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">optional</span> <span class="type">int32</span> be_number = <span class="number">4</span>;</span><br><span class="line">    <span class="comment">// If set to true, indicates that no more row batches will be sent</span></span><br><span class="line">    <span class="comment">// for this dest_node_id.</span></span><br><span class="line">    <span class="keyword">optional</span> <span class="type">bool</span> eos = <span class="number">5</span>;</span><br><span class="line">    <span class="comment">// RPC sequence number for the send channel.</span></span><br><span class="line">    <span class="comment">// Sever will check this number to see if some packet has lost.</span></span><br><span class="line">    <span class="keyword">optional</span> <span class="type">int64</span> sequence = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The protobuf data structure for column chunk.</span></span><br><span class="line">    <span class="keyword">repeated</span> ChunkPB chunks = <span class="number">7</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Some statistics for the runing query.</span></span><br><span class="line">    <span class="keyword">optional</span> PQueryStatistics query_statistics = <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">optional</span> <span class="type">bool</span> use_pass_through = <span class="number">9</span> [default = <span class="literal">false</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Whether enable pipeline level shuffle.</span></span><br><span class="line">    <span class="keyword">optional</span> <span class="type">bool</span> is_pipeline_level_shuffle = <span class="number">10</span> [default = <span class="literal">false</span>];</span><br><span class="line">    <span class="comment">// Driver sequences of pipeline level shuffle.</span></span><br><span class="line">    <span class="keyword">repeated</span> <span class="type">int32</span> driver_sequences = <span class="number">11</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Channel-send-one-chunk"><a href="#Channel-send-one-chunk" class="headerlink" title="Channel::send_one_chunk"></a>Channel::send_one_chunk</h3><p>Channel 有三种方式发送RPC 数据:</p><ul><li>send_chunk_request 是直接发送 RPC 请求，</li><li>send_one_chunk 是批量发送 RPC 数据，超过大小阈值或者最后一个 RPC 才会发送</li><li>add_rows_selective 也是批量模式，不过会先对输入 Chunk 进行筛选后再调用 send_one_chunk。</li></ul><p>这里以 send_one_chunk 为例。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">Status ExchangeSinkOperator::Channel::<span class="built_in">send_one_chunk</span>(RuntimeState* state,</span><br><span class="line">                                                     <span class="type">const</span> Chunk* chunk, </span><br><span class="line">                                                     <span class="type">int32_t</span> driver_sequence,</span><br><span class="line">                                                     <span class="type">bool</span> eos, </span><br><span class="line">                                                     <span class="type">bool</span>* is_real_sent) &#123;</span><br><span class="line"></span><br><span class="line">    *is_real_sent = <span class="literal">false</span>;</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(_ignore_local_data &amp;&amp; !eos, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_chunk_request == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        _chunk_request = std::<span class="built_in">make_shared</span>&lt;PTransmitChunkParams&gt;();</span><br><span class="line">        _chunk_request-&gt;<span class="built_in">set_node_id</span>(_dest_node_id);</span><br><span class="line">        _chunk_request-&gt;<span class="built_in">set_sender_id</span>(_parent-&gt;_sender_id);</span><br><span class="line">        _chunk_request-&gt;<span class="built_in">set_be_number</span>(_parent-&gt;_be_number);</span><br><span class="line">        <span class="keyword">if</span> (_parent-&gt;_is_pipeline_level_shuffle) &#123;</span><br><span class="line">            _chunk_request-&gt;<span class="built_in">set_is_pipeline_level_shuffle</span>(<span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. batch 数据</span></span><br><span class="line">    <span class="keyword">if</span> (chunk != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_use_pass_through) &#123;</span><br><span class="line">            <span class="comment">// 1.1 使用共享内存方式传递数据</span></span><br><span class="line">            <span class="comment">//     发送端没有序列化，对端接受到数据也不用反序列化</span></span><br><span class="line">            <span class="type">size_t</span> chunk_size = </span><br><span class="line">                serde::ProtobufChunkSerde::<span class="built_in">max_serialized_size</span>(*chunk);</span><br><span class="line">            <span class="built_in">TRY_CATCH_BAD_ALLOC</span>(_pass_through_context.<span class="built_in">append_chunk</span>(</span><br><span class="line">                        _parent-&gt;_sender_id, chunk, chunk_size,</span><br><span class="line">                        _parent-&gt;_is_pipeline_level_shuffle </span><br><span class="line">                         ? driver_sequence : <span class="number">-1</span>));</span><br><span class="line">            _current_request_bytes += chunk_size;</span><br><span class="line">            <span class="built_in">COUNTER_UPDATE</span>(_parent-&gt;_bytes_pass_through_counter, chunk_size);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 1.2 RPC 方式通信，则攒批</span></span><br><span class="line">            <span class="keyword">if</span> (_parent-&gt;_is_pipeline_level_shuffle) &#123;</span><br><span class="line">                _chunk_request-&gt;<span class="built_in">add_driver_sequences</span>(driver_sequence);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 数据序列化后添加到 pchunk 中</span></span><br><span class="line">            <span class="keyword">auto</span> pchunk = _chunk_request-&gt;<span class="built_in">add_chunks</span>();</span><br><span class="line">            <span class="built_in">TRY_CATCH_BAD_ALLOC</span>(<span class="built_in">RETURN_IF_ERROR</span>(_parent-&gt;<span class="built_in">serialize_chunk</span>(</span><br><span class="line">                chunk, pchunk, &amp;_is_first_chunk)));</span><br><span class="line">            _current_request_bytes += pchunk-&gt;<span class="built_in">data</span>().<span class="built_in">size</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 真正的发送消息</span></span><br><span class="line">    <span class="comment">//    条件是: batched 的数据超过内存限制，或者是最后一条数据（eos 为 true）</span></span><br><span class="line">    <span class="keyword">if</span> (_current_request_bytes &gt; config::max_transmit_batched_bytes || eos) &#123;</span><br><span class="line">        _chunk_request-&gt;<span class="built_in">set_eos</span>(eos);</span><br><span class="line">        _chunk_request-&gt;<span class="built_in">set_use_pass_through</span>(_use_pass_through);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">auto</span> delta_statistic = state-&gt;<span class="built_in">intermediate_query_statistic</span>()) &#123;</span><br><span class="line">            delta_statistic-&gt;<span class="built_in">to_pb</span>(_chunk_request-&gt;<span class="built_in">mutable_query_statistics</span>());</span><br><span class="line">        &#125;</span><br><span class="line">        butil::IOBuf attachment;</span><br><span class="line">        <span class="type">int64_t</span> attachment_physical_bytes = </span><br><span class="line">            _parent-&gt;<span class="built_in">construct_brpc_attachment</span>(_chunk_request, attachment);</span><br><span class="line">        TransmitChunkInfo info &#123;_fragment_instance_id, _brpc_stub,</span><br><span class="line">                                 std::<span class="built_in">move</span>(_chunk_request),</span><br><span class="line">                                 attachment, attachment_physical_bytes,</span><br><span class="line">                                 _brpc_dest_addr&#125;;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_parent-&gt;_buffer-&gt;<span class="built_in">add_request</span>(info));</span><br><span class="line">        _current_request_bytes = <span class="number">0</span>;</span><br><span class="line">        *is_real_sent = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="SinkBuffer-add-request"><a href="#SinkBuffer-add-request" class="headerlink" title="SinkBuffer::add_request"></a>SinkBuffer::add_request</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">SinkBuffer::add_request</span><span class="params">(TransmitChunkInfo&amp; request)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(_is_finishing, Status::<span class="built_in">OK</span>());</span><br><span class="line">    <span class="keyword">if</span> (!request.attachment.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        _bytes_enqueued += request.attachment.<span class="built_in">size</span>();</span><br><span class="line">        _request_enqueued++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">auto</span>&amp; instance_id = request.fragment_instance_id;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_try_to_send_rpc(instance_id, </span><br><span class="line">            [&amp;]() &#123; _buffers[instance_id.lo].<span class="built_in">push</span>(request); &#125;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="SinkBuffer-try-to-send-rpc"><a href="#SinkBuffer-try-to-send-rpc" class="headerlink" title="SinkBuffer::_try_to_send_rpc"></a>SinkBuffer::_try_to_send_rpc</h3><p>SinkBuffer 设计要稍微复杂点，因为要考虑顺序。下面将 _try_to_send_rpc 函数分解为4部分来剖析细节。完整代码见 <a href="https://github.com/StarRocks/starrocks/blob/fbfb7ed80e284d349694adbb57d3f1c643e46e58/be/src/exec/pipeline/exchange/sink_buffer.cpp#L257C1-L257C1">_try_to_send_rpc</a>。</p><h4 id="Part1-callback"><a href="#Part1-callback" class="headerlink" title="Part1: callback"></a>Part1: callback</h4><p>_try_to_send_rpc 函数第二个参数 <em>pre_works_cb</em> 会在发送 RPC 之前执行，比如上面 add_request 函数传入的 cb 是将新增的 RPC 请求 request 添加到 _buffers[instance_id.lo] 中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status SinkBuffer::_try_to_send_rpc(<span class="type">const</span> TUniqueId&amp; instance_id,</span><br><span class="line">                                    <span class="type">const</span> std::function&lt;<span class="built_in">void</span>()&gt;&amp; pre_works_cb) &#123;</span><br><span class="line">    <span class="comment">//! 注意：这里是有 mutex</span></span><br><span class="line">    <span class="function">std::lock_guard&lt;Mutex&gt; <span class="title">l</span><span class="params">(*_mutexes[instance_id.lo])</span></span>;</span><br><span class="line">    <span class="built_in">pre_works_cb</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function">DeferOp <span class="title">decrease_defer</span><span class="params">([<span class="keyword">this</span>]() &#123; --_num_sending_rpc; &#125;)</span></span>;</span><br><span class="line">    ++_num_sending_rpc;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Part2-限流"><a href="#Part2-限流" class="headerlink" title="Part2: 限流"></a>Part2: 限流</h4><p>_buffers[instance_id] 中存储的是所有待发送给 instance_id 的 RPCs。在发送 RPC 之前会先检测下是否需要限流:  </p><ul><li><p>_is_dest_merge 为 true，此时需要保证发送顺序性<br>  比如 SQL 中包含 ORDER BY，TOPN 等操作时，要求输出结果有序。在 FragmentInstances 之间交换数据时，需要发送端和接收端一起保证顺序性，实现方式类似 TCP 滑动窗口。</p><p>  如图，_request_seqs[instance_id] 记录的是给 instance_id 实例已发送 RPC 的最大序号，_max_continuous_acked_seqs[instance_id] 记录的是 instance_id 已回应 RPC 的最大连续序号，差值是不连续的窗口大小 <em>discontinuous_acked_window_size</em></p><p>  此时限流的标准是该 window_size 不能超过阈值 <em>config::pipeline_sink_brpc_dop</em>（默认值 64），<strong>防止乱序数据太多</strong>。</p><p>  <img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-ExchangeNode-2.svg?raw=true" alt="StarRocks/Pipeline-ExchangeNode-2"></p></li><li><p>_is_dest_merge 为 false，此时不需要保证发送的顺序性</p><p> _num_in_flight_rpcs[instance_id] 记录的是已发送给 instance_id 但尚未收到 response 的 PRC 数量，该数据量不能超过阈值 config::pipeline_sink_brpc_dop（默认值 64），如果超过则暂停发送，<strong>防止对端处理不过来</strong>。</p></li></ul><p>限流代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Status SinkBuffer::_try_to_send_rpc(<span class="type">const</span> TUniqueId&amp; instance_id,</span><br><span class="line">                                    <span class="type">const</span> std::function&lt;<span class="built_in">void</span>()&gt;&amp; pre_works_cb) &#123;</span><br><span class="line">  <span class="comment">//...above code</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// part2</span></span><br><span class="line">  <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(_is_finishing, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 限流</span></span><br><span class="line">    <span class="type">int64_t</span> too_much_rpc = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (_is_dest_merge) &#123;</span><br><span class="line">      <span class="type">int64_t</span> discontinuous_acked_window_size =</span><br><span class="line">        _request_seqs[instance_id.lo] - _max_continuous_acked_seqs[instance_id.lo];</span><br><span class="line">      too_much_brpc_process = </span><br><span class="line">        discontinuous_acked_window_size &gt;= config::pipeline_sink_brpc_dop;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      too_much_brpc_process = </span><br><span class="line">        _num_in_flight_rpcs[instance_id.lo] &gt;= config::pipeline_sink_brpc_dop;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">RETURN_IF</span> (buffer.<span class="built_in">empty</span>() || too_much_rpc, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br></pre></td></tr></table></figure><h4 id="Part3-Order"><a href="#Part3-Order" class="headerlink" title="Part3: Order"></a>Part3: Order</h4><p>顺序性保证，要求发送过程如下:</p><ul><li>必须等收到第一个 RPC 的 response 之后，后续 RPCs 才能发送出去，保证基准不会出问题</li><li>最后一个 RPC（即 eos 为 true 的 RPC）必须是最后一个发送给对端，用于通知对端后续不会再有数据发送，让对端做好 finishing 操作</li><li>中间 RPCs 可以一定程度的乱序，但是通过 _max_continuous_acked_seqs 来维护总体的有序性</li></ul><p>所以，一共有两处需要等待（need_wait 为 true):</p><ol><li><p>中间的 RPCs 需要等待收到第一个 RPC 的 response</p><p> _num_finished_rpcs[instance_id] &#x3D;&#x3D; 0 和 _num_in_flight_rpcs[instance_id] &gt; 0 就能说明还没收到第一个 RPC 的 response。</p></li><li><p>最后一个 RPC 需要等待前面所有的 RPCs 都都收到 response</p><p>_num_remaining_eos 和 _num_sinkers 可以用来确定当前 RPC 是否为发送给 instance_id 实例的最后一个 EOS RPC. 它们在构造函数中赋值如下：</p> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; dest : destinations) &#123;</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span>&amp; instance_id = dest.fragment_instance_id;</span><br><span class="line">  _num_sinkers[instance_id] = _num_sinkers; </span><br><span class="line">  <span class="comment">//..</span></span><br><span class="line">&#125;</span><br><span class="line">_num_remaining_eos = _num_sinkers.<span class="built_in">size</span>() * num_sinkers;</span><br></pre></td></tr></table></figure><p> _num_sinkers 在 <em>_create_exchange_sink_operator</em> 函数中被赋值为 dop，如果 _num_sinkers[instance_id] 为 0，则表示当前 Sink 给 instance_id 对应的 FragmentInstance 实例的所有 PipelineDrivers ExchangeSourceOperator 该发送的数据都发送了，此时就需要给 RPC request 中的 eos 标志设为 true，告知对端不会再有数据了（即 ExchangeSourceOperator 即将进入 OperatorStage::FINISHING 阶段）。</p></li></ol><p>Part3 就是做上述两处检测。当 <em>need_wait</em> 为 true，当前 RPC 不会被发送给对端，即从 _buffer[instance_id] 中取出的 RPC request 不会被 pop 出去。</p><blockquote><p>DeferOp 是基于 RAII 设计的类，在 DeferOp 对象离开作用域时调用传入的回调函数。</p></blockquote><p>核心代码及其注释如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">Status SinkBuffer::_try_to_send_rpc(<span class="type">const</span> TUniqueId&amp; instance_id,</span><br><span class="line">                                    <span class="type">const</span> std::function&lt;<span class="built_in">void</span>()&gt;&amp; pre_works_cb) &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="comment">// 2. 提取待发送的 RPC request</span></span><br><span class="line">        TransmitChunkInfo&amp; request = buffer.<span class="built_in">front</span>();</span><br><span class="line">        <span class="type">bool</span> need_wait = <span class="literal">false</span>;</span><br><span class="line">        <span class="function">DeferOp <span class="title">pop_defer</span><span class="params">([&amp;need_wait, &amp;buffer, mem_tracker = _mem_tracker]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="comment">// 如果需要等待</span></span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">if</span> (need_wait) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="keyword">return</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">            &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="comment">// 能正常发送给对端</span></span></span></span><br><span class="line"><span class="params"><span class="function">            SCOPED_THREAD_LOCAL_MEM_TRACKER_SETTER(mem_tracker);</span></span></span><br><span class="line"><span class="params"><span class="function">            buffer.pop();</span></span></span><br><span class="line"><span class="params"><span class="function">        &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.1 CHECK: 必须等待第一个 add_request 对应的 RPC 返回，才能继续发送</span></span><br><span class="line">        <span class="keyword">if</span> (_num_finished_rpcs[instance_id.lo] == <span class="number">0</span> </span><br><span class="line">            &amp;&amp; _num_in_flight_rpcs[instance_id.lo] &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            need_wait = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.2 CHECK: 最后一个 RPC，必须是最后一个发送，且只发送一次</span></span><br><span class="line">        <span class="keyword">auto</span>&amp; params = request.params;</span><br><span class="line">        <span class="keyword">if</span> (params-&gt;<span class="built_in">eos</span>()) &#123;</span><br><span class="line">            <span class="function">DeferOp <span class="title">eos_defer</span><span class="params">([<span class="keyword">this</span>, &amp;instance_id, &amp;need_wait]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="keyword">if</span> (need_wait) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">                    <span class="keyword">return</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">                &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="keyword">if</span> (--_num_remaining_eos == <span class="number">0</span>) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">                    <span class="comment">// 所有对端的 FragmentInstances 该发送的数据</span></span></span></span><br><span class="line"><span class="params"><span class="function">                    <span class="comment">// 都已发送完</span></span></span></span><br><span class="line"><span class="params"><span class="function">                    _is_finishing = <span class="literal">true</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">                &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="comment">// 给 instance_id 的一个 PipelineDriver 发送完数据</span></span></span></span><br><span class="line"><span class="params"><span class="function">                --_num_sinkers[instance_id.lo];</span></span></span><br><span class="line"><span class="params"><span class="function">            &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// instance_id 对应的 FragmentInstance 中</span></span><br><span class="line">            <span class="comment">// 还有 PipelineDrviers 还没有接受到完整的数据</span></span><br><span class="line">            <span class="keyword">if</span> (_num_sinkers[instance_id.lo] &gt; <span class="number">1</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (params-&gt;<span class="built_in">chunks_size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                params-&gt;<span class="built_in">set_eos</span>(<span class="literal">false</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 仍有尚未收到 response 的 RPCs</span></span><br><span class="line">                <span class="comment">// 则需要 wait</span></span><br><span class="line">                <span class="keyword">if</span> (_num_in_flight_rpcs[instance_id.lo] &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    need_wait = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">                &#125; </span><br><span class="line">                <span class="comment">// else-branch: _num_in_flight_rpcs[instance_id] 为 0</span></span><br><span class="line">                <span class="comment">// 此时 params-&gt;eos() 就是 true</span></span><br><span class="line">                <span class="comment">// 表示这个是该 FragmentInstance 最后一个 RPC 请求</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//... </span></span><br><span class="line">    &#125; <span class="comment">// while</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Part4-Send-RPC"><a href="#Part4-Send-RPC" class="headerlink" title="Part4: Send RPC"></a>Part4: Send RPC</h4><p>通过了上面的校验，下面就是真正发送 RPC request 的代码。 Part4 核心部分是设置 RPC 回调函数。</p><blockquote><p>bRPC 异步回调相关知识可以参考：<a href="https://github.com/apache/brpc/blob/master/docs/cn/client.md">异步访问</a></p></blockquote><p>由于是异步发送 RPC 消息，因此要设置回调函数来处理返回结果。 通过 DisposableClosure 继承 google::protobuf::Closure 传递给 bRPC。在 RPC 返回时执行 <em>Closure::Run</em> 函数。这里就是根据 RPC 发送结果即 ctnl.Failed() 来判断调用哪个 callback。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DisposableClosure</span> : <span class="keyword">public</span> google::protobuf::Closure &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> FailedFunc = std::function&lt;<span class="built_in">void</span>(<span class="type">const</span> C&amp;)&gt;;</span><br><span class="line">    <span class="keyword">using</span> SuccessFunc = std::function&lt;<span class="built_in">void</span>(<span class="type">const</span> C&amp;, <span class="type">const</span> T&amp;)&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">DisposableClosure</span>(<span class="type">const</span> C&amp; ctx) : _ctx(ctx) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">addFailedHandler</span><span class="params">(FailedFunc fn)</span> </span>&#123; _failed_handler = std::<span class="built_in">move</span>(fn); &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">addSuccessHandler</span><span class="params">(SuccessFunc fn)</span> </span>&#123; _success_handler = fn; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Run</span><span class="params">()</span> <span class="keyword">noexcept</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">      <span class="comment">// 自我释放内存</span></span><br><span class="line">      <span class="function">std::unique_ptr&lt;DisposableClosure&gt; <span class="title">self_guard</span><span class="params">(<span class="keyword">this</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (cntl.<span class="built_in">Failed</span>()) &#123;</span><br><span class="line">          _failed_handler(_ctx);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          _success_handler(_ctx, result);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    brpc::Controller cntl;</span><br><span class="line">    T result;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">const</span> C _ctx;</span><br><span class="line">    FailedFunc _failed_handler;</span><br><span class="line">    SuccessFunc _success_handler;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>两个回调函数如下:</p><ol><li><p>SuccessFunc</p><p> ctnl.Failed() 为 false 只表明 RPC 请求确实发送给对端了，但是对端接受到 RPC 后真正的处理结果由 result.status() 来表征。如果对端处理失败，则取消当前 FragmentInstance，进而由 GloablDriverExecutor 取消整个 query。否则就 <strong>递归</strong> 执行 _try_to_send_rpc 函数，不断地从 _buffer[instance_id] 中取出 RPC request 发送给 instance_id 对应的 FragmentInstance。此时传入的 pre_work_cb 中有 <em>_process_send_window</em> 函数，这是用来处理滑动窗口的。</p><p> SuccessFunc 代码如下。 </p> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">success_cb = [<span class="keyword">this</span>](<span class="type">const</span> ClosureContext&amp; ctx, </span><br><span class="line">                    <span class="type">const</span> PTransmitChunkResult&amp; result) &#123;</span><br><span class="line">  Status <span class="built_in">status</span>(result.<span class="built_in">status</span>());</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// 更新记录</span></span><br><span class="line">    <span class="function">std::lock_guard&lt;Mutex&gt; <span class="title">l</span><span class="params">(*_mutexes[ctx.instance_id.lo])</span></span>;</span><br><span class="line">    ++_num_finished_rpcs[ctx.instance_id.lo];</span><br><span class="line">    --_num_in_flight_rpcs[ctx.instance_id.lo];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">    <span class="comment">// 对端处理失败，则取消当前 FragmentInstance</span></span><br><span class="line">    _is_finishing = <span class="literal">true</span>;</span><br><span class="line">    _fragment_ctx-&gt;<span class="built_in">cancel</span>(status);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 对端处理成功，则递归发送 RPC 给对端</span></span><br><span class="line">    _try_to_send_rpc(ctx.instance_id, [&amp;]() &#123;</span><br><span class="line">                _update_network_time(ctx.instance_id,</span><br><span class="line">                                     ctx.send_timestamp,</span><br><span class="line">                                     result.<span class="built_in">receiver_post_process_time</span>());</span><br><span class="line">                _process_send_window(ctx.instance_id, ctx.sequence); &#125;); </span><br><span class="line">  &#125;</span><br><span class="line">  --_total_in_flight_rpc;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li><li><p>FailedFunc</p><p> 如果因为网络等问题 RPC 无法发送给对端，则取消当前 FragmentInstance 的 PipelineDriver，并更新相关状态。</p> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">failed_cb = [<span class="keyword">this</span>](<span class="type">const</span> ClosureContext&amp; ctx) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// 算子完成</span></span><br><span class="line">  _is_finishing = <span class="literal">true</span>;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// 更新记录</span></span><br><span class="line">    <span class="function">std::lock_guard&lt;Mutex&gt; <span class="title">l</span><span class="params">(*_mutexes[ctx.instance_id.lo])</span></span>;</span><br><span class="line">    ++_num_finished_rpcs[ctx.instance_id.lo];</span><br><span class="line">    --_num_in_flight_rpcs[ctx.instance_id.lo];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 取消当前 FragmentInstance 的 PipelineDrivers</span></span><br><span class="line">  std::string err_msg = fmt::format(</span><br><span class="line">     <span class="string">&quot;transmit chunk rpc failed:&#123;&#125;&quot;</span>, <span class="built_in">print_id</span>(ctx.instance_id));</span><br><span class="line">  _fragment_ctx-&gt;<span class="built_in">cancel</span>(Status::<span class="built_in">InternalError</span>(err_msg));</span><br><span class="line"></span><br><span class="line">  --_total_in_flight_rpc;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ol><p>RPC 回调函数 closure 设置完毕，就可以将 RPC 真正发送出去了，这个由 <em>_send_rpc</em> 函数完成。完成代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Status SinkBuffer::_try_to_send_rpc(<span class="type">const</span> TUniqueId&amp; instance_id,</span><br><span class="line">                                    <span class="type">const</span> std::function&lt;<span class="built_in">void</span>()&gt;&amp; pre_works_cb) &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="comment">//... above code</span></span><br><span class="line"></span><br><span class="line">        params-&gt;<span class="built_in">mutable_finst_id</span>()-&gt;<span class="built_in">CopyFrom</span>(_instance_id2finst_id[instance_id.lo]);</span><br><span class="line">        params-&gt;<span class="built_in">set_sequence</span>(++_request_seqs[instance_id.lo]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!request.attachment.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            _bytes_sent += request.attachment.<span class="built_in">size</span>();</span><br><span class="line">            _request_sent++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 callback</span></span><br><span class="line">        <span class="keyword">auto</span>* closure = <span class="keyword">new</span> <span class="built_in">DisposableClosure</span>&lt;PTransmitChunkResult, ClosureContext&gt;(</span><br><span class="line">                &#123;instance_id, params-&gt;<span class="built_in">sequence</span>(), <span class="built_in">MonotonicNanos</span>()&#125;);</span><br><span class="line">        <span class="keyword">if</span> (_first_send_time == <span class="number">-1</span>) &#123;</span><br><span class="line">            _first_send_time = <span class="built_in">MonotonicNanos</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        closure-&gt;<span class="built_in">addFailedHandler</span>(failed_cb);</span><br><span class="line">        closure-&gt;<span class="built_in">addSuccessHandler</span>(success_cb);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 在发送 RPC 前，递增变量</span></span><br><span class="line">        ++_total_in_flight_rpc;</span><br><span class="line">        ++_num_in_flight_rpcs[instance_id.lo];</span><br><span class="line"></span><br><span class="line">        _mem_tracker-&gt;<span class="built_in">release</span>(request.attachment_physical_bytes);</span><br><span class="line">        ExecEnv::<span class="built_in">GetInstance</span>()-&gt;<span class="built_in">process_mem_tracker</span>()-&gt;<span class="built_in">consume</span>(</span><br><span class="line">            request.attachment_physical_bytes);</span><br><span class="line"></span><br><span class="line">        closure-&gt;cntl.<span class="built_in">Reset</span>();</span><br><span class="line">        closure-&gt;cntl.<span class="built_in">set_timeout_ms</span>(_brpc_timeout_ms);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">bthread_self</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> _send_rpc(closure, request);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">SCOPED_THREAD_LOCAL_MEM_TRACKER_SETTER</span>(<span class="literal">nullptr</span>);</span><br><span class="line">            <span class="keyword">return</span> _send_rpc(closure, request);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="process-send-window"><a href="#process-send-window" class="headerlink" title="_process_send_window"></a>_process_send_window</h4><p>sequence 是本次成功的 RPC，下面用 sequence 来更新滑动窗口的逻辑也是比较简洁的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> SinkBuffer::_process_send_window(<span class="type">const</span> TUniqueId&amp; instance_id, <span class="type">const</span> <span class="type">int64_t</span> sequence) &#123;</span><br><span class="line">    <span class="comment">// Both sender side and receiver side can tolerate disorder of tranmission</span></span><br><span class="line">    <span class="comment">// if receiver side is not ExchangeMergeSortSourceOperator</span></span><br><span class="line">    <span class="keyword">if</span> (!_is_dest_merge) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span>&amp; seqs = _discontinuous_acked_seqs[instance_id.lo];</span><br><span class="line">    seqs.<span class="built_in">insert</span>(sequence);</span><br><span class="line">    <span class="keyword">auto</span>&amp; max_continuous_acked_seq = _max_continuous_acked_seqs[instance_id.lo];</span><br><span class="line">    std::unordered_set&lt;<span class="type">int64_t</span>&gt;::iterator it;</span><br><span class="line">    <span class="keyword">while</span> ((it = seqs.<span class="built_in">find</span>(max_continuous_acked_seq + <span class="number">1</span>)) != seqs.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        seqs.<span class="built_in">erase</span>(it);</span><br><span class="line">        ++max_continuous_acked_seq;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="SinkBuffer-send-rpc"><a href="#SinkBuffer-send-rpc" class="headerlink" title="SinkBuffer::_send_rpc"></a>SinkBuffer::_send_rpc</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Status SinkBuffer::_send_rpc(DisposableClosure&lt;PTransmitChunkResult,</span><br><span class="line">                             ClosureContext&gt;* closure,</span><br><span class="line">                             <span class="type">const</span> TransmitChunkInfo&amp; request) &#123;</span><br><span class="line">    <span class="keyword">auto</span> expected_iobuf_size = request.attachment.<span class="built_in">size</span>() </span><br><span class="line">                             + request.params-&gt;<span class="built_in">ByteSizeLong</span>() </span><br><span class="line">                             + <span class="built_in">sizeof</span>(<span class="type">size_t</span>) * <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">UNLIKELY</span>(expected_iobuf_size &gt; _rpc_http_min_size)) &#123;</span><br><span class="line">        butil::IOBuf iobuf;</span><br><span class="line">        <span class="function">butil::IOBufAsZeroCopyOutputStream <span class="title">wrapper</span><span class="params">(&amp;iobuf)</span></span>;</span><br><span class="line">        request.params-&gt;<span class="built_in">SerializeToZeroCopyStream</span>(&amp;wrapper);</span><br><span class="line">        <span class="comment">// append params to iobuf</span></span><br><span class="line">        <span class="type">size_t</span> params_size = iobuf.<span class="built_in">size</span>();</span><br><span class="line">        closure-&gt;cntl.<span class="built_in">request_attachment</span>().<span class="built_in">append</span>(</span><br><span class="line">            &amp;params_size, <span class="built_in">sizeof</span>(<span class="type">size_t</span>));</span><br><span class="line">        closure-&gt;cntl.<span class="built_in">request_attachment</span>().<span class="built_in">append</span>(iobuf);</span><br><span class="line">        <span class="comment">// append attachment</span></span><br><span class="line">        <span class="type">size_t</span> attachment_size = request.attachment.<span class="built_in">size</span>();</span><br><span class="line">        closure-&gt;cntl.<span class="built_in">request_attachment</span>().<span class="built_in">append</span>(</span><br><span class="line">            &amp;attachment_size, <span class="built_in">sizeof</span>(<span class="type">size_t</span>));</span><br><span class="line">        closure-&gt;cntl.<span class="built_in">request_attachment</span>().<span class="built_in">append</span>(request.attachment);</span><br><span class="line">        closure-&gt;cntl.<span class="built_in">http_request</span>().<span class="built_in">set_content_type</span>(<span class="string">&quot;application/proto&quot;</span>);</span><br><span class="line">        <span class="keyword">auto</span> res = BrpcStubCache::<span class="built_in">create_http_stub</span>(request.brpc_addr);</span><br><span class="line">        <span class="built_in">RETURN_IF</span>(!res.<span class="built_in">ok</span>(), res.<span class="built_in">status</span>());</span><br><span class="line">        <span class="comment">// 异步 RPC </span></span><br><span class="line">        res.<span class="built_in">value</span>()-&gt;<span class="built_in">transmit_chunk_via_http</span>(</span><br><span class="line">            &amp;closure-&gt;cntl, <span class="literal">NULL</span>, &amp;closure-&gt;result, closure);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 异步 RPC</span></span><br><span class="line">        closure-&gt;cntl.<span class="built_in">request_attachment</span>().<span class="built_in">append</span>(request.attachment);</span><br><span class="line">        request.brpc_stub-&gt;<span class="built_in">transmit_chunk</span>(</span><br><span class="line">            &amp;closure-&gt;cntl, request.params.<span class="built_in">get</span>(), &amp;closure-&gt;result, closure);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="push-chunk"><a href="#push-chunk" class="headerlink" title="push_chunk"></a>push_chunk</h2><p>上面讲解了 Channel 是如何 batched RPCs 到真正发送 RPC 给对端。下面来讲解 ExchangeSinkOperator::push_chunk。</p><p>_output_columns 是当前 Sink 需要输出的列，当前一个 Operator 将数据 Chunk 推向 ExchangeSinkOperator 时，需要从 chunk 中提取出 _output_columns 中所必须的列数据即可，得到的即 send_chunk。</p><h3 id="TPartitionType-UNPARTITIONED"><a href="#TPartitionType-UNPARTITIONED" class="headerlink" title="TPartitionType::UNPARTITIONED"></a>TPartitionType::UNPARTITIONED</h3><p>当传输数据方式是 TPartitionType::UNPARTITIONED，即广播模式，给每个对端都发送一份完整的数据，如下图所示。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-ExchangeNode-3.svg?raw=true" alt="StarRocks/Pipeline-ExchangeNode-3"></p><p>即遍历 _channels 给所有的 Channel[idx] 发送数据。也正如前文所述，如果 Channel::use_pass_through() 为 true，则可以走共享内存模式，而不用 RPC 通信。反之，则需要先序列化再进行 RPC 发送。</p><blockquote><p>Channel 发现 ExchangeSinkOperator::_is_pipeline_level_shuffle 为 false 时，在 Channel::send_one_chunk 函数中不会处理 DEFAULT_DRIVER_SEQUENCE。</p></blockquote><p>代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ExchangeSinkOperator::push_chunk</span><span class="params">(RuntimeState* state, </span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line">    <span class="type">uint16_t</span> num_rows = chunk-&gt;<span class="built_in">num_rows</span>();</span><br><span class="line">    <span class="built_in">RETURN_IF</span>(num_rows == <span class="number">0</span>, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">    vectorized::Chunk temp_chunk;</span><br><span class="line">    vectorized::Chunk* send_chunk = chunk.<span class="built_in">get</span>();</span><br><span class="line">    <span class="keyword">if</span> (!_output_columns.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> cid : _output_columns) &#123;</span><br><span class="line">            temp_chunk.<span class="built_in">append_column</span>(chunk-&gt;<span class="built_in">get_column_by_slot_id</span>(cid), cid);</span><br><span class="line">        &#125;</span><br><span class="line">        send_chunk = &amp;temp_chunk;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_part_type == TPartitionType::UNPARTITIONED || _num_shuffles == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_chunk_request == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            _chunk_request = std::<span class="built_in">make_shared</span>&lt;PTransmitChunkParams&gt;();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        std::vector&lt;<span class="type">int</span>&gt; not_pass_through_channles;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> idx : _channel_indices) &#123;</span><br><span class="line">            <span class="keyword">if</span> (_channels[idx]-&gt;<span class="built_in">use_pass_through</span>()) &#123;</span><br><span class="line">               <span class="comment">// pass_through 模式，直接传递数据</span></span><br><span class="line">                <span class="built_in">RETURN_IF_ERROR</span>(_channels[idx]-&gt;<span class="built_in">send_one_chunk</span>(</span><br><span class="line">                    state, send_chunk, DEFAULT_DRIVER_SEQUENCE, <span class="literal">false</span>));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//记录需要爱 RPC 通信的对端</span></span><br><span class="line">                not_pass_through_channles.<span class="built_in">emplace_back</span>(idx);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!not_pass_through_channles.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="comment">// 1. create a new chunk PB to serialize</span></span><br><span class="line">            ChunkPB* pchunk = _chunk_request-&gt;<span class="built_in">add_chunks</span>();</span><br><span class="line">            <span class="comment">// 2. 将输入的 send_chunk 序列化到 pchunk 中</span></span><br><span class="line">            <span class="built_in">TRY_CATCH_BAD_ALLOC</span>(<span class="built_in">RETURN_IF_ERROR</span>(<span class="built_in">serialize_chunk</span>(</span><br><span class="line">                send_chunk, pchunk, &amp;_is_first_chunk, _channels.<span class="built_in">size</span>())));</span><br><span class="line">            _current_request_bytes += pchunk-&gt;<span class="built_in">data</span>().<span class="built_in">size</span>();</span><br><span class="line">            <span class="comment">// 3. 如果请求的字节数超过限制，再通过 Channel 发送</span></span><br><span class="line">            <span class="keyword">if</span> (_current_request_bytes &gt; config::max_transmit_batched_bytes) &#123;</span><br><span class="line">                butil::IOBuf attachment;</span><br><span class="line">                <span class="type">int64_t</span> attachment_physical_bytes =</span><br><span class="line">                     <span class="built_in">construct_brpc_attachment</span>(_chunk_request, attachment);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">auto</span> idx : not_pass_through_channles) &#123;</span><br><span class="line">                    <span class="built_in">RETURN_IF_ERROR</span>(_channels[idx]-&gt;<span class="built_in">send_chunk_request</span>(</span><br><span class="line">                        state, </span><br><span class="line">                        std::<span class="built_in">make_shared</span>&lt;PTransmitChunkParams&gt;(*_chunk_request),</span><br><span class="line">                        attachment, </span><br><span class="line">                        attachment_physical_bytes));</span><br><span class="line">                &#125;</span><br><span class="line">                _current_request_bytes = <span class="number">0</span>;</span><br><span class="line">                _chunk_request.<span class="built_in">reset</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="TPartitionType-RANDOM"><a href="#TPartitionType-RANDOM" class="headerlink" title="TPartitionType::RANDOM"></a>TPartitionType::RANDOM</h3><p>TPartitionType::RANDOM 的数据分发策略是 Round-robin，每次调用 ExchangeSinkOperator::push_chunk 都挑选一个同进程的 FragmentInstance 作为对端。如下图所示。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-ExchangeNode-4.svg?raw=true" alt="StarRocks/Pipeline-ExchangeNode-4"></p><p>_curr_random_channel_idx 指示当前发送给哪个 Local Channels。见代码注释。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ExchangeSinkOperator::push_chunk</span><span class="params">(RuntimeState* state, <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="keyword">if</span> (_part_type == TPartitionType::UNPARTITIONED || _num_shuffles == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">//...</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (_part_type == TPartitionType::RANDOM) &#123;</span><br><span class="line">        std::vector&lt;Channel*&gt; local_channels;</span><br><span class="line">        <span class="comment">// 1. 挑选处同进程的 FragmenInstance</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; channel : _channels) &#123;</span><br><span class="line">            <span class="keyword">if</span> (channel-&gt;<span class="built_in">is_local</span>()) &#123;</span><br><span class="line">                local_channels.<span class="built_in">emplace_back</span>(channel);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 没有 Local Channel，才选择 Remote Channel</span></span><br><span class="line">        <span class="keyword">if</span> (local_channels.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            local_channels = _channels;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">auto</span>&amp; channel = local_channels[_curr_random_channel_idx];</span><br><span class="line">        <span class="type">bool</span> real_sent = <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// 2. 发送</span></span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(channel-&gt;<span class="built_in">send_one_chunk</span>(</span><br><span class="line">                state, send_chunk,</span><br><span class="line">                DEFAULT_DRIVER_SEQUENCE,</span><br><span class="line">                <span class="literal">false</span>, &amp;real_sent));</span><br><span class="line">        <span class="comment">// 3. 只有在 RPC 真的发送出去了，才会切换到下一个 FragmentInstance</span></span><br><span class="line">        <span class="keyword">if</span> (real_sent) &#123;</span><br><span class="line">            _curr_random_channel_idx = </span><br><span class="line">                (_curr_random_channel_idx + <span class="number">1</span>) % local_channels.<span class="built_in">size</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="comment">// else if</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="TPartitionType-BUCKET-SHUFFLE-HASH-PARTITIONED"><a href="#TPartitionType-BUCKET-SHUFFLE-HASH-PARTITIONED" class="headerlink" title="TPartitionType::BUCKET_SHUFFLE&#x2F;HASH_PARTITIONED"></a>TPartitionType::BUCKET_SHUFFLE&#x2F;HASH_PARTITIONED</h3><p>这两种数据分发策略要复杂点，二者本质不同点在于使用的 Hash 函数。如下示意图。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-ExchangeNode-5.svg?raw=true" alt="StarRocks/Pipeline-ExchangeNode-5"></p><h4 id="hash-values"><a href="#hash-values" class="headerlink" title="hash_values"></a>hash_values</h4><p>Shuffler::exchange_shuffle 函数用于将 chunk 的每一行都分发到具体的分区 {instance_id, driver_seq} 中。参数 hash_values 是对 chunk 中每一行的 join-key 进行 hash 值。BUCKET_SHUFFLE_HASH_PARTITIONED 和 HASH_PARTITIONED 两种策略根本区别也在于这里。</p><blockquote><p>这里的分区列的 “partition” 和建分区表时的 “partition” 不是一个含义。这里的是对端 {instnace_id, driver_seq} 处理的数据源。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ExchangeSinkOperator::push_chunk</span><span class="params">(RuntimeState* state, </span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> </span>&#123;</span><br><span class="line"> <span class="comment">//...</span></span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span> (_part_type == TPartitionType::HASH_PARTITIONED ||</span><br><span class="line">          _part_type == TPartitionType::BUCKET_SHUFFLE_HASH_PARTITIONED) &#123;</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">//1. 计算 hash 的分区列</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; _partitions_columns.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">        <span class="built_in">ASSIGN_OR_RETURN</span>(</span><br><span class="line">          _partitions_columns[i], _partition_expr_ctxs[i]-&gt;<span class="built_in">evaluate</span>(chunk.<span class="built_in">get</span>()));</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 2. 为每个分区列计算 hash 值</span></span><br><span class="line">      <span class="keyword">if</span> (_part_type == TPartitionType::HASH_PARTITIONED) &#123;</span><br><span class="line">        _hash_values.<span class="built_in">assign</span>(num_rows, HashUtil::FNV_SEED);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> vectorized::ColumnPtr&amp; column : _partitions_columns) &#123;</span><br><span class="line">           column-&gt;<span class="built_in">fnv_hash</span>(&amp;_hash_values[<span class="number">0</span>], <span class="number">0</span>, num_rows);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 当 join-key 和分桶键一样</span></span><br><span class="line">        <span class="comment">// 则和分桶键使用一样的 Hash 函数</span></span><br><span class="line">        _hash_values.<span class="built_in">assign</span>(num_rows, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> vectorized::ColumnPtr&amp; column : _partitions_columns) &#123;</span><br><span class="line">           column-&gt;<span class="built_in">crc32_hash</span>(&amp;_hash_values[<span class="number">0</span>], <span class="number">0</span>, num_rows);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//..</span></span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br></pre></td></tr></table></figure><h4 id="exchange-shuffle"><a href="#exchange-shuffle" class="headerlink" title="exchange_shuffle"></a>exchange_shuffle</h4><p>TPartitionType::UNPARTITIONED 和 TPartitionType::RANDOM 两种策略的 shuffle 粒度是 chunk ，即可以直接将整个 chunk 发送给 FragmentInstance。而 (BUCKET_SHUFFLE_)HASH_PARTITIONED 策略，shuffle 的粒度是 row，需要把一个 chunk 分发到不同 {FragmentInstance, PipelineDriver} 中。 </p><p>因此，可以把 (channl_id, driver_sequence) 视为一个坐标，那么 exchange_shuffle 函数就是将 chunk 的 num_rows 行数据均匀分布在 channels_size * num_shuffles_per_channel 的平面上。其中 num_shuffles_per_channel 表征的是 dop。</p><p>shuffle 策略实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">bool</span> two_level_shuffle, <span class="keyword">typename</span> ReduceOp&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">exchange_shuffle</span><span class="params">(std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; shuffle_channel_ids, </span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; hash_values,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">size_t</span> num_rows)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; num_rows; ++i) &#123;</span><br><span class="line">        <span class="type">size_t</span> channel_id = <span class="built_in">ReduceOp</span>()(hash_values[i], _num_channels);</span><br><span class="line">        <span class="type">size_t</span> shuffle_id;</span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(!two_level_shuffle)</span> </span>&#123;</span><br><span class="line">            shuffle_id = channel_id;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 基于均匀分布将 hash_values 映射到 [0, _num_shuffles_per_channel) 区间</span></span><br><span class="line">            <span class="type">uint32_t</span> driver_sequence = <span class="built_in">ReduceOp</span>()(</span><br><span class="line">                HashUtil::<span class="built_in">xorshift32</span>(hash_values[i]), _num_shuffles_per_channel);</span><br><span class="line">            shuffle_id = </span><br><span class="line">                channel_id * _num_shuffles_per_channel + driver_sequence;</span><br><span class="line">        &#125;</span><br><span class="line">        shuffle_channel_ids[i] = shuffle_id;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>得到 chunk 每一行的 hash_values 后，并基于 Shuffler::exchange_shuffle 函数得到每一行所属的分区，结果存储于 _shuffle_channel_ids。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (_part_type == TPartitionType::HASH_PARTITIONED ||</span><br><span class="line">         _part_type == TPartitionType::BUCKET_SHUFFLE_HASH_PARTITIONED) &#123;</span><br><span class="line">   &#123;</span><br><span class="line">     <span class="comment">// 3. Compute row indexes for each channel&#x27;s each shuffle</span></span><br><span class="line">     _shuffler-&gt;<span class="built_in">exchange_shuffle</span>(_shuffle_channel_ids, _hash_values, num_rows);</span><br><span class="line"></span><br><span class="line">     <span class="comment">//...</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="channel-row-idx-start-points"><a href="#channel-row-idx-start-points" class="headerlink" title="channel_row_idx_start_points"></a>channel_row_idx_start_points</h4><p>接下来就是 shuffle 之后的处理流程：_row_indexes 将 chunk 中所有发往同一个分区的 row_ids 连续存储在一起，并用 _channel_row_idx_start_points 记录每个分区起始偏移量。如下示意图:</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-ExchangeNode-6.svg?raw=true" alt="StarRocks/Pipeline-ExchangeNode-6"></p><p>这个流程分为如下三个 for-loop:</p><ol><li><p>计算每个分区的行数</p><p> _shuffle_channel_ids[i] 表征 partitions[i]，那么第一个 for-loop 计算完，_channel_row_idx_start_points[i] 即表征 chunk 落在 partitions[i] 的行数。</p><p> 比如有三个分区，分别是 9, 10, 11行，经过第一个 for-loop，start_points 中存储的值就是:</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">9 10 11</span><br></pre></td></tr></table></figure></li><li><p>计算每个分区最后的位置</p><p>上述例子，经过第二个 for-loop 后， start_points 中存储的值就是:</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">9 19 30</span><br></pre></td></tr></table></figure></li><li><p>将同一个分区的在chunk中的行号记录在 _row_indexes，同时将 _channel_row_idx_start_points 更新到每个分区的起始位置。</p><p> 此时 _row_indexes 和 start_points 的值变更结果如下:</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">_row_indexes[0:8] = partition0</span><br><span class="line">_row_indexes[9:18] = partition1</span><br><span class="line">_row_indexes[19:29] = partition2</span><br><span class="line"></span><br><span class="line">start_points[0] = 0</span><br><span class="line">start_points[1] = 9</span><br><span class="line">start_points[2] = 19</span><br></pre></td></tr></table></figure></li></ol><p>三个 for-loop 的完成代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span> (_part_type == TPartitionType::HASH_PARTITIONED ||</span><br><span class="line">          _part_type == TPartitionType::BUCKET_SHUFFLE_HASH_PARTITIONED) &#123;</span><br><span class="line">  &#123;</span><br><span class="line">      <span class="comment">// _num_shuffles = _channels.size() * _num_shuffles_per_channel</span></span><br><span class="line">      _channel_row_idx_start_points.<span class="built_in">assign</span>(_num_shuffles + <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">      <span class="comment">//4.1 </span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; num_rows; ++i) &#123;</span><br><span class="line">          _channel_row_idx_start_points[_shuffle_channel_ids[i]]++;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 4.2</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">1</span>; i &lt;= _num_shuffles; ++i) &#123;</span><br><span class="line">          _channel_row_idx_start_points[i] += _channel_row_idx_start_points[i - <span class="number">1</span>];</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 4.3</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int32_t</span> i = num_rows - <span class="number">1</span>; i &gt;= <span class="number">0</span>; --i) &#123;</span><br><span class="line">          _row_indexes[_channel_row_idx_start_points[_shuffle_channel_ids[i]] - <span class="number">1</span>] = i;</span><br><span class="line">          _channel_row_idx_start_points[_shuffle_channel_ids[i]]--;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="add-rows-selective"><a href="#add-rows-selective" class="headerlink" title="add_rows_selective"></a>add_rows_selective</h4><p>上面四步对chunk完成了分区，并将结果记录在 _row_indexes 和 _start_points 中，最后一步就是将所有分区数据发送出去，只需要遍历 (_channel_indices, _num_shuffles_per_channel) 二维区间，再使用 Channel::add_rows_selective 函数发送数据，没啥可说，</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span> (_part_type == TPartitionType::HASH_PARTITIONED ||</span><br><span class="line">          _part_type == TPartitionType::BUCKET_SHUFFLE_HASH_PARTITIONED) &#123;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// above code</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int32_t</span> channel_id : _channel_indices) &#123;</span><br><span class="line">      <span class="keyword">if</span> (_channels[channel_id]-&gt;<span class="built_in">get_fragment_instance_id</span>().lo == <span class="number">-1</span>) &#123;</span><br><span class="line">          <span class="comment">// dest bucket is no used, continue</span></span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; _num_shuffles_per_channel; ++i) &#123;</span><br><span class="line">          <span class="type">int</span> shuffle_id = channel_id * _num_shuffles_per_channel + i;</span><br><span class="line">          <span class="type">int</span> driver_sequence = _driver_sequence_per_shuffle[shuffle_id];</span><br><span class="line"></span><br><span class="line">          <span class="type">size_t</span> from = _channel_row_idx_start_points[shuffle_id];</span><br><span class="line">          <span class="type">size_t</span> size = _channel_row_idx_start_points[shuffle_id + <span class="number">1</span>] - from;</span><br><span class="line">          <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">              <span class="comment">// no data for this channel continue;</span></span><br><span class="line">              <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="built_in">RETURN_IF_ERROR</span>(_channels[channel_id]-&gt;<span class="built_in">add_rows_selective</span>(send_chunk,         </span><br><span class="line">                                                                    driver_sequence, </span><br><span class="line">                                                                    _row_indexes.<span class="built_in">data</span>(), </span><br><span class="line">                                                                    from, size,</span><br><span class="line">                                                                    state));</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://www.zhihu.com/collection/853861081">StarRocks Exchange 算子源码解析</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前面几篇所述都单个 FragmentInstance 内的执行流。StarRocks 是 MPP 架构，并发执行多个 FragmentInstances。因此就涉及到多个 FragmentInstances 之间数据通信，FragmentExecutor 在构造每个 Pip</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>FragmentInsance: 物理计划执行实例</title>
    <link href="https://szza.github.io/2023/07/31/Pipeline/FragmentInstance/"/>
    <id>https://szza.github.io/2023/07/31/Pipeline/FragmentInstance/</id>
    <published>2023-07-31T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:16.028Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要阐述 BE 节点从接受 FE 执行计划到构建 PipelineDriver 并提交给 GlobalDriverExecutor 的过程。</p><p>每个 Query 在 StarRocks-FE 生成的物理计划（Physical Plan）后会被拆分为 PlanFragment 来实现 MPP，而 FragmentInstance 是 PlanFragment 的执行实例。简而言之，Query 最终是由多个 BE 节点上的 FragmentInstances 执行的，一个 FragmentInstance 对应着BE 节点上的 FragmentExecutor。</p><blockquote><p>概念理解可以参考 <a href="https://zhuanlan.zhihu.com/p/573181686">技术内幕 | StarRocks Pipeline 执行框架（上）</a>。</p></blockquote><h2 id="PInternalServiceImplBase"><a href="#PInternalServiceImplBase" class="headerlink" title="PInternalServiceImplBase"></a>PInternalServiceImplBase</h2><h4 id="exec-plan-fragment-by-pipeline"><a href="#exec-plan-fragment-by-pipeline" class="headerlink" title="_exec_plan_fragment_by_pipeline"></a>_exec_plan_fragment_by_pipeline</h4><p>开启了 Pipeline 引擎后，最终都是调用 _exec_plan_fragment_by_pipeline 函数来执行 FragmentInstance，内部主要由 pipeline::FragmentExecutor 完成，一共就两个操作：</p><ol><li><p>FragmentExecutor::prepare</p><p>将 FE 传递过来的 FragmentInstance 反序列化生成物理执行计划，即 ExecNode-Tree，然后 ExecNode 的子类（比如 OlapScanNode，HashJoinNode, ExchangeNode等）需要实现 <strong>ExecNode::decompose_to_pipeline</strong> 函数，通过 decompose_to_pipeline 函数将所有的 ExecNode 分解为 Pipeline Operators。</p><p>再根据 CPU 核数计算 pipeline_dop，生成 dop 个 PipelineDrivers。 </p></li><li><p>FragmentExecutor::execute</p><p> execute 函数比较简单，就是将生成的 drivers 提交给 GlobalDriverExecutor，提交后的状态变化就是前几篇博客所述。因此，本文着重 prepare 函数中的故事。</p></li></ol><p>RPC 接口代码如下。 </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">Status PInternalServiceImplBase&lt;T&gt;::_exec_plan_fragment_by_pipeline(</span><br><span class="line">    <span class="type">const</span> TExecPlanFragmentParams&amp; t_common_param,</span><br><span class="line">    <span class="type">const</span> TExecPlanFragmentParams&amp; t_unique_request) &#123;</span><br><span class="line"></span><br><span class="line">    pipeline::FragmentExecutor fragment_executor;</span><br><span class="line">    <span class="keyword">auto</span> status = </span><br><span class="line">        fragment_executor.<span class="built_in">prepare</span>(_exec_env, t_common_param, t_unique_request);</span><br><span class="line">    <span class="keyword">if</span> (status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> fragment_executor.<span class="built_in">execute</span>(_exec_env);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> status.<span class="built_in">is_duplicate_rpc_invocation</span>() ? Status::<span class="built_in">OK</span>() : status;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="FragmentExecutor"><a href="#FragmentExecutor" class="headerlink" title="FragmentExecutor"></a>FragmentExecutor</h2><p>一个 BE 节点可能会在存在一个 query 的多个 FragmentInstances 实例，统一由 QueryContext 进行管理。</p><p>在 FragmentExecutor::prepare 阶段需要完成的操作即 6 个 _prepare_xxx 系列函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FragmentExecutor</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">FragmentExecutor</span>();</span><br><span class="line">    <span class="function">Status <span class="title">prepare</span><span class="params">(ExecEnv* exec_env, <span class="type">const</span> TExecPlanFragmentParams&amp; common_request,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> TExecPlanFragmentParams&amp; unique_request)</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// Several steps of prepare a fragment</span></span><br><span class="line">    <span class="comment">// 1. query context</span></span><br><span class="line">    <span class="comment">// 2. fragment context</span></span><br><span class="line">    <span class="comment">// 3. workgroup</span></span><br><span class="line">    <span class="comment">// 4. runtime state</span></span><br><span class="line">    <span class="comment">// 5. exec plan</span></span><br><span class="line">    <span class="comment">// 6. pipeline driver</span></span><br><span class="line">    Status _prepare_query_ctx(ExecEnv* exec_env, <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_fragment_ctx(<span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_workgroup(<span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_runtime_state(ExecEnv* exec_env, <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_exec_plan(ExecEnv* exec_env, <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_global_dict(<span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_pipeline_driver(ExecEnv* exec_env, <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line">    Status _prepare_stream_load_pipe(ExecEnv* exec_env, <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request);</span><br><span class="line"></span><br><span class="line">    Status _decompose_data_sink_to_operator(RuntimeState* runtime_state, </span><br><span class="line">                                            PipelineBuilderContext* context,</span><br><span class="line">                                            <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request,</span><br><span class="line">                                            std::unique_ptr&lt;starrocks::DataSink&gt;&amp; datasink,</span><br><span class="line">                                            <span class="type">const</span> TDataSink&amp; thrift_sink,</span><br><span class="line">                                            <span class="type">const</span> std::vector&lt;TExpr&gt;&amp; output_exprs);</span><br><span class="line">    <span class="comment">//... other methods or fields</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> _fragment_start_time = <span class="number">0</span>;</span><br><span class="line">    QueryContext* _query_ctx = <span class="literal">nullptr</span>;</span><br><span class="line">    std::shared_ptr&lt;FragmentContext&gt; _fragment_ctx = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="prepare-query-ctx"><a href="#prepare-query-ctx" class="headerlink" title="_prepare_query_ctx"></a>_prepare_query_ctx</h3><p>如图，每个 BE 节点都有一个 QueryContextManger 用于管理在一个 BE 上执行的所有 query，QueryContextManger 可以理解为Map，内部在 {query_id, query_context} 之间建立映射关系。</p><p>在 StaRocks-BE 中，全局唯一的对象基本都存储在类 <strong>ExecEnv</strong> 中，并在 ExecEnv::_init 函数中初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status ExecEnv::_init(<span class="type">const</span> std::vector&lt;StorePath&gt;&amp; store_paths) &#123;</span><br><span class="line">    _query_context_mgr = <span class="keyword">new</span> pipeline::<span class="built_in">QueryContextManager</span>(<span class="number">6</span>);</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_query_context_mgr-&gt;<span class="built_in">init</span>());</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">pipeline::QueryContextManager* <span class="title">query_context_mgr</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    <span class="keyword">return</span> _query_context_mgr; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为，BE 接受到一个新的 query，需要先在 query_context_mgr 中注册，再使用该 query 的参数对 _query_ctx 进行初始化。</p><p>这里重要的是设置查询超时时间，默认是 300s，这是一个 query 最大的可执行时间，其他设置基本都是默认关闭。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">Status FragmentExecutor::_prepare_query_ctx(ExecEnv* exec_env, <span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request) &#123;</span><br><span class="line">    <span class="comment">// prevent an identical fragment instance from multiple execution caused by FE&#x27;s</span></span><br><span class="line">    <span class="comment">// duplicate invocations of rpc exec_plan_fragment.</span></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; params = request.<span class="built_in">common</span>().params;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; query_id = params.query_id;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; fragment_instance_id = request.<span class="built_in">fragment_instance_id</span>();</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; query_options = request.<span class="built_in">common</span>().query_options;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 去重</span></span><br><span class="line">    <span class="keyword">auto</span>&amp;&amp; existing_query_ctx = exec_env-&gt;<span class="built_in">query_context_mgr</span>()-&gt;<span class="built_in">get</span>(query_id);</span><br><span class="line">    <span class="keyword">if</span> (existing_query_ctx) &#123;</span><br><span class="line">        <span class="keyword">auto</span>&amp;&amp; existingfragment_ctx = existing_query_ctx-&gt;<span class="built_in">fragment_mgr</span>()-&gt;<span class="built_in">get</span>(fragment_instance_id);</span><br><span class="line">        <span class="keyword">if</span> (existingfragment_ctx) &#123;</span><br><span class="line">            <span class="keyword">return</span> Status::<span class="built_in">DuplicateRpcInvocation</span>(<span class="string">&quot;Duplicate invocations of exec_plan_fragment&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 通过 query_id 注册新的 query_contex</span></span><br><span class="line">    _query_ctx = exec_env-&gt;<span class="built_in">query_context_mgr</span>()-&gt;<span class="built_in">get_or_register</span>(query_id);</span><br><span class="line">    _query_ctx-&gt;<span class="built_in">set_exec_env</span>(exec_env);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.1 设置 fragment_instances 个数</span></span><br><span class="line">    <span class="keyword">if</span> (params.__isset.instances_number) &#123;</span><br><span class="line">        _query_ctx-&gt;<span class="built_in">set_total_fragments</span>(params.instances_number);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.2 设置查询超时时间</span></span><br><span class="line">    _query_ctx-&gt;<span class="built_in">set_delivery_expire_seconds</span>(_calc_delivery_expired_seconds(request));</span><br><span class="line">    _query_ctx-&gt;<span class="built_in">set_query_expire_seconds</span>(_calc_query_expired_seconds(request));</span><br><span class="line">    <span class="comment">// initialize query&#x27;s deadline</span></span><br><span class="line">    _query_ctx-&gt;<span class="built_in">extend_delivery_lifetime</span>();</span><br><span class="line">    _query_ctx-&gt;<span class="built_in">extend_query_lifetime</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.3 是否开启 query profile，默认关闭</span></span><br><span class="line">    <span class="keyword">if</span> (query_options.__isset.enable_profile &amp;&amp; query_options.enable_profile) &#123;</span><br><span class="line">        _query_ctx-&gt;<span class="built_in">set_report_profile</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (query_options.__isset.pipeline_profile_level) &#123;</span><br><span class="line">        _query_ctx-&gt;<span class="built_in">set_profile_level</span>(query_options.pipeline_profile_level);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.4 是否开启查询 trace，默认关闭</span></span><br><span class="line">    <span class="type">bool</span> enable_query_trace = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (query_options.__isset.enable_query_debug_trace &amp;&amp; query_options.enable_query_debug_trace) &#123;</span><br><span class="line">        enable_query_trace = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    _query_ctx-&gt;<span class="built_in">set_query_trace</span>(std::<span class="built_in">make_shared</span>&lt;starrocks::debug::QueryTrace&gt;(query_id, enable_query_trace));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="prepare-fragment-ctx"><a href="#prepare-fragment-ctx" class="headerlink" title="_prepare_fragment_ctx"></a>_prepare_fragment_ctx</h3><p>创建一个 FragmentContext 对象，设置所属的 query，自己的 fragment_instance_id，以及 FE 地址。只有等后续几个 _prepare_xxx 函数都成功执行，才会将此 _fragment_ctx 注册到 _query_ctx 中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Status FragmentExecutor::_prepare_fragment_ctx(<span class="type">const</span> UnifiedExecPlanFragmentParams&amp; request) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; coord = request.<span class="built_in">common</span>().coord;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; query_id = request.<span class="built_in">common</span>().params.query_id;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; fragment_instance_id = request.<span class="built_in">fragment_instance_id</span>();</span><br><span class="line"></span><br><span class="line">    _fragment_ctx = std::<span class="built_in">make_shared</span>&lt;FragmentContext&gt;();</span><br><span class="line"></span><br><span class="line">    _fragment_ctx-&gt;<span class="built_in">set_query_id</span>(query_id);</span><br><span class="line">    _fragment_ctx-&gt;<span class="built_in">set_fragment_instance_id</span>(fragment_instance_id);</span><br><span class="line">    _fragment_ctx-&gt;<span class="built_in">set_fe_addr</span>(coord);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文主要阐述 BE 节点从接受 FE 执行计划到构建 PipelineDriver 并提交给 GlobalDriverExecutor 的过程。&lt;/p&gt;
&lt;p&gt;每个 Query 在 StarRocks-FE 生成的物理计划（Physical Plan）后会被拆分为 Plan</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>GloablDriverExecutor: 实现协程模型的执行器</title>
    <link href="https://szza.github.io/2023/07/25/Pipeline/PipelineExecutor/"/>
    <id>https://szza.github.io/2023/07/25/Pipeline/PipelineExecutor/</id>
    <published>2023-07-25T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:57.262Z</updated>
    
    <content type="html"><![CDATA[<p>在前面几篇已经叙述了 PipelineDriver、DriverQueue、PipelinePoller 等设计，下面再来看看是 GlobalDriverExecutor 怎么将他们组合在一起的。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-1.svg?raw=true" alt="pipeline-1"></p><p>由于 _driver_queue 和 _blocked_driver_poller 是在 _thread_pool 中所有 workers 间共享的。一个 query FragemntInstance 划分成 dop 个 PipelineDrivers 分发（dispatch）给 n 个 worker 去执行。但是有可能 driver0 开始分配给 worker0，在执行过程中被添加到 blocked_driver_poller，后又被 worker1 取出，最终 driver0 在 work1 中执行。</p><blockquote><p>这里是不是能优化下？分为两个队列 LocalReadyQueue，RemoteReadyQueue：只有 local_ready_queue 中满了，才会从其他 workers 中窃取(steal) PipelineDrivers 放到 remote_ready_queue，<u>减少 corss-core 通信</u>。</p></blockquote><h2 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h2><p>Executor 的所有 workers 都是阻塞等待在 DrvierQueue::take 处，当 DriverQueue 中有添加了新的 Ready PipelineDrvier 时，就会有一个 worker 解除阻塞。</p><ol><li>对于取出的 ready_driver，worker 会先检测其状态，过滤一些已经处于终态（CANCELED、FINISH、INTERNEL_ERROR）的 Driver，会调用 GlobalDriverExecutor::_finalize_driver 函数，如果是 FragementInstance 的最后一个 PipelineDriver，则生成该 FragmentInstance 的查询统计信息（即 profile），汇报给 Frontend。</li><li>对于正常处于 READY&#x2F;Running 状态的 driver，则调用 PipelineDriver::process 函数，推动 pipeline 状态机前进。</li></ol><ul><li>如果返回的状态 <strong>maybe_state</strong>.is_not_ok，则通过 QueryContext::cancel 将当前 Backend 上该 query 的所有 FragmentInstances 标记为取消状态。后续该 query 所有的 drivers，无论是在 Poller 中或者正在 Executor 中的，在执行前会去检测 fragment_ctx::is_canceled，如果返回 true，则取消本次执行，进入 step(1)</li><li>如果 maybe_state.is_ok，则会根据此时 driver 的状态，判断是重新放回到 driver_queue、或是 blocked_driver_poller，或者说直接完成了。</li></ul><p>在执行过程中，会设置并更新 Driver、DriverQueue 的统计信息，便于 DrvierQueue 更为准确地调度。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> GlobalDriverExecutor::_worker_thread() &#123;</span><br><span class="line">    <span class="keyword">auto</span> current_thread = Thread::<span class="built_in">current_thread</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> worker_id = _next_id++;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_num_threads_setter.<span class="built_in">should_shrink</span>()) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 0. 取出 READY 状态的 driver</span></span><br><span class="line">        <span class="keyword">auto</span> maybe_driver = <span class="keyword">this</span>-&gt;_driver_queue-&gt;<span class="built_in">take</span>();</span><br><span class="line">        <span class="keyword">auto</span> driver = maybe_driver.<span class="built_in">value</span>();</span><br><span class="line">        <span class="built_in">DCHECK</span>(driver != <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">auto</span>* query_ctx = driver-&gt;<span class="built_in">query_ctx</span>();</span><br><span class="line">        <span class="keyword">auto</span>* fragment_ctx = driver-&gt;<span class="built_in">fragment_ctx</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 统计信息</span></span><br><span class="line">        driver-&gt;<span class="built_in">increment_schedule_times</span>();</span><br><span class="line">        _schedule_count++;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">auto</span> runtime_state_ptr = fragment_ctx-&gt;<span class="built_in">runtime_state_ptr</span>();</span><br><span class="line">        <span class="keyword">auto</span>* runtime_state = runtime_state_ptr.<span class="built_in">get</span>();</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">SCOPED_THREAD_LOCAL_MEM_TRACKER_SETTER</span>(</span><br><span class="line">                runtime_state-&gt;<span class="built_in">instance_mem_tracker</span>());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 1.1 终态检测: 检测 fragment 是否已经取消</span></span><br><span class="line">            <span class="keyword">if</span> (fragment_ctx-&gt;<span class="built_in">is_canceled</span>()) &#123;</span><br><span class="line">                driver-&gt;<span class="built_in">cancel_operators</span>(runtime_state);</span><br><span class="line">                <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_still_pending_finish</span>()) &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::PENDING_FINISH);</span><br><span class="line">                    _blocked_driver_poller-&gt;<span class="built_in">add_blocked_driver</span>(driver);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    _finalize_driver(driver,</span><br><span class="line">                                     runtime_state,</span><br><span class="line">                                     DriverState::CANCELED);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//1.2 终态检测：driver 是否已经处于终态</span></span><br><span class="line">            <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_finished</span>()) &#123;</span><br><span class="line">                _finalize_driver(driver, runtime_state, driver-&gt;<span class="built_in">driver_state</span>());</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 统计信息 </span></span><br><span class="line">            <span class="type">int64_t</span> start_time = driver-&gt;<span class="built_in">get_active_time</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2. 推动 PipelineDriver</span></span><br><span class="line">            StatusOr&lt;DriverState&gt; maybe_state;</span><br><span class="line">            <span class="built_in">TRY_CATCH_ALL</span>(maybe_state, driver-&gt;<span class="built_in">process</span>(runtime_state, worker_id));</span><br><span class="line"></span><br><span class="line">            Status status = maybe_state.<span class="built_in">status</span>();</span><br><span class="line">            <span class="keyword">this</span>-&gt;_driver_queue-&gt;<span class="built_in">update_statistics</span>(driver);</span><br><span class="line">            <span class="type">int64_t</span> end_time = driver-&gt;<span class="built_in">get_active_time</span>();</span><br><span class="line">            _driver_execution_ns += end_time - start_time;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2.1  PipelineDriver 执行过程出错</span></span><br><span class="line">            <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">                <span class="comment">// 取消整个 query</span></span><br><span class="line">                query_ctx-&gt;<span class="built_in">cancel</span>(status);</span><br><span class="line">                driver-&gt;<span class="built_in">cancel_operators</span>(runtime_state);</span><br><span class="line">                <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_still_pending_finish</span>()) &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::PENDING_FINISH);</span><br><span class="line">                    _blocked_driver_poller-&gt;<span class="built_in">add_blocked_driver</span>(driver);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    _finalize_driver(driver, </span><br><span class="line">                                     runtime_state,</span><br><span class="line">                                     DriverState::INTERNAL_ERROR);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 2.2 没有出错则更新状态，重新放回 driver_queue 或是添加到 poller</span></span><br><span class="line">            <span class="keyword">auto</span> driver_state = maybe_state.<span class="built_in">value</span>();</span><br><span class="line">            <span class="keyword">switch</span> (driver_state) &#123;</span><br><span class="line">            <span class="comment">// 重新放回 ready_driver</span></span><br><span class="line">            <span class="keyword">case</span> READY:</span><br><span class="line">            <span class="keyword">case</span> RUNNING: &#123;</span><br><span class="line">                <span class="keyword">this</span>-&gt;_driver_queue-&gt;<span class="built_in">put_back_from_executor</span>(driver);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 终态</span></span><br><span class="line">            <span class="keyword">case</span> FINISH:</span><br><span class="line">            <span class="keyword">case</span> CANCELED:</span><br><span class="line">            <span class="keyword">case</span> INTERNAL_ERROR: &#123;</span><br><span class="line">                _finalize_driver(driver, runtime_state, driver_state);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 阻塞</span></span><br><span class="line">            <span class="keyword">case</span> INPUT_EMPTY:</span><br><span class="line">            <span class="keyword">case</span> OUTPUT_FULL:</span><br><span class="line">            <span class="keyword">case</span> PENDING_FINISH:</span><br><span class="line">            <span class="keyword">case</span> PRECONDITION_BLOCK: &#123;</span><br><span class="line">                _blocked_driver_poller-&gt;<span class="built_in">add_blocked_driver</span>(driver);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="built_in">DCHECK</span>(<span class="literal">false</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Coroutione"><a href="#Coroutione" class="headerlink" title="Coroutione"></a>Coroutione</h2><p>那么这个协程模型体现在哪呢？</p><p>PipelineDriver::process 中变量 <em>should_yield</em> 被设置为 true 时，</p><ul><li>要么是当前状态受阻，则该 driver 放入到 _blocked_driver_poller</li><li>或者是当前时间片用完，都会重新放回到 _driver_queue，重新调度分发，给其他 drivers 执行的可能</li></ul><p>只要有 Ready&#x2F;Running 状态的 driver，Executor 的 worker 就不会阻塞。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在前面几篇已经叙述了 PipelineDriver、DriverQueue、PipelinePoller 等设计，下面再来看看是 GlobalDriverExecutor 怎么将他们组合在一起的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/sz</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>QuerySharedDriverQueue: 多级反馈队列</title>
    <link href="https://szza.github.io/2023/07/19/Pipeline/DriverQueue_1/"/>
    <id>https://szza.github.io/2023/07/19/Pipeline/DriverQueue_1/</id>
    <published>2023-07-19T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:05.944Z</updated>
    
    <content type="html"><![CDATA[<p>DriverQueue 的继承派生关系如下图所示。QuerySharedDriverQueue 是用于没有设置 ResuorceGroup 的 query，即 default ResourceGroup，而 WorkGroupDriverQueue 是针对设置了 ResourceGroup 的 query。</p><p>本文专注于 QuerySharedDriverQueue 的实现，ResuorceGroup 后文单独讲解。下文 DriverQueue 一般指 QuerySharedDriverQueue。 </p><p>DriverQueue 本质上是个调度 PipelineDrivers 的数据结构，这样 DrvierQueue 本身就不需要占据一个线程，它可以在 GloablEexecuotr::work_thread 所在的核上运行。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-driver-queue-1.svg?raw=true" alt="pipeline-driver-queue-1"></p><h2 id="DriverAcct"><a href="#DriverAcct" class="headerlink" title="DriverAcct"></a>DriverAcct</h2><p>DriverQueue 实现调度，需要依赖 PipelineDriver 运行时的统计信息。比如，在前文我们说过了 <a href="https://szza.github.io/2023/07/15/Pipeline/PipelineDriver_2">PipelineDriver</a> 每执行一次 PipelineDriver:process 函数都会更新统计信息。</p><p>统计信息由 DriverAcct 记录：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">DriverAcct</span> &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="function"><span class="type">int64_t</span> <span class="title">get_last_time_spent</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> last_time_spent; &#125;</span><br><span class="line">    <span class="function"><span class="type">int64_t</span> <span class="title">get_accumulated_time_spent</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> accumulated_time_spent; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> schedule_times&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int64_t</span> schedule_effective_times&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int64_t</span> last_time_spent&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int64_t</span> last_chunks_moved&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int64_t</span> accumulated_time_spent&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int64_t</span> accumulated_chunks_moved&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int64_t</span> accumulated_rows_moved&#123;<span class="number">0</span>&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>PipelineDriver 中统计信息如下。利用这些统计信息就能实现更为准确的调度。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">DriverAcct&amp; <span class="title">PipelineDriver::driver_acct</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    <span class="keyword">return</span> _driver_acct; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> PipelineDriver::_update_driver_acct(<span class="type">size_t</span> total_chunks_moved,</span><br><span class="line">                                         <span class="type">size_t</span> total_rows_moved,</span><br><span class="line">                                         <span class="type">size_t</span> time_spent) &#123;</span><br><span class="line">    <span class="built_in">driver_acct</span>().<span class="built_in">update_last_chunks_moved</span>(total_chunks_moved);</span><br><span class="line">    <span class="built_in">driver_acct</span>().<span class="built_in">update_accumulated_rows_moved</span>(total_rows_moved);</span><br><span class="line">    <span class="built_in">driver_acct</span>().<span class="built_in">update_last_time_spent</span>(time_spent);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> PipelineDriver::_update_statistics(<span class="type">size_t</span> total_chunks_moved,</span><br><span class="line">                                        <span class="type">size_t</span> total_rows_moved,</span><br><span class="line">                                        <span class="type">size_t</span> time_spent) &#123;</span><br><span class="line">    _update_driver_acct(total_chunks_moved,</span><br><span class="line">                        total_rows_moved,</span><br><span class="line">                        time_spent);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Update statistics of scan operator</span></span><br><span class="line">    <span class="keyword">if</span> (ScanOperator* scan = <span class="built_in">source_scan_operator</span>()) &#123;</span><br><span class="line">        <span class="built_in">query_ctx</span>()-&gt;<span class="built_in">incr_cur_scan_rows_num</span>(</span><br><span class="line">            scan-&gt;<span class="built_in">get_last_scan_rows_num</span>());</span><br><span class="line">        <span class="built_in">query_ctx</span>()-&gt;<span class="built_in">incr_cur_scan_bytes</span>(</span><br><span class="line">            scan-&gt;<span class="built_in">get_last_scan_bytes</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Update cpu cost of this query</span></span><br><span class="line">    <span class="type">int64_t</span> accounted_cpu_cost </span><br><span class="line">        = <span class="built_in">driver_acct</span>().<span class="built_in">get_last_time_spent</span>()</span><br><span class="line">        + <span class="built_in">source_operator</span>()-&gt;<span class="built_in">get_last_growth_cpu_time_ns</span>()</span><br><span class="line">        + <span class="built_in">sink_operator</span>()-&gt;<span class="built_in">get_last_growth_cpu_time_ns</span>();</span><br><span class="line">    <span class="built_in">query_ctx</span>()-&gt;<span class="built_in">incr_cpu_cost</span>(accounted_cpu_cost);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="SubQuerySharedDriverQueue"><a href="#SubQuerySharedDriverQueue" class="headerlink" title="SubQuerySharedDriverQueue"></a>SubQuerySharedDriverQueue</h2><p>QuerySharedDriverQueue 基于多级反馈队列实现，每一 level 的时间片不同，每一 level 的 PipelineDriver 是由 SubQuerySharedDriverQueue 来存储。</p><p>SubQuerySharedDriverQueue 有三个字段：</p><ul><li>queue：用于存放 Pipelinerivers，如果 driver 已经 DriverState::CANCELED 状态则从头部压入，否则从尾部压入</li><li>pending_cancel_queue：用于存放正在取消的 driver</li><li>cancelled_set：用于记录已经取消的 drivers，如果 queue 中取出的 drivers 已经在 canceled_set 中，则忽略该 driver，从 queue 中重新取</li></ul><p>结构如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SubQuerySharedDriverQueue</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">update_accu_time</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">        _accu_consume_time.<span class="built_in">fetch_add</span>(</span><br><span class="line">            driver-&gt;<span class="built_in">driver_acct</span>().<span class="built_in">get_last_time_spent</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">double</span> <span class="title">accu_time_after_divisor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> _accu_consume_time.<span class="built_in">load</span>() / factor_for_normal; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">put</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">cancel</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span></span>;</span><br><span class="line">    <span class="function">DriverRawPtr <span class="title">take</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    std::deque&lt;DriverRawPtr&gt; queue;</span><br><span class="line">    std::queue&lt;DriverRawPtr&gt; pending_cancel_queue;</span><br><span class="line">    std::unordered_set&lt;DriverRawPtr&gt; cancelled_set;</span><br><span class="line">    <span class="type">size_t</span> num_drivers = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// factor for normalization</span></span><br><span class="line">    <span class="type">double</span> factor_for_normal = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::atomic&lt;<span class="type">int64_t</span>&gt; _accu_consume_time = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="put"><a href="#put" class="headerlink" title="put"></a>put</h3><p>driver 如果已经处于 DriverState::CANCELED 状态，则从头部压入，否则从尾部压入。cancel 函数是直接压入 pending_cancel_queue 中。 queue 和 pending_cancel_queue 是可能存在重复的 driver，因此需要 cancelled_set 去重。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">SubQuerySharedDriverQueue::put</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (driver-&gt;<span class="built_in">driver_state</span>() == DriverState::CANCELED) &#123;</span><br><span class="line">        queue.<span class="built_in">emplace_front</span>(driver);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        queue.<span class="built_in">emplace_back</span>(driver);</span><br><span class="line">    &#125;</span><br><span class="line">    num_drivers++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SubQuerySharedDriverQueue::cancel</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (cancelled_set.<span class="built_in">count</span>(driver) == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(driver-&gt;<span class="built_in">is_in_ready_queue</span>());</span><br><span class="line">        pending_cancel_queue.<span class="built_in">emplace</span>(driver);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="take"><a href="#take" class="headerlink" title="take"></a>take</h3><p>从 SubQuerySharedDriverQueue 中获取 driver 时</p><ul><li>如果 pending_cancel_queue 不为空，率先从 pending_cancel_queue 中取，并将获得的 driver 记录在 cancelld_set 中。</li><li>否则，再从 queue 中获取，如果 driver 已经在 cancelled_set 中记录，则忽略并重新从 queue 中获取。</li></ul><p>代码也是比较简单的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">DriverRawPtr <span class="title">SubQuerySharedDriverQueue::take</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(!<span class="built_in">empty</span>());</span><br><span class="line">    <span class="keyword">if</span> (!pending_cancel_queue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        DriverRawPtr driver = pending_cancel_queue.<span class="built_in">front</span>();</span><br><span class="line">        pending_cancel_queue.<span class="built_in">pop</span>();</span><br><span class="line">        cancelled_set.<span class="built_in">insert</span>(driver);</span><br><span class="line">        --num_drivers;</span><br><span class="line">        <span class="keyword">return</span> driver;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!queue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        DriverRawPtr driver = queue.<span class="built_in">front</span>();</span><br><span class="line">        queue.<span class="built_in">pop_front</span>();</span><br><span class="line">        <span class="keyword">auto</span> iter = cancelled_set.<span class="built_in">find</span>(driver);</span><br><span class="line">        <span class="keyword">if</span> (iter != cancelled_set.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            cancelled_set.<span class="built_in">erase</span>(iter);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            --num_drivers;</span><br><span class="line">            <span class="keyword">return</span> driver;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="QuerySharedDriverQueue"><a href="#QuerySharedDriverQueue" class="headerlink" title="QuerySharedDriverQueue"></a>QuerySharedDriverQueue</h2><p>QuerySharedDriverQueue 一共有 QUEUE_SIZE（值是 8）个 SubQuerySharedDriverQueue，每个 SubQueue 对应的时间片依次是 <strong>{0.2s, 0.6s, 1.2s, 2s, 3s, 4.2s, 5.6s, 7.2s}</strong>:</p><ul><li>比如 SubQueue[0] 的时间片范围是 <strong>[0, 0.2)</strong>, </li><li>超过 7.2s 的 Pipeline 都位于最后一个队列 SubQueue[7] 中，即 SubQueue[7] 的时间范围是 [5.6, +∞)。</li></ul><p>每个 Driver 消耗的时间片记录在 <code>DriverAcct::accumulated_time_spent</code>，PipelineDriver 每执行一次就会调用一次 _update_statistics 函数来更新 DriverAcct 中的统计值，当 <em>accumulated_time_spent</em> 超过当前 SubQueue 的时间片区间，driver 就进入下一个 SubQueue。</p><p>QuerySharedDriverQueue 的构造函数如下 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">QuerySharedDriverQueue::<span class="built_in">QuerySharedDriverQueue</span>() &#123;</span><br><span class="line">    <span class="type">double</span> factor = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = QUEUE_SIZE - <span class="number">1</span>; i &gt;= <span class="number">0</span>; --i) &#123;</span><br><span class="line">        <span class="comment">// initialize factor for every sub queue,</span></span><br><span class="line">        <span class="comment">// Higher priority queues have more execution time,</span></span><br><span class="line">        <span class="comment">// so they have a larger factor.</span></span><br><span class="line">        _queues[i].factor_for_normal = factor;</span><br><span class="line">        factor *= RATIO_OF_ADJACENT_QUEUE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> time_slice = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; QUEUE_SIZE; ++i) &#123;</span><br><span class="line">        time_slice += LEVEL_TIME_SLICE_BASE_NS * (i + <span class="number">1</span>);</span><br><span class="line">        _level_time_slices[i] = time_slice;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="compute-driver-level"><a href="#compute-driver-level" class="headerlink" title="_compute_driver_level"></a>_compute_driver_level</h3><p>向 QuerySharedDriverQueue 添加 driver 时，从上一次所处的层 <code>PipelineDriver::get_driver_queue_level</code> 开始，再基于 accumulated_time_spent 计算 driver 本次将位于 DriverQueue 中的哪一层。</p><p>因此，一个长时间的运行的 driver 在 DriverQueue 中不断下沉。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> QuerySharedDriverQueue::_compute_driver_level(<span class="type">const</span> DriverRawPtr driver) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="type">int</span> time_spent = driver-&gt;<span class="built_in">driver_acct</span>().<span class="built_in">get_accumulated_time_spent</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = driver-&gt;<span class="built_in">get_driver_queue_level</span>(); i &lt; QUEUE_SIZE; ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> (time_spent &lt; _level_time_slices[i]) &#123;</span><br><span class="line">            <span class="keyword">return</span> i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> QUEUE_SIZE - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="put-back"><a href="#put-back" class="headerlink" title="put_back"></a>put_back</h3><p>put_back 函数将 READY 的 driver 放入到 DriverQueue，</p><ul><li>PipelineDriver::_driver_queue_level 记录每次在 DrvierQueue 中的层。</li><li>PipelineDriver::_in_ready_queue 标记是否被 <code>put_back</code> 到 DrvierQueue 中</li><li>PipelineDriver::_in_queue 即 driver 所属的 DriverQueue</li></ul><p>插入一个 driver 后，通过 _cv 解除 take 函数处的阻塞，Executor 就可以继续通过 DriverQueue::take 函数获得新的可执行的 driver</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuerySharedDriverQueue::put_back</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> level = _compute_driver_level(driver);</span><br><span class="line">    driver-&gt;<span class="built_in">set_driver_queue_level</span>(level);</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(_global_mutex)</span></span>;</span><br><span class="line">        _queues[level].<span class="built_in">put</span>(driver);</span><br><span class="line">        driver-&gt;<span class="built_in">set_in_ready_queue</span>(<span class="literal">true</span>);</span><br><span class="line">        driver-&gt;<span class="built_in">set_in_queue</span>(<span class="keyword">this</span>);</span><br><span class="line">        _cv.<span class="built_in">notify_one</span>();</span><br><span class="line">        ++_num_drivers;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// QuerySharedDriverQueue::put_back_from_executor is identical to put_back.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuerySharedDriverQueue::put_back_from_executor</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">put_back</span>(driver);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="take-1"><a href="#take-1" class="headerlink" title="take"></a>take</h3><p>put_back 函数是通过 <em>_compute_driver_level</em> 函数来确定 SubQueue 的层数。take 函数则通过 SubQuerySharedDriverQueue::accu_time_after_divisor() 来确定。 </p><ul><li><p>_accu_consume_time 字段是该 SubQueue 的耗时</p><p>这个值实际上和 <code>DriverAcct::accumulated_time_spent</code> 大小一样：每次更新统计时都是累加的 <code>DriverAcct::last_time_spent</code>。因此 put_back&#x2F;take 的衡量标准是一样的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">DriverAcct::update_last_time_spent</span><span class="params">(<span class="type">int64_t</span> time_spent)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>-&gt;last_time_spent = time_spent;</span><br><span class="line">    <span class="keyword">this</span>-&gt;accumulated_time_spent += time_spent;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SubQuerySharedDriverQueue::update_accu_time</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    _accu_consume_time.<span class="built_in">fetch_add</span>(driver-&gt;<span class="built_in">driver_acct</span>().<span class="built_in">get_last_time_spent</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>factor_for_normal 是在 QUEUE_SIZE 个 SubQueue 的正则系数</p></li></ul><p>二者相处得到归一化的时间系数，<u>使得每一层都有机会被访问到</u>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">SubQuerySharedDriverQueue::accu_time_after_divisor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _accu_consume_time.<span class="built_in">load</span>() / factor_for_normal;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>确定好 level 后，就可以直接从该 level 提取出 READY 状态的 PipelineDriver。如果整个 DriverQueue 都空的，则基于 _cv 阻塞等待。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;DriverRawPtr&gt; <span class="title">QuerySharedDriverQueue::take</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// -1 means no candidates; else has candidate.</span></span><br><span class="line">  <span class="type">int</span> queue_idx = <span class="number">-1</span>;</span><br><span class="line">  <span class="type">double</span> target_accu_time = <span class="number">0</span>;</span><br><span class="line">  DriverRawPtr driver_ptr;</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(_global_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="built_in">RETURN_IF</span>(_is_closed, Status::<span class="built_in">Cancelled</span>(<span class="string">&quot;Shutdown&quot;</span>));</span><br><span class="line">        <span class="comment">// Find the queue with the smallest execution time.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; QUEUE_SIZE; ++i) &#123;</span><br><span class="line">            <span class="comment">// we just search for queue has element</span></span><br><span class="line">            <span class="keyword">if</span> (!_queues[i].<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="type">double</span> local_target_time = _queues[i].<span class="built_in">accu_time_after_divisor</span>();</span><br><span class="line">                <span class="keyword">if</span> (queue_idx &lt; <span class="number">0</span> || local_target_time &lt; target_accu_time) &#123;</span><br><span class="line">                    target_accu_time = local_target_time;</span><br><span class="line">                    queue_idx = i;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (queue_idx &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        _cv.<span class="built_in">wait</span>(lock);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// record queue&#x27;s index to accumulate time for it.</span></span><br><span class="line">    driver_ptr = _queues[queue_idx].<span class="built_in">take</span>();</span><br><span class="line">    driver_ptr-&gt;<span class="built_in">set_in_ready_queue</span>(<span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">    --_num_drivers;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// next pipeline driver to execute.</span></span><br><span class="line">  <span class="keyword">return</span> driver_ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;DriverQueue 的继承派生关系如下图所示。QuerySharedDriverQueue 是用于没有设置 ResuorceGroup 的 query，即 default ResourceGroup，而 WorkGroupDriverQueue 是针对设置了 Resou</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Pipeline: Operator 状态机(2)</title>
    <link href="https://szza.github.io/2023/07/15/Pipeline/PipelineDriver_2/"/>
    <id>https://szza.github.io/2023/07/15/Pipeline/PipelineDriver_2/</id>
    <published>2023-07-15T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:59.289Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><p>Pipeline 由一组 Operators 组成，一个 Pipeline 内部 Operator 是串行执行的，第一个是 SourceOperatos，最后一个是 SinkOperator，数据流从 Source 流向 Sink：从前一个 Operator 拉取数据（<em>Operator::pull_chunk</em>），再将该数据推到下一个Operator（<em>Operator::push_chunk</em>），这就是 Pipeline 的 pull-push 模型。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/PipelineDriver-2.svg?raw=true" alt="PipelineDriver-2"></p><h3 id="OperatorStage"><a href="#OperatorStage" class="headerlink" title="OperatorStage"></a>OperatorStage</h3><p>每个 Operator 也有对应的状态 OperatorStage，用于保证与 Operator 特定状态相关的 Callback（Preapre、Close 等函数） 只调用一次。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">OperatorStage</span> &#123;</span><br><span class="line">    INIT = <span class="number">0</span>,</span><br><span class="line">    PREPARED = <span class="number">1</span>,</span><br><span class="line">    PRECONDITION_NOT_READY = <span class="number">2</span>,</span><br><span class="line">    PROCESSING = <span class="number">3</span>,</span><br><span class="line">    FINISHING = <span class="number">4</span>,</span><br><span class="line">    FINISHED = <span class="number">5</span>,</span><br><span class="line">    CANCELLED = <span class="number">6</span>,</span><br><span class="line">    CLOSED = <span class="number">7</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>OperatorStage 的状态流如下图，实际上阻塞只会发生在 SourceOperator&#x2F;SinkOperator，中间的 PipelineJob 是不会阻塞（只会因为时间片用完重新调度）的，只是个计算流。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-Operator-stage-1.svg?raw=true" alt="Pipeline-Operator-stage-1"></p><p>Operator 创建时状态为 OperatorStage::INIT，提交给 GloablDriverExecutor 时，先先会调用 PipelineDriver::prepare 函数将所有的 Operators 设置为 OperatorStage::PREPARED 状态，</p><ul><li>HashJoinProbeOperator 设置为 PRECONDITION_NOT_READY，</li><li>其他的通过 PipelineDriver::submit_operators 函数统一设置为 OperatorStage::PROCESSING 状态</li></ul><p>后续就由 PipelineDriver 状态机推动了，并由 PipelineDriver::_mark_operator_xxx 系列函数更改状态，这些函数可以保证 Operator 每个状态都只被调用一次：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// class PipelineDriver</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 所有的 Operator 设置为 OperatorStage::PROCESSING 状态</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mark_precondition_ready</span><span class="params">(RuntimeState* runtime_state)</span></span>;</span><br><span class="line"><span class="comment">// 将 operator 设置为 OperatorStage::FINISHING 状态</span></span><br><span class="line">Status _mark_operator_finishing(OperatorPtr&amp; op, RuntimeState* runtime_state);</span><br><span class="line"><span class="comment">// 将 operator 设置为 OperatorStage::FINISHED 状态</span></span><br><span class="line">Status _mark_operator_finished(OperatorPtr&amp; op, RuntimeState* runtime_state);</span><br><span class="line"><span class="comment">// 将 operator 设置为 OperatorStage::CANCELLED 状态</span></span><br><span class="line">Status _mark_operator_cancelled(OperatorPtr&amp; op, RuntimeState* runtime_state);</span><br><span class="line"><span class="comment">// 将 operator 设置为 OperatorStage::CLOSED 状态</span></span><br><span class="line">Status _mark_operator_closed(OperatorPtr&amp; op, RuntimeState* runtime_state);</span><br></pre></td></tr></table></figure><p>对应着 Operator 的不同状态更改函数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// class Operator</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">set_precondition_ready</span><span class="params">(RuntimeState* state)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">set_finishing</span><span class="params">(RuntimeState* state)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">set_finished</span><span class="params">(RuntimeState* state)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">set_cancelled</span><span class="params">(RuntimeState* state)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">close</span><span class="params">(RuntimeState* state)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="PipelineDriver-process"><a href="#PipelineDriver-process" class="headerlink" title="PipelineDriver:process"></a>PipelineDriver:process</h3><p>PipelineDriver:process 函数会依次处理 PipelineDriver::_operators，但是 process 函数有时间片，超过最大时间片 <strong>YIELD_PREEMPT_MAX_TIME_SPENT</strong>，就需要主动让出 CPU，让其他线程执行，将当前 Driver 放回到 DriverQueue 等待下次调度，如果发生阻塞则放到 poller 中。因此也需要更新统计信息，基于这些统计信息 DriverQueue 决定下次何时调度次 PipelineDriver。</p><p>PipelineDriver::_first_unfinished 记录着当前 Pipelien 的执行进度，即处理到哪一个 Operator，每次都是从 _first_unfinished 开始处理。</p><h4 id="Part1-check"><a href="#Part1-check" class="headerlink" title="Part1: check"></a>Part1: check</h4><p>在 (curr_op, next_op) 传递数据之前，需要先做一些前置校验工作：</p><ol><li><p>curr_op 是否已经处理结束</p><p>对于已经处理结束的，需要通过 _mark_operator_finishing 操作调用 Operator::set_finishing 函数来更改当前 Operator 的状态。通过 new_first_unfinished 记录已经完成的 Operator 的下标索引。</p><blockquote><p>为什么 i &#x3D;&#x3D; 0 时，_mark_operator_finishing 传入的参数包括 curr_op ?</p><ol><li>OperatorStage::FINISHING 表示 Operator 不会再有输入，等之前 pushed chunk 处理完，则进入 OperatorStage::FINISHED 状态。因此当 curr_op-&gt;is_finished() 为 true 时，即表示 next_op 不会再有输入，需要将 next_op 设置为 OperatorStage::FINISHING 状态</li><li>SourceOperator 本身就不需要输入（更准确地说，是没有上游 Operator push_chunk 给 SourceOperator），等 SoureOperator 从网络&#x2F;本地磁盘 pull 所有数据，curr_op-&gt;is_finished() 也会为 true，此时将 SourceOperator 标记为 OperatorStage::FINISHING，来表示 Source 不会再 pull。</li></ol></blockquote></li><li><p>要能在 (curr_op, next_op) 之间完成数据传递，前提是 curr_op 有就绪的数据输出，且 next_op 准备好接受数据</p><p> 这一步通过 Operator::has_output 和 Operator::need_input 判断</p></li><li><p>当前 FragmentInstance 没有取消，这个 Pipeline 才需要继续执行</p></li></ol><p>(curr_op, next_op) 一次数据流处理时间记录在 time_spent。这部分逻辑如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = _first_unfinished; i &lt; num_operators - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">SCOPED_RAW_TIMER</span>(&amp;time_spent);</span><br><span class="line">        <span class="keyword">auto</span>&amp; curr_op = _operators[i];</span><br><span class="line">        <span class="keyword">auto</span>&amp; next_op = _operators[i + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.</span></span><br><span class="line">        <span class="keyword">if</span> (curr_op-&gt;<span class="built_in">is_finished</span>()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// For source operators</span></span><br><span class="line">                <span class="built_in">RETURN_IF_ERROR</span>(return_status = _mark_operator_finishing(curr_op, runtime_state));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(return_status = _mark_operator_finishing(next_op, runtime_state));</span><br><span class="line">            new_first_unfinished = i + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// try successive operator pairs</span></span><br><span class="line">        <span class="keyword">if</span> (!curr_op-&gt;<span class="built_in">has_output</span>() || !next_op-&gt;<span class="built_in">need_input</span>()) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (_check_fragment_is_canceled(runtime_state)) &#123;</span><br><span class="line">            <span class="keyword">return</span> _state;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//...</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Part2-pull-push"><a href="#Part2-pull-push" class="headerlink" title="Part2: pull-push"></a>Part2: pull-push</h3><p>for 循环的第二部分，就是从 curr_op 拉取数据流推向 next_op，任何一步失败，都会将 bad status 返回给 GlobalDriverExecutor，进而取消整个 query。</p><p>第二部分代码是比较简单的，如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = _first_unfinished; i &lt; num_operators - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">//...above code</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1. pull chunk from current operator</span></span><br><span class="line">    StatusOr&lt;vectorized::ChunkPtr&gt; maybe_chunk;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">SCOPED_TIMER</span>(curr_op-&gt;_pull_timer);</span><br><span class="line">        maybe_chunk = curr_op-&gt;<span class="built_in">pull_chunk</span>(runtime_state);</span><br><span class="line">    &#125;</span><br><span class="line">    return_status = maybe_chunk.<span class="built_in">status</span>();</span><br><span class="line">    <span class="keyword">if</span> (!return_status.<span class="built_in">ok</span>() &amp;&amp; !return_status.<span class="built_in">is_end_of_file</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> return_status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 快速 check 下 query 是否被取消</span></span><br><span class="line">    <span class="keyword">if</span> (_check_fragment_is_canceled(runtime_state)) &#123;</span><br><span class="line">        <span class="keyword">return</span> _state;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. push chunk</span></span><br><span class="line">    <span class="keyword">if</span> (return_status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (maybe_chunk.<span class="built_in">value</span>() &amp;&amp; maybe_chunk.<span class="built_in">value</span>()-&gt;<span class="built_in">num_rows</span>() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 本次读取的数据超过限制</span></span><br><span class="line">            <span class="type">size_t</span> row_num = maybe_chunk.<span class="built_in">value</span>()-&gt;<span class="built_in">num_rows</span>();</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">UNLIKELY</span>(row_num &gt; runtime_state-&gt;<span class="built_in">chunk_size</span>())) &#123;</span><br><span class="line">                <span class="keyword">return</span> Status::<span class="built_in">InternalError</span>(fmt::format(</span><br><span class="line">                    <span class="string">&quot;Intermediate chunk size must noe be greater than &#123;&#125; &quot;</span></span><br><span class="line">                    <span class="string">&quot;actually &#123;&#125; after &#123;&#125;-th operator &#123;&#125; in &#123;&#125;&quot;</span>,</span><br><span class="line">                    runtime_state-&gt;<span class="built_in">chunk_size</span>(), row_num,</span><br><span class="line">                    i, curr_op-&gt;<span class="built_in">get_name</span>(), <span class="built_in">to_readable_string</span>()));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">SCOPED_TIMER</span>(next_op-&gt;_push_timer);</span><br><span class="line">                return_status = next_op-&gt;<span class="built_in">push_chunk</span>(runtime_state, maybe_chunk.<span class="built_in">value</span>());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!return_status.<span class="built_in">ok</span>() &amp;&amp; !return_status.<span class="built_in">is_end_of_file</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> return_status;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            num_chunks_moved += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. Check curr_op finished again</span></span><br><span class="line">    <span class="keyword">if</span> (curr_op-&gt;<span class="built_in">is_finished</span>()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// For source operators</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(return_status = _mark_operator_finishing(curr_op, runtime_state));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(return_status = _mark_operator_finishing(next_op, runtime_state));</span><br><span class="line">        new_first_unfinished = i + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">///...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="part3-time"><a href="#part3-time" class="headerlink" title="part3: time"></a>part3: time</h4><p>time_spent 记录了 (curr_op, next_op) 之间一次 {pull, push} 操作耗时。而每次 PipelineDriver 执行的最大时间片是 <strong>YIELD_MAX_TIME_SPENT</strong>，如果 query 设置了具体的 WorkGroup，最大的时间片是 <strong>YIELD_PREEMPT_MAX_TIME_SPENT</strong>，如果 time_spent 超过了这两个阈值的其中一个，则需要主动让出 CPU 给予其他线程机会，此时标记 should_yield 为 true，跳出 for-loop 循环。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = _first_unfinished; i &lt; num_operators - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">   <span class="comment">//...above code</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (time_spent &gt;= OVERLOADED_MAX_TIME_SPEND_NS) &#123;</span><br><span class="line">       StarRocksMetrics::<span class="built_in">instance</span>()-&gt;pipe_driver_overloaded.<span class="built_in">increment</span>(<span class="number">1</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// yield when total chunks moved or time spent on-core for evaluation</span></span><br><span class="line">   <span class="comment">// exceed the designated thresholds.</span></span><br><span class="line">   <span class="keyword">if</span> (time_spent &gt;= YIELD_MAX_TIME_SPENT) &#123;</span><br><span class="line">       should_yield = <span class="literal">true</span>;</span><br><span class="line">       <span class="built_in">COUNTER_UPDATE</span>(_yield_by_time_limit_counter, <span class="number">1</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (_workgroup != <span class="literal">nullptr</span> &amp;&amp; time_spent &gt;= YIELD_PREEMPT_MAX_TIME_SPENT &amp;&amp;</span><br><span class="line">       _workgroup-&gt;<span class="built_in">driver_sched_entity</span>()-&gt;<span class="built_in">in_queue</span>()-&gt;<span class="built_in">should_yield</span>(<span class="keyword">this</span>, time_spent)) &#123;</span><br><span class="line">       should_yield = <span class="literal">true</span>;</span><br><span class="line">       <span class="built_in">COUNTER_UPDATE</span>(_yield_by_preempt_counter, <span class="number">1</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Part4"><a href="#Part4" class="headerlink" title="Part4:"></a>Part4:</h3><p>一个 for-loop 完成，要么是本轮时间片用完要么是是当前 Pipeline 执行完。</p><ul><li><p>new_first_unfinished 标记着本轮已经完成 Operator 的下标索引。</p><p>首先要 [_first_unfinished, new_first_unfinished) 区间的 Operator 通过 _mark_operator_finished 函数设置标记为完成， 再用 new_first_unfinished 更新 _first_unfinished。</p></li><li><p>SinkOperator::is_finished 返回 true 表示当前 Pipeline 所有 Operators 执行完毕，</p><p>  finish_operators 函数遍历所有的 Operators，并对所有的 Operator 调用 _mark_operator_finished 函数。</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PipelineDriver::finish_operators</span><span class="params">(RuntimeState* runtime_state)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; op : _operators) &#123;</span><br><span class="line">      _mark_operator_finished(op, runtime_state);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  _mark_operator_finished 会调用 Operator::set_finished 函数，使得所有的 Operators 都进入 OperatorStage::FINISHED 状态。</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Status PipelineDriver::_mark_operator_finished(OperatorPtr&amp; op, </span><br><span class="line">                                               RuntimeState* state) &#123;</span><br><span class="line">  <span class="built_in">RETURN_IF_ERROR</span>(_mark_operator_finishing(op, state));</span><br><span class="line">  <span class="keyword">auto</span>&amp; op_state = _operator_stages[op-&gt;<span class="built_in">get_id</span>()];</span><br><span class="line">  <span class="built_in">RETURN_IF</span>(op_state &gt;= OperatorStage::FINISHED, Status::<span class="built_in">OK</span>());</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">      <span class="built_in">SCOPED_TIMER</span>(op-&gt;_finished_timer);</span><br><span class="line">      op_state = OperatorStage::FINISHED;</span><br><span class="line">      <span class="keyword">return</span> op-&gt;<span class="built_in">set_finished</span>(state);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  finish_operators 函数结束，再更改 PipelineDrvier 状态，使 drvier 进入 DriverState::PENDING_FINISH 或者 DriverState::FINISH 状态。</p><blockquote><p>正常一个 Operator 生命周期结束时行为:</p><ul><li>Source::is_finished –&gt; Source::set_finishing –&gt;  Source::set_finished</li><li>PrevOperator::is_finished –&gt; Operator::set_finishing –&gt; Operator::set_finished</li><li>PrevOperator::is_finished –&gt;  Sink::set_finishing –&gt; Sink::is_finished –&gt; Sink::set_finished –&gt; Operators::close</li></ul></blockquote></li><li><p>否则， 就说明是本轮时间片用完，会更改当前 PipelineDriver 的状态，让 Executor 根据此状态判断是否加入 blocked_driver_poller 还是放回 _drvier_queue。</p></li></ul><p>代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="built_in">RETURN_IF_LIMIT_EXCEEDED</span>(runtime_state, <span class="string">&quot;Pipeline&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> num_chunks_moved = <span class="number">0</span>;</span><br><span class="line">    <span class="type">bool</span> should_yield = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">size_t</span> num_operators = _operators.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">size_t</span> new_first_unfinished = _first_unfinished;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = _first_unfinished; i &lt; num_operators - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">        <span class="comment">/** above code**/</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// close finished operators and update _first_unfinished index</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = _first_unfinished; i &lt; new_first_unfinished; ++i) &#123;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(return_status = _mark_operator_finished(_operators[i], runtime_state));</span><br><span class="line">    &#125;</span><br><span class="line">    _first_unfinished = new_first_unfinished;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">sink_operator</span>()-&gt;<span class="built_in">is_finished</span>()) &#123;</span><br><span class="line">        <span class="built_in">finish_operators</span>(runtime_state);</span><br><span class="line">        <span class="built_in">set_driver_state</span>(</span><br><span class="line">            <span class="built_in">is_still_pending_finish</span>() </span><br><span class="line">            ? DriverState::PENDING_FINISH </span><br><span class="line">            : DriverState::FINISH);</span><br><span class="line">        <span class="keyword">return</span> _state;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// no chunk moved in current round means that the driver is blocked.</span></span><br><span class="line">    <span class="comment">// should yield means that the CPU core is occupied the driver for a</span></span><br><span class="line">    <span class="comment">// very long time so that the driver should switch off the core and</span></span><br><span class="line">    <span class="comment">// give chance for another ready driver to run.</span></span><br><span class="line">    <span class="keyword">if</span> (num_chunks_moved == <span class="number">0</span> || should_yield) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">is_precondition_block</span>()) &#123;</span><br><span class="line">            <span class="built_in">set_driver_state</span>(DriverState::PRECONDITION_BLOCK);</span><br><span class="line">            <span class="built_in">COUNTER_UPDATE</span>(_block_by_precondition_counter, <span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="built_in">sink_operator</span>()-&gt;<span class="built_in">is_finished</span>() </span><br><span class="line">                   &amp;&amp; !<span class="built_in">sink_operator</span>()-&gt;<span class="built_in">need_input</span>()) &#123;</span><br><span class="line">            <span class="built_in">set_driver_state</span>(DriverState::OUTPUT_FULL);</span><br><span class="line">            <span class="built_in">COUNTER_UPDATE</span>(_block_by_output_full_counter, <span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="built_in">source_operator</span>()-&gt;<span class="built_in">is_finished</span>()</span><br><span class="line">                   &amp;&amp; !<span class="built_in">source_operator</span>()-&gt;<span class="built_in">has_output</span>()) &#123;</span><br><span class="line">            <span class="built_in">set_driver_state</span>(DriverState::INPUT_EMPTY);</span><br><span class="line">            <span class="built_in">COUNTER_UPDATE</span>(_block_by_input_empty_counter, <span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">set_driver_state</span>(DriverState::READY);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> _state;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Pipeline&quot;&gt;&lt;a href=&quot;#Pipeline&quot; class=&quot;headerlink&quot; title=&quot;Pipeline&quot;&gt;&lt;/a&gt;Pipeline&lt;/h2&gt;&lt;p&gt;Pipeline 由一组 Operators 组成，一个 Pipeline 内部 Opera</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Pipeline: PipelineDriver 状态机(1)</title>
    <link href="https://szza.github.io/2023/07/12/Pipeline/PipelineDriver_1/"/>
    <id>https://szza.github.io/2023/07/12/Pipeline/PipelineDriver_1/</id>
    <published>2023-07-12T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:34.909Z</updated>
    
    <content type="html"><![CDATA[<p>本篇来看看 PipelineDriver 的执行流程，以及如何与 PipelineDriverPoller 交互。</p><h2 id="Pipeline-DriverState"><a href="#Pipeline-DriverState" class="headerlink" title="Pipeline DriverState"></a>Pipeline DriverState</h2><p>一个 PipelineDriver 的状态有如下 10 种：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">DriverState</span> : <span class="type">uint32_t</span> &#123;</span><br><span class="line">    NOT_READY = <span class="number">0</span>,</span><br><span class="line">    READY = <span class="number">1</span>,</span><br><span class="line">    RUNNING = <span class="number">2</span>,</span><br><span class="line">    INPUT_EMPTY = <span class="number">3</span>,</span><br><span class="line">    OUTPUT_FULL = <span class="number">4</span>,</span><br><span class="line">    PRECONDITION_BLOCK = <span class="number">5</span>,</span><br><span class="line">    FINISH = <span class="number">6</span>,</span><br><span class="line">    CANCELED = <span class="number">7</span>,</span><br><span class="line">    INTERNAL_ERROR = <span class="number">8</span>,</span><br><span class="line">    PENDING_FINISH = <span class="number">9</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>他们之间的状态变化如下:<br><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/PipelineDriver-1.svg?raw=true" alt="PipelineaDriver-1"></p><p>在此处不单独讲解每个状态，后面融到代码流程一起讲解。</p><h3 id="GlobalDriverExecutor-submit"><a href="#GlobalDriverExecutor-submit" class="headerlink" title="GlobalDriverExecutor::submit"></a>GlobalDriverExecutor::submit</h3><p>先回顾下 GlobalDrvierExecutor 整体设计:</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-1.svg?raw=true" alt="pipeline-1"></p><p>PipelineDriver 创建完，并通过 submit 接口传递给 Driver<strong>Executor</strong>。Executor 会先根据该 drvier 当前状态来判断是进入 <strong>_driver_queue</strong> 还是 <strong>_blocked_driver_poller</strong> 中。</p><p>比如，在 <a href="https://szza.github.io/2023/07/05/Pipeline/MorselQueue_2/">Morsel 和 OlapScanOperator(2)</a> 中提到的 OlapScanPrepareOperator 和 OlapScanOperator：需要等待 PrepareOperator::pull_chunk 执行完（因为需要先获取待访问的 tablets 和 rowsets），ScanOperator 才能执行。然而 Prepare 和 Scan 分属于两个 PipelineDriver。他们的依赖关系如下：</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-OlapScanOperator-1.svg?raw=true" alt="Pipeline-OlapScanOperator-1"><br>因此，而 pipeline0 在被提交给 Executor 后会进入 _driver_queue，pipeline1 提交后则进入 _blocked_driver_poller。这里的初始判断条件：</p><ul><li>HashJoin：Join 需要先等待 Build 阶段完成，才能进入 Probe 阶段。Build 阶段即 Probe 阶段的 Precondition，Probe 则会进入 submit 函数第一个分支，并添加到 <em>_blocked_driver_poller</em> 中</li><li>其他，都是使用 <em>SourceOperator::is_finished</em> 函数和 <em>SourceOperator::has_output</em> 函数来判断进入哪个 driver_queue</li></ul><p>代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">GlobalDriverExecutor::submit</span><span class="params">(DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    driver-&gt;<span class="built_in">start_schedule</span>(_schedule_count, _driver_execution_ns);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_precondition_block</span>()) &#123;</span><br><span class="line">        driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::PRECONDITION_BLOCK);</span><br><span class="line">        driver-&gt;<span class="built_in">mark_precondition_not_ready</span>();</span><br><span class="line">        <span class="keyword">this</span>-&gt;_blocked_driver_poller-&gt;<span class="built_in">add_blocked_driver</span>(driver);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        driver-&gt;<span class="built_in">submit_operators</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Try to add the driver to poller first.</span></span><br><span class="line">        <span class="keyword">if</span> (!driver-&gt;<span class="built_in">source_operator</span>()-&gt;<span class="built_in">is_finished</span>() </span><br><span class="line">            &amp;&amp; !driver-&gt;<span class="built_in">source_operator</span>()-&gt;<span class="built_in">has_output</span>()) &#123;</span><br><span class="line">            driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::INPUT_EMPTY);</span><br><span class="line">            <span class="keyword">this</span>-&gt;_blocked_driver_poller-&gt;<span class="built_in">add_blocked_driver</span>(driver);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>-&gt;_driver_queue-&gt;<span class="built_in">put_back</span>(driver);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="PipelineDriverPoller"><a href="#PipelineDriverPoller" class="headerlink" title="PipelineDriverPoller"></a>PipelineDriverPoller</h2><p>PipelineDriverPoller 的主要字段解释如下:</p><ul><li><p><em>_driver_queue</em>: PipelineDriverPoller 和 GlobalDriverExecutor 共享 <em>_driver_queue</em>，存放着 READY 状态可执行的 PipelineDriver。</p></li><li><p><em>_blocked_drivers</em>: 存储当前 Backends 中所有暂时无法执行的 blocked PipelineDrivers，</p><p> _global_mutex 是用于保护 _blocked_drivers，在 poll_thread 和 PipelineDriverPoller::add_blocked_driver 函数之间形成互斥。</p><p> _cond 则是配合 _gloabl_mutex，上层调用 add_blocked_driver 函数添加 blocked driver 时，唤醒正在阻塞等待的 poller_thread。</p></li><li><p><em>_local_blocked_drivers</em>: 表征的是当前 poller_thread 中正在处理 blocked PipelineDrivers。</p><p>  但是我觉得没必要引入一个 _local_mutex，SpinLock 就能满足要求。详见 poller_thread 分析。</p></li></ul><p>类 PipelineDriverPoller 主要字段及其构造函数如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PipelineDriverPoller</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">PipelineDriverPoller</span><span class="params">(DriverQueue* driver_queue)</span></span></span><br><span class="line"><span class="function">        : _driver_queue(driver_queue),</span></span><br><span class="line"><span class="function">          _polling_thread(nullptr),</span></span><br><span class="line"><span class="function">          _is_polling_thread_initialized(false),</span></span><br><span class="line"><span class="function">          _is_shutdown(false) &#123;</span> &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">using</span> DriverList = std::list&lt;DriverRawPtr&gt;;</span><br><span class="line">    <span class="comment">//... other methods</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">mutable</span> std::mutex _global_mutex;</span><br><span class="line">    std::condition_variable _cond;</span><br><span class="line">    DriverList _blocked_drivers;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">mutable</span> std::shared_mutex _local_mutex;</span><br><span class="line">    DriverList _local_blocked_drivers;</span><br><span class="line"></span><br><span class="line">    DriverQueue* _driver_queue;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PipelineDriverPoller 在 Executor 构造</span></span><br><span class="line">GlobalDriverExecutor::<span class="built_in">GlobalDriverExecutor</span>(std::string name, </span><br><span class="line">                                           std::unique_ptr&lt;ThreadPool&gt; pool,</span><br><span class="line">                                           <span class="type">bool</span> enable_resource_group)</span><br><span class="line">        : <span class="built_in">Base</span>(std::<span class="built_in">move</span>(name)),</span><br><span class="line">          <span class="comment">// driver_queue 在 Executor 中构造</span></span><br><span class="line">          _driver_queue(enable_resource_group </span><br><span class="line">            ? std::<span class="built_in">unique_ptr</span>&lt;DriverQueue&gt;(<span class="keyword">new</span> <span class="built_in">WorkGroupDriverQueue</span>())</span><br><span class="line">            : std::<span class="built_in">make_unique</span>&lt;QuerySharedDriverQueue&gt;()),</span><br><span class="line">          _thread_pool(std::<span class="built_in">move</span>(pool)),</span><br><span class="line">          <span class="comment">// 传递 _driver_queue 指针给 poller</span></span><br><span class="line">          _blocked_driver_poller(<span class="keyword">new</span> <span class="built_in">PipelineDriverPoller</span>(_driver_queue.<span class="built_in">get</span>())),</span><br><span class="line">          _exec_state_reporter(<span class="keyword">new</span> <span class="built_in">ExecStateReporter</span>()) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="add-blocked-driver"><a href="#add-blocked-driver" class="headerlink" title="add_blocked_driver"></a>add_blocked_driver</h3><p>add_blocked_driver 函数是 Executor 向 Poller 添加 blocked drivers 的函数接口，这里需要使用 _global_mutex 来与 poller_thread 形成互斥。</p><p>_pending_timer_sw 用于统计每次 driver 处于阻塞状态的时间，即加入 poller 时重置，从 poller 中删除后计算本次 blocked 耗时。多次阻塞总耗时更新到 PipelineDriver::_pending_timer 中，查询结束可以在 query profile 中搜索 ‘PendingTime’ 字段查看。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PipelineDriverPoller::add_blocked_driver</span><span class="params">(<span class="type">const</span> DriverRawPtr driver)</span> </span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(_global_mutex)</span></span>;</span><br><span class="line">    _blocked_drivers.<span class="built_in">push_back</span>(driver);</span><br><span class="line">    driver-&gt;_pending_timer_sw-&gt;<span class="built_in">reset</span>();</span><br><span class="line">    _cond.<span class="built_in">notify_one</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="run-internal"><a href="#run-internal" class="headerlink" title="run_internal"></a>run_internal</h3><p>下面是 Poller 的重点：poller_thread。可以将 poller_thread 分为三个部分：</p><h4 id="Part1"><a href="#Part1" class="headerlink" title="Part1"></a>Part1</h4><p>等待 Executor 将 blocked drivers 加入到 Poller 中。</p><p>在一个正常部署的 StarRocks 集群中，任意一个时刻都应该有查询存在，且生成的 PipelineDriver 会很多。因此，add_blocked_driver 函数与 poller_thread 之间的 race condition 应该比较激烈。poller_thread  在局部作用域里使用 std::mutex + std::condition_variable ，来缩小 _gloab_mutex 的范围。</p><p>如果有新 blocked drivers 加入，则将其从 _blocked_drivers 中移到 tmp_blocked_drivers，局部作用域结束就释放了 _gloabl_mutex。poller_thread 后续就直接对 poller_thread 进行操作，也就不会阻塞 add_blocked_driver 函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PipelineDriverPoller::run_internal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    _is_polling_thread_initialized.<span class="built_in">store</span>(<span class="literal">true</span>, std::memory_order_release);</span><br><span class="line"></span><br><span class="line">    DriverList tmp_blocked_drivers;</span><br><span class="line">    <span class="keyword">while</span> (!_is_shutdown.<span class="built_in">load</span>(std::memory_order_acquire)) &#123;</span><br><span class="line">      <span class="comment">// part1 start...</span></span><br><span class="line">      <span class="comment">// 1. 局部作用域</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(_global_mutex)</span></span>;</span><br><span class="line">        <span class="comment">// 将 _blocked_drivers 中的元素移到 tmp_blocked_drivers</span></span><br><span class="line">        tmp_blocked_drivers.<span class="built_in">splice</span>(</span><br><span class="line">            tmp_blocked_drivers.<span class="built_in">end</span>(), _blocked_drivers);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (_local_blocked_drivers.<span class="built_in">empty</span>() &amp;&amp; tmp_blocked_drivers.<span class="built_in">empty</span>() </span><br><span class="line">            &amp;&amp; _blocked_drivers.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="comment">// 超时等待</span></span><br><span class="line">            std::cv_status cv_status = std::cv_status::no_timeout;</span><br><span class="line">            <span class="keyword">while</span> (!_is_shutdown.<span class="built_in">load</span>(std::memory_order_acquire) </span><br><span class="line">                   &amp;&amp; _blocked_drivers.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                   cv_status = _cond.<span class="built_in">wait_for</span>(lock, <span class="number">10</span>ms);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (cv_status == std::cv_status::timeout) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (_is_shutdown.<span class="built_in">load</span>(std::memory_order_acquire)) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 获得本轮的 blocked drivers</span></span><br><span class="line">            tmp_blocked_drivers.<span class="built_in">splice</span>(</span><br><span class="line">                tmp_blocked_drivers.<span class="built_in">end</span>(), _blocked_drivers);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Part2"><a href="#Part2" class="headerlink" title="Part2"></a>Part2</h4><p>得到本轮 tmp_blocked_drivers 后，将其加入到 _local_blocked_drivers 中。后续对 _local_blocked_drivers 中的 drivers 当前状态进行判断。因为有个 iterate_immutable_driver 函数需要读取 _local_blocked_drivers，故而也用 _local_mutex 对其进行互斥保护。</p><blockquote><p>但是，iterate_immutable_driver 是来源于 HTTP 请求，通常情况下请求几乎不会被执行，可能开发人员会在调试时使用下，因次这里几乎没有必要使用 std::mutex，更好的选择显然是使用 SpinLock。</p></blockquote><p>需要对 _local_blocked_drivers 中的每个 driver 进行遍历，检测是否 READY 或者处于终止状态</p><ul><li><p><strong>case1: QueryContext::is_query_expired</strong></p><p>  每个 query 都有个 query_timeout（默认值 300s），超过这个时间就会 cancel 该 query。这时会主动调用 FragmentContext::cancel 函数，标记这个 query。由于 FragmentInstance 的所有 PipelineDrievrs 共享一个 FragmentContext 对象，因此其他 PipelineDriver 就会可以通过检测 FragmentContext::is_canceled 来查看当前 query 是否仍处于取消状态</p><blockquote><p>实际上这个状态会上报，再下发取消其他节点的 FragementInstances?</p></blockquote></li><li><p><strong>case2: FragmentContext::is_canceled</strong></p><p>  触发 FragmentContext::cancel 操作的场景很多，除了上述的查询超时，还有在查询过程中 Operators::pull_chunk、Operators::push_chunk 执行遇到某些问题，此时在 GloablDriverExecutor 会调用 QueryContex::cancel 将该 query 的所有 FragementInstance 都进行 cancel。如此，该 query 下所有的 FragmentInstances 的所有 PipelineDriver 都不会再被执行。</p></li><li><p><strong>case3: DriverState::PENDING_FINISH</strong></p><p>  从代码中，不难发现只有当 PipelineDriver::pending_finish 为 false 时，这个 blocked_driver 才会调用 remove_blocked_driver 函数将其从 _local_blocked_drivers 中删除。</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PipelineDriverPoller::remove_blocked_driver</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    DriverList&amp; local_blocked_drivers, DriverList::iterator&amp; driver_it)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span>&amp; driver = *driver_it;</span><br><span class="line">    driver-&gt;_pending_timer-&gt;<span class="built_in">update</span>(</span><br><span class="line">        driver-&gt;_pending_timer_sw-&gt;<span class="built_in">elapsed_time</span>());</span><br><span class="line">    local_blocked_drivers.<span class="built_in">erase</span>(driver_it++);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 转为 DriverState::PENDING_FINISH 状态的前提是 is_still_pending_finish 函数返回 true:</p>   <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="type">bool</span> <span class="title">PipelineDriver::is_still_pending_finish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">source_operator</span>()-&gt;<span class="built_in">pending_finish</span>() </span><br><span class="line">           || <span class="built_in">sink_operator</span>()-&gt;<span class="built_in">pending_finish</span>(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  实际上 SourceOperator 中，只有 ScanOperator 实现了这个函数，且返回值为 false</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ScanOperator::pending_finish</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  也就是说， is_still_pending_finish 函数的返回值取决于 SinkOperator::pending_finish 了。</p><blockquote><p>这也是这个阶段存在的原因</p></blockquote><p>  实际上就是为了等待 SinkOperator 中的数据处理完，比如 ExchangeSinkOperator 中的 buffer 消耗完才能进入 DriverState::FINISH 阶段。因此 is_still_pending_finish 返回 true 时，blocked drvier 并没有加入 ready drivers 中，而是被忽略了，等待下一次 poll。</p></li><li><p><strong>case4: PipelineDriver::is_finished</strong><br>  query 终态有三种:</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">is_finished</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _state == DriverState::FINISH </span><br><span class="line">           || _state == DriverState::CANCELED</span><br><span class="line">           || _state == DriverState::INTERNAL_ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  已经处于终态的可以直接从 _local_blocked_drivers 中删除，并加入 ready_drivers 中。 </p></li><li><p><strong>case5: PipelineDriver::is_not_blocked</strong><br>  这个分支才是用于检测 PipelineDriver 是否解除阻塞，可以继续执行了。比如 OlapScanPrepareOperator::pull_chunk 执行完毕，OlapScanOperator 的 PipelineDrvier::is_not_block 函数才会返回 true，从 _local_blocked_drivers 中转入 ready_drivers。</p></li><li><p><strong>case6</strong></p><p>PipelineDriver 仍无法 Ready</p></li></ul><p>Part2 代码如下.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PipelineDriverPoller::run_internal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;DriverRawPtr&gt; ready_drivers;</span><br><span class="line">    <span class="keyword">while</span> (!_is_shutdown.<span class="built_in">load</span>(std::memory_order_acquire)) &#123;</span><br><span class="line">      <span class="comment">// above part1 code ...</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// part2 start ...</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="function">std::unique_lock <span class="title">write_lock</span><span class="params">(_local_mutex)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!tmp_blocked_drivers.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            _local_blocked_drivers.<span class="built_in">splice</span>(</span><br><span class="line">                _local_blocked_drivers.<span class="built_in">end</span>(), tmp_blocked_drivers);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">auto</span> driver_it = _local_blocked_drivers.<span class="built_in">begin</span>();</span><br><span class="line">        <span class="keyword">while</span> (driver_it != _local_blocked_drivers.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            <span class="keyword">auto</span>* driver = *driver_it;</span><br><span class="line">            <span class="keyword">auto</span>* fragment_ctx = driver-&gt;<span class="built_in">fragment_ctx</span>();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (driver-&gt;<span class="built_in">query_ctx</span>()-&gt;<span class="built_in">is_query_expired</span>()) &#123;</span><br><span class="line">               <span class="comment">// case1: 查询超时</span></span><br><span class="line">                fragment_ctx-&gt;<span class="built_in">cancel</span>(Status::<span class="built_in">TimedOut</span>(fmt::format(</span><br><span class="line">                    <span class="string">&quot;Query exceeded time limit of &#123;&#125; seconds&quot;</span>,</span><br><span class="line">                    driver-&gt;<span class="built_in">query_ctx</span>()-&gt;<span class="built_in">get_query_expire_seconds</span>())));</span><br><span class="line"></span><br><span class="line">                driver-&gt;<span class="built_in">cancel_operators</span>(fragment_ctx-&gt;<span class="built_in">runtime_state</span>());</span><br><span class="line">                <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_still_pending_finish</span>()) &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::PENDING_FINISH);</span><br><span class="line">                    ++driver_it;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::FINISH);</span><br><span class="line">                    <span class="built_in">remove_blocked_driver</span>(_local_blocked_drivers, driver_it);</span><br><span class="line">                    ready_drivers.<span class="built_in">emplace_back</span>(driver);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (fragment_ctx-&gt;<span class="built_in">is_canceled</span>()) &#123;</span><br><span class="line">                <span class="comment">//case2: query 已经被 cancel</span></span><br><span class="line">                driver-&gt;<span class="built_in">cancel_operators</span>(fragment_ctx-&gt;<span class="built_in">runtime_state</span>());</span><br><span class="line">                <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_still_pending_finish</span>()) &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::PENDING_FINISH);</span><br><span class="line">                    ++driver_it;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::CANCELED);</span><br><span class="line">                    <span class="built_in">remove_blocked_driver</span>(_local_blocked_drivers, driver_it);</span><br><span class="line">                    ready_drivers.<span class="built_in">emplace_back</span>(driver);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (driver-&gt;<span class="built_in">pending_finish</span>()) &#123;</span><br><span class="line">                <span class="comment">// case3: 处于即将完成的状态</span></span><br><span class="line">                <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_still_pending_finish</span>()) &#123;</span><br><span class="line">                    ++driver_it;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    driver-&gt;<span class="built_in">set_driver_state</span>(</span><br><span class="line">                        fragment_ctx-&gt;<span class="built_in">is_canceled</span>()</span><br><span class="line">                        ? DriverState::CANCELED</span><br><span class="line">                        : DriverState::FINISH);</span><br><span class="line">                    <span class="built_in">remove_blocked_driver</span>(_local_blocked_drivers, driver_it);</span><br><span class="line">                    ready_drivers.<span class="built_in">emplace_back</span>(driver);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_finished</span>()) &#123;</span><br><span class="line">                <span class="comment">// case4: 已经完成</span></span><br><span class="line">                <span class="built_in">remove_blocked_driver</span>(_local_blocked_drivers, driver_it);</span><br><span class="line">                ready_drivers.<span class="built_in">emplace_back</span>(driver);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (driver-&gt;<span class="built_in">is_not_blocked</span>()) &#123;</span><br><span class="line">                <span class="comment">// case5: 解除阻塞</span></span><br><span class="line">                driver-&gt;<span class="built_in">set_driver_state</span>(DriverState::READY);</span><br><span class="line">                <span class="built_in">remove_blocked_driver</span>(_local_blocked_drivers, driver_it);</span><br><span class="line">                ready_drivers.<span class="built_in">emplace_back</span>(driver);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// case6: NOT_READY</span></span><br><span class="line">                ++driver_it;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">  &#125; <span class="comment">// while-loop</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Part3"><a href="#Part3" class="headerlink" title="Part3"></a>Part3</h4><p>第三部分比较简单，就是将 ready 加入 DriverQueue，让 Executor 就会从该 driver_queue 取出可执行的 PipelineDrivers。这部分使用了 spin-loop 的优化，这个优化详情分析可见 RocksDB 系列的 <a href="https://szza.github.io/2022/02/02/rocksdb/WritePath/write_thread_3/">WriteThread 如何自适应优化线程同步</a>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PipelineDriverPoller::run_internal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> spin_count = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (!_is_shutdown.<span class="built_in">load</span>(std::memory_order_acquire)) &#123;</span><br><span class="line">        <span class="comment">//...above code</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// part3 start...</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (ready_drivers.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            spin_count += <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            spin_count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            _driver_queue-&gt;<span class="built_in">put_back</span>(ready_drivers);</span><br><span class="line">            ready_drivers.<span class="built_in">clear</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (spin_count != <span class="number">0</span> &amp;&amp; spin_count % <span class="number">64</span> == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __x86_64__</span></span><br><span class="line">            _mm_pause();</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">            <span class="comment">// <span class="doctag">TODO:</span> Maybe there&#x27;s a better intrinsic like _mm_pause on non-x86_64 architecture.</span></span><br><span class="line">            <span class="built_in">sched_yield</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (spin_count == <span class="number">640</span>) &#123;</span><br><span class="line">            spin_count = <span class="number">0</span>;</span><br><span class="line">            <span class="built_in">sched_yield</span>();</span><br><span class="line">        &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PipelineDriverPoller::run_internal 完整的代码可见 <a href="https://github.com/StarRocks/starrocks/blob/52fc2ed8e2e4cba6594bb534b4291c5053ddb97d/be/src/exec/pipeline/pipeline_driver_poller.cpp#L40C3-L40C3">PipelineDriverPoller::run_internal</a>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本篇来看看 PipelineDriver 的执行流程，以及如何与 PipelineDriverPoller 交互。&lt;/p&gt;
&lt;h2 id=&quot;Pipeline-DriverState&quot;&gt;&lt;a href=&quot;#Pipeline-DriverState&quot; class=&quot;header</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>BalancedChunkBuffer 与 ChunkBufferLimiter</title>
    <link href="https://szza.github.io/2023/07/10/Pipeline/ChunkBuffer/"/>
    <id>https://szza.github.io/2023/07/10/Pipeline/ChunkBuffer/</id>
    <published>2023-07-10T02:00:01.000Z</published>
    <updated>2023-09-26T02:32:01.595Z</updated>
    
    <content type="html"><![CDATA[<p>本篇博客阐述 BalancedChunkBuffer 的内部实现，以及如何配合 ChunkBufferLimiter 限读取并发度。</p><h2 id="BalancedChunkBuffer"><a href="#BalancedChunkBuffer" class="headerlink" title="BalancedChunkBuffer"></a>BalancedChunkBuffer</h2><p>在上一篇博客 <a href="https://szza.github.io/2023/07/07/Pipeline/MorselQueue_3/">MorselQueue_3</a> 说过 chunk_buffer 的作用：缓存一个 Fragement 中，所有 ScanOperators 从存储层读取的数据。chunk_buffer 实际上是 <strong>BalancedChunkBuffer</strong> 对象，并在 OlapScanContextFactory 构造函数中创建。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">OlapScanContextFactory</span>(vectorized::OlapScanNode* <span class="type">const</span> scan_node,</span><br><span class="line">                       <span class="type">int32_t</span> dop,</span><br><span class="line">                       <span class="type">bool</span> shared_morsel_queue,</span><br><span class="line">                       <span class="type">bool</span> shared_scan,</span><br><span class="line">                       ChunkBufferLimiterPtr chunk_buffer_limiter)</span><br><span class="line">: _scan_node(scan_node),</span><br><span class="line">    _dop(dop),</span><br><span class="line">    _shared_morsel_queue(shared_morsel_queue),</span><br><span class="line">    _shared_scan(shared_scan),</span><br><span class="line">    <span class="comment">// BalancedChunkBuffer 创建</span></span><br><span class="line">    _chunk_buffer(shared_scan </span><br><span class="line">                    ? BalanceStrategy::kRoundRobin </span><br><span class="line">                    : BalanceStrategy::kDirect,</span><br><span class="line">                 dop,</span><br><span class="line">                 std::<span class="built_in">move</span>(chunk_buffer_limiter)),</span><br><span class="line">    _contexts(shared_morsel_queue ? <span class="number">1</span> : dop) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// BalancedChunkBuffer 构造函数</span></span><br><span class="line">BalancedChunkBuffer::<span class="built_in">BalancedChunkBuffer</span>(BalanceStrategy strategy,</span><br><span class="line">                                         <span class="type">int</span> output_operators,</span><br><span class="line">                                         ChunkBufferLimiterPtr limiter)</span><br><span class="line">: _output_operators(output_operators),</span><br><span class="line">  _strategy(strategy),</span><br><span class="line">  _sub_buffers(std::<span class="built_in">make_unique</span>&lt;SubBuffer[]&gt;(output_operators)),</span><br><span class="line">  _limiter(std::<span class="built_in">move</span>(limiter)) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; output_operators; i++) &#123;</span><br><span class="line">        _sub_buffers[i] = std::<span class="built_in">make_unique</span>&lt;QueueT&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="SubBuffer"><a href="#SubBuffer" class="headerlink" title="SubBuffer"></a>SubBuffer</h3><p>BalancBdChunkBuffer 中，SubBuffer 存储着每个 Pipeline ScanOperator 待返回给上层的数据。</p><p>从实现可以看出，这个 SubBuffer 实际上是个无界的队列 <em>UnboundedBlockingQueue</em>，用于缓存数据。<code>_sub_buffers</code> 是个大小为 dop 的数组，为每个 Pipeline 都分配了一个 SubBuffer。</p><blockquote><p>_sub_buffers 里面不应该直接存储 SubBuffer，而是应该经过 cache_line 对齐的后 AlignedSubBuffer，因为多线程同时访问 _sub_buffers，如果不cache_line 对齐，会造成 false sharing 问题。</p></blockquote><p>因为会多线程向 sub_buffer[seq] 插入数据，因此 <a href="https://github.com/StarRocks/starrocks/blob/204a6cd2f40c2553adafce1c6ce0cb9774145a00/be/src/util/blocking_queue.hpp#L124">UnboundedBlockingQueue</a> 需要确保线程安全，内部实现也很朴素。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BalancedChunkBuffer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">try_get</span><span class="params">(<span class="type">int</span> buffer_index, vectorized::ChunkPtr* output_chunk)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">put</span><span class="params">(<span class="type">int</span> buffer_index, vectorized::ChunkPtr chunk, ChunkBufferTokenPtr chunk_token)</span></span>;</span><br><span class="line">    <span class="comment">//... other methods</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">using</span> ChunkWithToken = std::pair&lt;vectorized::ChunkPtr, ChunkBufferTokenPtr&gt;;</span><br><span class="line">    <span class="keyword">using</span> QueueT = UnboundedBlockingQueue&lt;ChunkWithToken&gt;;</span><br><span class="line">    <span class="keyword">using</span> SubBuffer = std::unique_ptr&lt;QueueT&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> SubBuffer&amp; _get_sub_buffer(<span class="type">int</span> index) <span class="type">const</span>;</span><br><span class="line">    SubBuffer&amp; _get_sub_buffer(<span class="type">int</span> index);</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> _output_operators;</span><br><span class="line">    <span class="type">const</span> BalanceStrategy _strategy;</span><br><span class="line">    std::unique_ptr&lt;SubBuffer[]&gt; _sub_buffers;</span><br><span class="line">    std::<span class="type">atomic_int64_t</span> _output_index = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    ChunkBufferLimiterPtr _limiter;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="BalancBdChunkBuffer-put"><a href="#BalancBdChunkBuffer-put" class="headerlink" title="BalancBdChunkBuffer::put"></a>BalancBdChunkBuffer::put</h3><p>BalancedChunkBuffer 输入输出内存映射关系有两种，从 OlapScanContextFactory 的构造函数可以看出，</p><ul><li>BalanceStrategy::kDirect，直通模式，对应 IndividualMorselQueueFactory，此时 Pipeline-driver_seq ScanOperator 读取到的数据传递给 该Pipeline-driver_seq 上自己的 Operators 使用</li><li>BalanceStrategy::kRoundRobin，共享模式，对应 SharedMorselQueueFactory，此时 io-tasks 会分别给所有 Pipelines 的 ChunkBuffer 依次分配自己读取到的 chunks<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">BalanceStrategy</span> &#123;</span><br><span class="line">    kDirect,</span><br><span class="line">    kRoundRobin,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ul><p>BalancedChunkBuffer::put 函数会根据 BalanceStrategy 来选择插入方式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> BalancedChunkBuffer::SubBuffer&amp; BalancedChunkBuffer::_get_sub_buffer(<span class="type">int</span> index) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> _sub_buffers[index % _output_operators];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">BalancedChunkBuffer::put</span><span class="params">(<span class="type">int</span> buffer_index, vectorized::ChunkPtr chunk, ChunkBufferTokenPtr chunk_token)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!chunk || (!chunk-&gt;<span class="built_in">owner_info</span>().<span class="built_in">is_last_chunk</span>() &amp;&amp; chunk-&gt;<span class="built_in">num_rows</span>() == <span class="number">0</span>)) &#123; </span><br><span class="line">       <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_strategy == BalanceStrategy::kDirect) &#123;</span><br><span class="line">        <span class="keyword">return</span> _get_sub_buffer(buffer_index)-&gt;<span class="built_in">put</span>(</span><br><span class="line">            std::<span class="built_in">make_pair</span>(std::<span class="built_in">move</span>(chunk), std::<span class="built_in">move</span>(chunk_token)));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (_strategy == BalanceStrategy::kRoundRobin) &#123;</span><br><span class="line">        <span class="type">int</span> target_index = _output_index.<span class="built_in">fetch_add</span>(<span class="number">1</span>) % _output_operators;</span><br><span class="line">        <span class="keyword">return</span> _get_sub_buffer(target_index)-&gt;<span class="built_in">put</span>(</span><br><span class="line">            std::<span class="built_in">make_pair</span>(std::<span class="built_in">move</span>(chunk), std::<span class="built_in">move</span>(chunk_token)));</span><br><span class="line">    &#125;</span><br><span class="line">    __builtin_unreachable();</span><br></pre></td></tr></table></figure><h3 id="BalancedChunkBuffer-try-get"><a href="#BalancedChunkBuffer-try-get" class="headerlink" title="BalancedChunkBuffer::try_get"></a>BalancedChunkBuffer::try_get</h3><p>BalancedChunkBuffer::try_get 就更加简单了，每个 Pipeline-driver_seq 从自己的 SubBuffer 中取出数据即可。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">BalancedChunkBuffer::try_get</span><span class="params">(<span class="type">int</span> buffer_index, vectorized::ChunkPtr* output_chunk)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Will release the token after exiting this scope.</span></span><br><span class="line">    ChunkWithToken chunk_with_token = std::<span class="built_in">make_pair</span>(<span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</span><br><span class="line">    <span class="type">bool</span> ok = _get_sub_buffer(buffer_index)-&gt;<span class="built_in">try_get</span>(&amp;chunk_with_token);</span><br><span class="line">    <span class="keyword">if</span> (ok) &#123;</span><br><span class="line">        *output_chunk = std::<span class="built_in">move</span>(chunk_with_token.first);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ok;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ChunkBufferLimiter"><a href="#ChunkBufferLimiter" class="headerlink" title="ChunkBufferLimiter"></a>ChunkBufferLimiter</h2><p>在 BalancedChunkBuffer 内部存放数据的 SubBuffer 是无界队列，单独使用了一个 ChunkBufferLimiter 来限制速率。ChunkBufferLimiter 在 OlapScanNode::decompose_to_pipeline 中实例化后，经过 OlapScanContextFactory 构造函数传递给 BalancBdChunkBuffer。</p><p>由于 <em>ScanOperator::max_buffer_capacity</em> 默认值是 64，因此每个 Pipeline 一次性最多可以读取 64 个 Chunks。又通过 estimated_max_concurrent_chunks 函数估计个下限。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// OlapScanNode::decompose_to_pipeline</span></span><br><span class="line"><span class="type">size_t</span> max_buffer_capacity = </span><br><span class="line">            pipeline::ScanOperator::<span class="built_in">max_buffer_capacity</span>() * dop; <span class="comment">// 64 * dop</span></span><br><span class="line"><span class="type">size_t</span> default_buffer_capacity = std::<span class="built_in">min</span>&lt;<span class="type">size_t</span>&gt;(</span><br><span class="line">            max_buffer_capacity, <span class="built_in">estimated_max_concurrent_chunks</span>());</span><br><span class="line"><span class="keyword">auto</span> buffer_limiter = std::<span class="built_in">make_unique</span>&lt;pipeline::DynamicChunkBufferLimiter&gt;(</span><br><span class="line">                    max_buffer_capacity,</span><br><span class="line">                    default_buffer_capacity,</span><br><span class="line">                    _mem_limit,</span><br><span class="line">                    <span class="built_in">runtime_state</span>()-&gt;<span class="built_in">chunk_size</span>());</span><br><span class="line">    </span><br><span class="line"><span class="keyword">auto</span> scan_ctx_factory = std::<span class="built_in">make_shared</span>&lt;pipeline::OlapScanContextFactory&gt;(</span><br><span class="line">            <span class="keyword">this</span>,</span><br><span class="line">            dop, shared_morsel_queue,</span><br><span class="line">            _enable_shared_scan,</span><br><span class="line">            std::<span class="built_in">move</span>(buffer_limiter));</span><br><span class="line"></span><br><span class="line"><span class="comment">// DynamicChunkBufferLimiter 构造函数</span></span><br><span class="line"><span class="built_in">DynamicChunkBufferLimiter</span>(<span class="type">size_t</span> max_capacity, <span class="type">size_t</span> default_capacity,</span><br><span class="line">                          <span class="type">int64_t</span> mem_limit, <span class="type">int</span> chunk_size)</span><br><span class="line">: _capacity(default_capacity),</span><br><span class="line">  _max_capacity(max_capacity),</span><br><span class="line">  _default_capacity(default_capacity),</span><br><span class="line">  _mem_limit(mem_limit) &#123;&#125;</span><br></pre></td></tr></table></figure><h3 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h3><p><em>DynamicChunkBufferLimiter::_pinned_tokens_counter</em> 字段表征当前读取了多少个 chunk，不能超过限制。</p><p>DynamicChunkBufferLimiter::Token 基于 RAII 设计，用户通过 DynamicChunkBufferLimiter::pin 函数对 pinned_tokens_counter 进行累加 <em>num_chunks</em>，并在析构函数中完成恢复，即pinned_tokens_counter 递减 num_chunks。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DynamicChunkBufferLimiter</span> <span class="keyword">final</span> : <span class="keyword">public</span> ChunkBufferLimiter &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Token</span> <span class="keyword">final</span> : <span class="keyword">public</span> ChunkBufferToken &#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Token</span>(std::atomic&lt;<span class="type">int</span>&gt;&amp; pinned_tokens_counter, <span class="type">int</span> num_tokens)</span><br><span class="line">        : _pinned_tokens_counter(pinned_tokens_counter),</span><br><span class="line">          _num_tokens(num_tokens) &#123;&#125;</span><br><span class="line"></span><br><span class="line">        ~<span class="built_in">Token</span>() <span class="keyword">override</span> &#123; </span><br><span class="line">            _pinned_tokens_counter.<span class="built_in">fetch_sub</span>(_num_tokens);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="built_in">DISALLOW_COPY_AND_MOVE</span>(Token);</span><br><span class="line"></span><br><span class="line">        std::atomic&lt;<span class="type">int</span>&gt;&amp; _pinned_tokens_counter;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> _num_tokens;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">update_avg_row_bytes</span><span class="params">(<span class="type">size_t</span> added_sum_row_bytes,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">size_t</span> added_num_rows,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">size_t</span> max_chunk_rows)</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">ChunkBufferTokenPtr <span class="title">pin</span><span class="params">(<span class="type">int</span> num_chunks)</span> <span class="keyword">override</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::atomic&lt;<span class="type">int</span>&gt; _pinned_chunks_counter = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="pin"><a href="#pin" class="headerlink" title="pin"></a>pin</h3><p>ScanOperator 在向存储层读取数据前，先会调用 DynamicChunkBufferLimiter::pin 函数申请一个 Token，是否超过 query 限制的并发读取速率 _capacity。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ChunkBufferTokenPtr <span class="title">DynamicChunkBufferLimiter::pin</span><span class="params">(<span class="type">int</span> num_chunks)</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> prev_value = _pinned_chunks_counter.<span class="built_in">fetch_add</span>(num_chunks);</span><br><span class="line">    <span class="keyword">if</span> (prev_value + num_chunks &gt; _capacity) &#123;</span><br><span class="line">        <span class="comment">// 回滚 counter</span></span><br><span class="line">        _pinned_chunks_counter.<span class="built_in">fetch_sub</span>(num_chunks);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;DynamicChunkBufferLimiter::Token&gt;(</span><br><span class="line">        _pinned_chunks_counter, num_chunks);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么是如此控制着 ScanOperator 读取速率？</p><ol><li>在 ScanOperator::_trigger_next_scan 函数中，提交 io-task 前，会先向 ChunkBufferLimiter 申请一个 Token，<br>ChunkBufferLimiter::pin 判断还有余量，则返回一个 Token 对象， _trigger_next_scan 函数才能提交 io-task。否则限流。  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Status ScanOperator::_trigger_next_scan(</span><br><span class="line">    RuntimeState* state, <span class="type">int</span> chunk_source_index) &#123;</span><br><span class="line"></span><br><span class="line">    ChunkBufferTokenPtr buffer_token;</span><br><span class="line">    <span class="keyword">if</span> (buffer_token = <span class="built_in">pin_chunk</span>(<span class="number">1</span>); buffer_token == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">COUNTER_UPDATE</span>(_submit_task_counter, <span class="number">1</span>);</span><br><span class="line">    _chunk_sources[chunk_source_index]-&gt;<span class="built_in">pin_chunk_token</span>(std::<span class="built_in">move</span>(buffer_token));</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// function detail</span></span><br><span class="line"><span class="function">ChunkBufferTokenPtr <span class="title">OlapScanOperator::pin_chunk</span><span class="params">(<span class="type">int</span> num_chunks)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _ctx-&gt;<span class="built_in">get_chunk_buffer</span>().<span class="built_in">limiter</span>()-&gt;<span class="built_in">pin</span>(num_chunks);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ChunkSource::pin_chunk_token</span><span class="params">(ChunkBufferTokenPtr chunk_token)</span> </span>&#123;</span><br><span class="line">    _chunk_token = std::<span class="built_in">move</span>(chunk_token);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>在 ChunkSource::buffer_next_batch_chunks_blocking 函数中每尝试读取一次 chunk 前都会申请一 Token，只有当 Token 非空，才能继续读取。成功读取到数据后，{Chunk, Token} 作为 Pair 一起缓存到 BalancedChunkBuffer。当执行 BalancedChunkBuffer::try_get 函数时候，Chunk 会被返回给上层，而 Token 的生命周期结束，调用析构函数释放 Token，增加 _pinned_tokens_counter 让后续线程可以继续读取。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ChunkSource::buffer_next_batch_chunks_blocking</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        RuntimeState* state, <span class="type">size_t</span> batch_size, </span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> workgroup::WorkGroup* running_wg)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; batch_size &amp;&amp; !state-&gt;<span class="built_in">is_cancelled</span>(); ++i) &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (_chunk_token == <span class="literal">nullptr</span> &amp;&amp; </span><br><span class="line">                (_chunk_token = _chunk_buffer.<span class="built_in">limiter</span>()-&gt;<span class="built_in">pin</span>(<span class="number">1</span>)) == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            ChunkPtr chunk;</span><br><span class="line">            _status = _read_chunk(state, &amp;chunk);</span><br><span class="line">            <span class="comment">//... </span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// drvier_seq --&gt; &#123;chunk, token&#125;</span></span><br><span class="line">            _chunk_buffer.<span class="built_in">put</span>(_scan_operator_seq,</span><br><span class="line">                              std::<span class="built_in">move</span>(chunk),</span><br><span class="line">                              std::<span class="built_in">move</span>(_chunk_token));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//...</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> _status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="update-avg-row-bytes"><a href="#update-avg-row-bytes" class="headerlink" title="update_avg_row_bytes"></a>update_avg_row_bytes</h3><p>但是读取总的速率也不是额定的，在每次 _read_chunk 后都会更新。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本篇博客阐述 BalancedChunkBuffer 的内部实现，以及如何配合 ChunkBufferLimiter 限读取并发度。&lt;/p&gt;
&lt;h2 id=&quot;BalancedChunkBuffer&quot;&gt;&lt;a href=&quot;#BalancedChunkBuffer&quot; class=</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Morsel 和 OlapScanOperator (3)</title>
    <link href="https://szza.github.io/2023/07/07/Pipeline/MorselQueue_3/"/>
    <id>https://szza.github.io/2023/07/07/Pipeline/MorselQueue_3/</id>
    <published>2023-07-07T02:30:02.000Z</published>
    <updated>2023-09-26T02:32:26.109Z</updated>
    
    <content type="html"><![CDATA[<p>单个 ScanOperator::pull_chunk 从存储层读取数据的流程，如图所示：</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-OlapScanOperator-3.svg?raw=true" alt="Pipeline-OlapScanOperator-3"></p><p>每个 ScanOperator 都是需要从数据源读取数据，比如子类 OlapScanOperator 需要从存储层读取数据，这就涉及到 Io 任务。 StarRocks 将一个 ScanOperator 划分为 <strong>_io_tasks_per_scan_operator</strong> 个 io-tasks（_io_tasks_per_scan_operator 默认值是 4 个）。此外，ScanOperator 将读取到的数据存到 <strong>OlapScanContext::_chunk_buffer</strong> 中，该 ChunkBuffer 是所有 Pipeline ScanOperators 共享，因此是个并发写入的数据结构。由于每个 Pipeline 都有一个唯一的 driver_queue，因此可以作为 ChunkBuffer 的 key，即 ChunkBuffer 内部的映射关系是 <em>{driver_sequeue, SubBuffer}</em> 。</p><p>图中的 ChunkSource 功能类似 TabletReader，不过处理的数据粒度是 Morsel。从前文可知一个 Morsel 的范围可能是一个 Tablet，也可能只是一个 Segment 的部分行数据。一个 io-task 对应一个 ChunkSource，用于从存储层读取数据，并将所有 ChunkSource 读取到的数据缓存到当前 ScanOperator 对应的 ChunkBuffer[driver_seq] 中。</p><p>io-task 是个异步任务，内部调用 ChunkSource 读取数据，该异步任务由 ScanExecutor 执行。ChunkBuffer::try_get 函数获取数据是个非阻塞操作，不会阻塞等待 io-task 成功读取到数据，ScanOperator::pull_chunk 就能返回。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ScanOperator</span> : <span class="keyword">public</span> SourceOperator &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    workgroup::ScanExecutor* _scan_executor = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">mutable</span> std::shared_mutex _task_mutex; <span class="comment">// Protects the chunk-source from concurrent close and read</span></span><br><span class="line">    std::vector&lt;std::atomic&lt;<span class="type">bool</span>&gt;&gt; _is_io_task_running;</span><br><span class="line">    std::vector&lt;ChunkSourcePtr&gt; _chunk_sources;</span><br><span class="line">    <span class="type">int32_t</span> _chunk_source_idx = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">mutable</span> SpinLock _scan_status_mutex;</span><br><span class="line">    Status _scan_status;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ScanOperator-pull-chunk"><a href="#ScanOperator-pull-chunk" class="headerlink" title="ScanOperator::pull_chunk"></a>ScanOperator::pull_chunk</h2><p>下面就直接来看 ScanOperator::pull_chunk 函数执行流程:</p><ul><li><p>所有的 io_tasks 异步从存储层获取数据，如果其中一个 io-task 失败则会调用 <em>_set_scan_status</em> 函数将 <strong>_scan_status</strong> 更改为错误状态，让本次查询任务尽快结束</p></li><li><p>_try_to_trigger_next_scan: 从 MorseQueue 中获取 Morsel，异步从存储层中读取数据（chunk），并缓存在 ChunkBuffer</p></li><li><p>get_chunk_from_buffer: 将 io-task 读取到的数据返回给上层</p><p>  对获得的数据 chunk，会再进行 runtime_bloom_filter 过滤。这个 bloom_filter 不是由用户创建的索引，而是运行时生成的。一般是用于 HashJoin 场景：Build 侧的表会在运行时生成一个 bloom_filter 发送给 Probe 侧，来过滤 Probe 侧的数据，减少需要探测的数据，减少网络开销。</p></li></ul><p>下面代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;vectorized::ChunkPtr&gt; <span class="title">ScanOperator::pull_chunk</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1. </span></span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_get_scan_status());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 统计内存</span></span><br><span class="line">    _peak_buffer_size_counter-&gt;<span class="built_in">set</span>(<span class="built_in">buffer_size</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. </span></span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_try_to_trigger_next_scan(state));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.</span></span><br><span class="line">    vectorized::ChunkPtr res = <span class="built_in">get_chunk_from_buffer</span>();</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">begin_pull_chunk</span>(res);</span><br><span class="line">        <span class="comment">// for query cache mechanism, </span></span><br><span class="line">        <span class="comment">// we should emit EOS chunk when we receive the last chunk.</span></span><br><span class="line">        <span class="keyword">auto</span> [tablet_id, is_eos] = _should_emit_eos(res);</span><br><span class="line">        <span class="built_in">eval_runtime_bloom_filters</span>(res.<span class="built_in">get</span>());</span><br><span class="line">        res-&gt;<span class="built_in">owner_info</span>().<span class="built_in">set_owner_id</span>(tablet_id, is_eos);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="try-to-trigger-next-scan"><a href="#try-to-trigger-next-scan" class="headerlink" title="_try_to_trigger_next_scan"></a>_try_to_trigger_next_scan</h3><p>_try_to_trigger_next_scan 函数的语义是：</p><ul><li>尝试从 _chunk_sources[_chunk_source_idx + 1] 对应的 Morsel 指向的存储文件中继续读取数据。如果 _chunk_sources 中有数据可读，则继续读取，即 _trigger_next_scan 函数完成的功能。 </li><li>没有数据可读的 _chunk_sources[idx] 也不会闲置（即该 _chunk_sources[idx] 对应的 Morsel 对应的数据已经读取完毕），则需要从 MorselQueue 继续获取一个 NextMorsel，创建新的 _chunk_sources[idx]，重新向 ScanExecutor 提交一个 io-task，即 _pickup_morsel 函数完成的功能。</li></ul><p>下面是一些指标：</p><ul><li>_num_running_io_tasks：用于表征当前正在运行的 io-task 数量，不能超过上限 _io_tasks_per_scan_operator</li><li>_is_io_task_running[i]：用于表征 _chunk_sources[i] 正在执行读取操作</li><li>_chunk_source_idx：用于当前正在执行读取操作的 chunk_source</li></ul><p>因为一共有 _io_tasks_per_scan_operator 个 io-tasks，这里采用轮询的方式来看哪个 _chunk_sources[i] 可以继续读取数据，忽略正在读取 chunk_source，并用 to_sched 数组记录已经没有数据可读的 chunk_source:</p><ul><li>_trigger_next_scan: 异步执行 io-task，将读取到的数据缓存到 ChunkBuffer 中</li><li>_pickup_morsel: 从 MorselQueue 获取下一个 morsel，再执行 _trigger_next_scan 函数</li></ul><p>因此，_try_to_trigger_next_scan 函数不会存在阻塞。整体执行逻辑如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Status ScanOperator::_try_to_trigger_next_scan(RuntimeState* state) &#123;</span><br><span class="line">    <span class="type">int</span> total_cnt = _io_tasks_per_scan_operator;</span><br><span class="line">    <span class="keyword">if</span> (_num_running_io_tasks &gt;= _io_tasks_per_scan_operator) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Avoid uneven distribution when io tasks execute very fast, so we start</span></span><br><span class="line">    <span class="comment">// traverse the chunk_source array from last visit idx</span></span><br><span class="line">    <span class="type">int</span> cnt = _io_tasks_per_scan_operator;</span><br><span class="line">    <span class="type">int</span> to_sched[_io_tasks_per_scan_operator];</span><br><span class="line">    <span class="type">int</span> size = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// pick up already started chunk source.</span></span><br><span class="line">    <span class="keyword">while</span> (--cnt &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        _chunk_source_idx = (_chunk_source_idx + <span class="number">1</span>) % _io_tasks_per_scan_operator;</span><br><span class="line">        <span class="type">int</span> i = _chunk_source_idx;</span><br><span class="line">        <span class="keyword">if</span> (_is_io_task_running[i]) &#123;</span><br><span class="line">            total_cnt -= <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (_chunk_sources[i] != <span class="literal">nullptr</span> &amp;&amp; _chunk_sources[i]-&gt;<span class="built_in">has_next_chunk</span>()) &#123;</span><br><span class="line">          <span class="comment">// 仍有数据可读的 chunk_source，则触发 io-task</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_trigger_next_scan(state, i));</span><br><span class="line">            total_cnt -= <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 没有的则记录</span></span><br><span class="line">            to_sched[size++] = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    size = std::<span class="built_in">min</span>(size, total_cnt);</span><br><span class="line">    <span class="comment">// 获取下一个 morsel，创建新的 chunk_source</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        <span class="type">int</span> idx = to_sched[i];</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_pickup_morsel(state, idx));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="pickup-morsel"><a href="#pickup-morsel" class="headerlink" title="_pickup_morsel"></a>_pickup_morsel</h3><p>OlapScanPrepareOperator 和 ScanOperator 共享一个 <strong>_morsel_queue</strong>，因此当 OlapScanPrepareOperator::pull_chunk 函数中完成了 MorselQueue 参数设置，_pick_morsel 就可以通过 MorselQueue::try_get 函数获得 Morsel，并基于获得的 Morsel 创建 OlapChunkSource，赋值给 _chunk_sources[chunk_source_index]。</p><p>完成获取 Morsel 和创建 ChunkSource 就可以进入 <em>_trigger_next_scan</em> 函数从存储层读取数据。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Status ScanOperator::_pickup_morsel(RuntimeState* state, <span class="type">int</span> chunk_source_index) &#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(_morsel_queue != <span class="literal">nullptr</span>);</span><br><span class="line">    _close_chunk_source(state, chunk_source_index);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> attach an active source before really creating it, to avoid the race condition</span></span><br><span class="line">    <span class="type">bool</span> need_detach = <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">attach_chunk_source</span>(chunk_source_index);</span><br><span class="line">    <span class="function">DeferOp <span class="title">defer</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">if</span> (need_detach) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">            detach_chunk_source(chunk_source_index);</span></span></span><br><span class="line"><span class="params"><span class="function">        &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得 Morsel</span></span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> morsel, _morsel_queue-&gt;<span class="built_in">try_get</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//... igonre query cache code</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (morsel != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">COUNTER_UPDATE</span>(_morsels_counter, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 基于 Morsel 创建 chunk_source</span></span><br><span class="line">        _chunk_sources[chunk_source_index] = <span class="built_in">create_chunk_source</span>(std::<span class="built_in">move</span>(morsel), chunk_source_index);</span><br><span class="line">        <span class="keyword">auto</span> status = _chunk_sources[chunk_source_index]-&gt;<span class="built_in">prepare</span>(state);</span><br><span class="line">        <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">            _chunk_sources[chunk_source_index] = <span class="literal">nullptr</span>;</span><br><span class="line">            <span class="built_in">set_finishing</span>(state);</span><br><span class="line">            <span class="keyword">return</span> status;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 从存储层查询</span></span><br><span class="line">        need_detach = <span class="literal">false</span>;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_trigger_next_scan(state, chunk_source_index));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="create-chunk-source"><a href="#create-chunk-source" class="headerlink" title="create_chunk_source"></a>create_chunk_source</h4><p>每个 ChunkSource 都需要：1）一个 Morsel 来指定本次需要读取的数据范围；2）同时需要一个 chunk_buffer 来存储从存储层获得的数据。</p><p>从下面的构造函数传递关系可知，ChunkSource::_chunk_buffer 即 OlapScanContext::_chunk_buffer。又由 OlapScanContextFactory::get_or_create 函数可知，这个 _chunk_buffer 是在 pipeline_dop 个 Pipeline ScanOperators 间共享，即存储着 pipeline_dop 个 Pipeline ScanOperators 从存储层读取的数据。</p><p>因此，这个 chunk_buffer 内部映射关系是 <strong>{driver_sequence, buffer}</strong> 。代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 0.</span></span><br><span class="line"><span class="function">ChunkSourcePtr <span class="title">OlapScanOperator::create_chunk_source</span><span class="params">(MorselPtr morsel,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                     <span class="type">int32_t</span> chunk_source_index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span>* olap_scan_node = <span class="built_in">down_cast</span>&lt;vectorized::OlapScanNode*&gt;(_scan_node);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;OlapChunkSource&gt;(</span><br><span class="line">           <span class="keyword">this</span>, _chunk_source_profiles[chunk_source_index].<span class="built_in">get</span>(),</span><br><span class="line">           std::<span class="built_in">move</span>(morsel), olap_scan_node, _ctx.<span class="built_in">get</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. </span></span><br><span class="line">OlapChunkSource::<span class="built_in">OlapChunkSource</span>(ScanOperator* op, </span><br><span class="line">                                 RuntimeProfile* runtime_profile,</span><br><span class="line">                                 MorselPtr&amp;&amp; morsel,</span><br><span class="line">                                 vectorized::OlapScanNode* scan_node,</span><br><span class="line">                                 OlapScanContext* scan_ctx)</span><br><span class="line">        : <span class="built_in">ChunkSource</span>(op, </span><br><span class="line">                     runtime_profile,</span><br><span class="line">                     std::<span class="built_in">move</span>(morsel),</span><br><span class="line">                     scan_ctx-&gt;<span class="built_in">get_chunk_buffer</span>()), <span class="comment">// 创建 ChubkBuffer</span></span><br><span class="line">          _scan_node(scan_node),</span><br><span class="line">          _scan_ctx(scan_ctx),</span><br><span class="line">          _limit(scan_node-&gt;<span class="built_in">limit</span>()),</span><br><span class="line">          _scan_range(<span class="built_in">down_cast</span>&lt;ScanMorsel*&gt;(_morsel.<span class="built_in">get</span>())-&gt;<span class="built_in">get_olap_scan_range</span>()) &#123;&#125;</span><br><span class="line"></span><br><span class="line">ChunkSource::<span class="built_in">ChunkSource</span>(ScanOperator* scan_op,</span><br><span class="line">                         RuntimeProfile* runtime_profile,</span><br><span class="line">                         MorselPtr&amp;&amp; morsel,</span><br><span class="line">                         BalancedChunkBuffer&amp; chunk_buffer)</span><br><span class="line">        : _scan_op(scan_op),</span><br><span class="line">          _scan_operator_seq(scan_op-&gt;<span class="built_in">get_driver_sequence</span>()),</span><br><span class="line">          _runtime_profile(runtime_profile),</span><br><span class="line">          _morsel(std::<span class="built_in">move</span>(morsel)),</span><br><span class="line">          _chunk_buffer(chunk_buffer), <span class="comment">//  共享一个 ChunkBuffer</span></span><br><span class="line">          _chunk_token(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. </span></span><br><span class="line"><span class="function">OlapScanContextPtr <span class="title">OlapScanContextFactory::get_or_create</span><span class="params">(<span class="type">int32_t</span> driver_sequence)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK_LT</span>(driver_sequence, _dop);</span><br><span class="line">    <span class="comment">// ScanOperators sharing one morsel use the same context.</span></span><br><span class="line">    <span class="type">int32_t</span> idx = _shared_morsel_queue ? <span class="number">0</span> : driver_sequence;</span><br><span class="line">    <span class="built_in">DCHECK_LT</span>(idx, _contexts.<span class="built_in">size</span>());</span><br><span class="line">    <span class="comment">// _chunk_buffer 是 pipeline_dop 个 Pipeline ScanOperators 共享的</span></span><br><span class="line">    <span class="keyword">if</span> (_contexts[idx] == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        _contexts[idx] = std::<span class="built_in">make_shared</span>&lt;OlapScanContext&gt;(</span><br><span class="line">                _scan_node, _dop, _shared_scan, _chunk_buffer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> _contexts[idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="trigger-next-scan"><a href="#trigger-next-scan" class="headerlink" title="_trigger_next_scan"></a>_trigger_next_scan</h4><p>create_chunk_source 函数完成了 ChunkSource 的创建，下面就需要异步从存储层读取数据。 <em>_trigger_next_scan</em> 函数内会封装一个 ScanTask 对象，并向 _scan_executor 提交该 io-task，最终任务由 workgroup::ScanExecutor 执行，</p><p>_trigger_next_scan 函数包含了许多统计信息，下面只是关注功能。从功能上说，就是调用 ChunkSource::buffer_next_batch_chunks_blocking 函数从存储层读取数据。*_finish_chunk_source_task* 用于在读完后更新统计信息。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">Status ScanOperator::_trigger_next_scan(RuntimeState* state, <span class="type">int</span> chunk_source_index) &#123;</span><br><span class="line">    ChunkBufferTokenPtr buffer_token;</span><br><span class="line">    <span class="keyword">if</span> (buffer_token = <span class="built_in">pin_chunk</span>(<span class="number">1</span>); buffer_token == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 0. 更改状态</span></span><br><span class="line">    _chunk_sources[chunk_source_index]-&gt;<span class="built_in">pin_chunk_token</span>(std::<span class="built_in">move</span>(buffer_token));</span><br><span class="line">    _num_running_io_tasks++;</span><br><span class="line">    _is_io_task_running[chunk_source_index] = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 封装 io-task</span></span><br><span class="line">    workgroup::ScanTask task;</span><br><span class="line">    task.workgroup = _workgroup.<span class="built_in">get</span>();</span><br><span class="line">    task.priority =</span><br><span class="line">        vectorized::OlapScanNode::<span class="built_in">compute_priority</span>(_submit_task_counter-&gt;<span class="built_in">value</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> io_task_start_nano = <span class="built_in">MonotonicNanos</span>();</span><br><span class="line">    task.work_function = [wp = _query_ctx, <span class="keyword">this</span>, state, chunk_source_index,</span><br><span class="line">                          query_trace_ctx, driver_id,</span><br><span class="line">                          io_task_start_nano]() &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">auto</span> sp = wp.<span class="built_in">lock</span>()) &#123;</span><br><span class="line">            <span class="built_in">SCOPED_THREAD_LOCAL_MEM_TRACKER_SETTER</span>(</span><br><span class="line">                state-&gt;<span class="built_in">instance_mem_tracker</span>());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">auto</span>&amp; chunk_source = _chunk_sources[chunk_source_index];</span><br><span class="line"></span><br><span class="line">            <span class="comment">//... other statistic info</span></span><br><span class="line">            <span class="type">int64_t</span> prev_cpu_time = chunk_source-&gt;<span class="built_in">get_cpu_time_spent</span>();</span><br><span class="line">            <span class="type">int64_t</span> prev_scan_rows = chunk_source-&gt;<span class="built_in">get_scan_rows</span>();</span><br><span class="line">            <span class="type">int64_t</span> prev_scan_bytes = chunk_source-&gt;<span class="built_in">get_scan_bytes</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 1. 阻塞读取数据</span></span><br><span class="line">            <span class="keyword">auto</span> status = chunk_source-&gt;<span class="built_in">buffer_next_batch_chunks_blocking</span>(</span><br><span class="line">                    state, kIOTaskBatchSize, _workgroup.<span class="built_in">get</span>());</span><br><span class="line">            <span class="keyword">if</span> (!status.<span class="built_in">ok</span>() &amp;&amp; !status.<span class="built_in">is_end_of_file</span>()) &#123;</span><br><span class="line">                _set_scan_status(status);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">int64_t</span> delta_cpu_time = chunk_source-&gt;<span class="built_in">get_cpu_time_spent</span>() - prev_cpu_time;</span><br><span class="line">            <span class="comment">// 2. 更新状态</span></span><br><span class="line">            _finish_chunk_source_task(</span><br><span class="line">                state, chunk_source_index, delta_cpu_time,</span><br><span class="line">                chunk_source-&gt;<span class="built_in">get_scan_rows</span>() - prev_scan_rows,</span><br><span class="line">                chunk_source-&gt;<span class="built_in">get_scan_bytes</span>() - prev_scan_bytes);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 提交 io-task</span></span><br><span class="line">    <span class="keyword">if</span> (_scan_executor-&gt;<span class="built_in">submit</span>(std::<span class="built_in">move</span>(task))) &#123;</span><br><span class="line">        _io_task_retry_cnt = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 3. 失败，则回滚状态</span></span><br><span class="line">        _chunk_sources[chunk_source_index]-&gt;<span class="built_in">unpin_chunk_token</span>();</span><br><span class="line">        _num_running_io_tasks--;</span><br><span class="line">        _is_io_task_running[chunk_source_index] = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 最多失败次数</span></span><br><span class="line">        <span class="keyword">if</span> (++_io_task_retry_cnt &gt; <span class="number">100</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> Status::<span class="built_in">RuntimeError</span>(<span class="string">&quot;ScanOperator failed to offer io task due to thread pool overload&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="buffer-next-batch-chunks-blocking"><a href="#buffer-next-batch-chunks-blocking" class="headerlink" title="buffer_next_batch_chunks_blocking"></a>buffer_next_batch_chunks_blocking</h4><p>buffer_next_batch_chunks_blocking 主要有两步：</p><ul><li>_read_chunk： 从存储层读取数据，由子类实现</li><li>将读取到的数据插入到 _chunk_buffer 中，ChunkSource::_scan_operator_seq 即 _driver_sequence</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ChunkSource::buffer_next_batch_chunks_blocking</span><span class="params">(RuntimeState* state, <span class="type">size_t</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                      <span class="type">const</span> workgroup::WorkGroup* running_wg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> vectorized;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!_status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> _status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> time_spent_ns = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">auto</span> [tablet_id, version] = _morsel-&gt;<span class="built_in">get_lane_owner_and_version</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; batch_size &amp;&amp; !state-&gt;<span class="built_in">is_cancelled</span>(); ++i) &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">SCOPED_RAW_TIMER</span>(&amp;time_spent_ns);</span><br><span class="line">            <span class="keyword">if</span> (_chunk_token == <span class="literal">nullptr</span> &amp;&amp; (_chunk_token = _chunk_buffer.<span class="built_in">limiter</span>()-&gt;<span class="built_in">pin</span>(<span class="number">1</span>)) == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 从存储层读取数据</span></span><br><span class="line">            ChunkPtr chunk;</span><br><span class="line">            _status = _read_chunk(state, &amp;chunk);</span><br><span class="line">            <span class="keyword">if</span> (chunk == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                chunk = std::<span class="built_in">make_shared</span>&lt;vectorized::Chunk&gt;();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//.. ingore if fail to read</span></span><br><span class="line">            chunk-&gt;<span class="built_in">owner_info</span>().<span class="built_in">set_owner_id</span>(tablet_id, <span class="literal">false</span>);</span><br><span class="line">            <span class="comment">// 将读取的数据存在 _chunk_buffer 中</span></span><br><span class="line">            _chunk_buffer.<span class="built_in">put</span>(_scan_operator_seq, std::<span class="built_in">move</span>(chunk), std::<span class="built_in">move</span>(_chunk_token));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (time_spent_ns &gt;= YIELD_MAX_TIME_SPENT) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (running_wg != <span class="literal">nullptr</span> &amp;&amp; time_spent_ns &gt;= YIELD_PREEMPT_MAX_TIME_SPENT &amp;&amp;</span><br><span class="line">            _scan_sched_entity(running_wg)-&gt;<span class="built_in">in_queue</span>()-&gt;<span class="built_in">should_yield</span>(running_wg, time_spent_ns)) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> _status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="get-chunk-from-buffer"><a href="#get-chunk-from-buffer" class="headerlink" title="get_chunk_from_buffer"></a>get_chunk_from_buffer</h3><p>ScanOperator::pull_chunk 第一步在读取完数据后， 第二步就是要从 ChunkSource 中获取数据，第二步由 get_chunk_from_buffer 函数完成。</p><p>从 get_chunk_from_buffer 可以看出，这里 ScanOperator 获得是自己 Pipeline 读取到的数据，即只要自己Pipeline的 io-task 读取到数据就行。</p><p>BalancedChunkBuffer::try_get 这里是个非阻塞等待的操作，如果没有读取到数据，则返回 NULL 给上层，上层任务会任务这个 operator 的 Pipeline 处于 NOT-READY 状态，将其加入 BlockedPipelineDrvier 中，等 Poller 唤醒。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ChunkPtr <span class="title">OlapScanOperator::get_chunk_from_buffer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vectorized::ChunkPtr chunk = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">if</span> (_ctx-&gt;<span class="built_in">get_chunk_buffer</span>().<span class="built_in">try_get</span>(_driver_sequence, &amp;chunk)) &#123;</span><br><span class="line">        <span class="keyword">return</span> chunk;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到此，ScanOperator::pull_chunk 基本流程结束，具体如何从存储层读取数据待后续更新了，目前先关注 Pipeline 引擎。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;单个 ScanOperator::pull_chunk 从存储层读取数据的流程，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeli</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Morsel 和 OlapScanOperator (2)</title>
    <link href="https://szza.github.io/2023/07/05/Pipeline/MorselQueue_2/"/>
    <id>https://szza.github.io/2023/07/05/Pipeline/MorselQueue_2/</id>
    <published>2023-07-05T08:10:02.000Z</published>
    <updated>2023-09-26T02:32:23.346Z</updated>
    
    <content type="html"><![CDATA[<p>和 Morsel 有关的 SourceOperator 的类继承关系如下：<br><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-OlapScanOperator-2.svg?raw=true" alt="Pipeline-OlapScanOperator-2"></p><p>从 Morsel 到 OlapScanOperator 的执行流程如下:<br><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-OlapScanOperator-1.svg?raw=true" alt="Pipeline-OlapScanOperator-1"></p><p>OlapScanPrepareOperator 和 OlapScanOperator 共享一个 MorselQueue，<u>也是通过这个 MorselQueue 建立依赖关系</u>: 当 <em>OlapScanPrepareOperator::pull_chunk</em> 执行完毕，OlapScanOperator::pull_chunk 就可以从该 MorselQueue 中取出 morsel，进而才从存储层中读取数据。</p><p>构建 Pipeline 的过程为这两个 Pipelines 的输入设置了同一个 MorselQueue，具体过程在 <a href="https://github.com/StarRocks/starrocks/blob/a22ef531281e56a84f9b620c8730a184bc8f0019/be/src/exec/pipeline/fragment_executor.cpp#L552C1-L552C1">FragmentExecutor::_prepare_pipeline_driver</a> 函数处。</p><h2 id="OlapScanNode-decompose-to-pipeline"><a href="#OlapScanNode-decompose-to-pipeline" class="headerlink" title="OlapScanNode::decompose_to_pipeline"></a>OlapScanNode::decompose_to_pipeline</h2><p>通过 decompose_to_pipeline 函数将 ExecNode 分解为上图中 Operators，生成两个 Piplines。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">pipeline::OpFactories <span class="title">OlapScanNode::decompose_to_pipeline</span><span class="params">(pipeline::PipelineBuilderContext* context)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Set the dop according to requested parallelism and number of morsels</span></span><br><span class="line">    <span class="keyword">auto</span>* morsel_queue_factory = context-&gt;<span class="built_in">morsel_queue_factory_of_source_operator</span>(<span class="built_in">id</span>());</span><br><span class="line">    <span class="type">size_t</span> dop = morsel_queue_factory-&gt;<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">bool</span> shared_morsel_queue = morsel_queue_factory-&gt;<span class="built_in">is_shared</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> max_buffer_capacity = pipeline::ScanOperator::<span class="built_in">max_buffer_capacity</span>() * dop;</span><br><span class="line">    <span class="type">size_t</span> default_buffer_capacity = std::<span class="built_in">min</span>&lt;<span class="type">size_t</span>&gt;(max_buffer_capacity, <span class="built_in">estimated_max_concurrent_chunks</span>());</span><br><span class="line">    pipeline::ChunkBufferLimiterPtr buffer_limiter = std::<span class="built_in">make_unique</span>&lt;pipeline::DynamicChunkBufferLimiter&gt;(</span><br><span class="line">            max_buffer_capacity, default_buffer_capacity, _mem_limit, <span class="built_in">runtime_state</span>()-&gt;<span class="built_in">chunk_size</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> scan_ctx_factory = std::<span class="built_in">make_shared</span>&lt;pipeline::OlapScanContextFactory&gt;(</span><br><span class="line">            <span class="keyword">this</span>, dop, shared_morsel_queue, _enable_shared_scan, std::<span class="built_in">move</span>(buffer_limiter));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span>&amp;&amp; rc_rf_probe_collector = std::<span class="built_in">make_shared</span>&lt;RcRfProbeCollector&gt;(<span class="number">2</span>, std::<span class="built_in">move</span>(<span class="keyword">this</span>-&gt;<span class="built_in">runtime_filter_collector</span>()));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// scan_prepare_op.</span></span><br><span class="line">    <span class="keyword">auto</span> scan_prepare_op = std::<span class="built_in">make_shared</span>&lt;pipeline::OlapScanPrepareOperatorFactory&gt;(context-&gt;<span class="built_in">next_operator_id</span>(), <span class="built_in">id</span>(),</span><br><span class="line">                                                                                      <span class="keyword">this</span>, scan_ctx_factory);</span><br><span class="line">    scan_prepare_op-&gt;<span class="built_in">set_degree_of_parallelism</span>(shared_morsel_queue ? <span class="number">1</span> : dop);</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">init_runtime_filter_for_operator</span>(scan_prepare_op.<span class="built_in">get</span>(), context, rc_rf_probe_collector);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> scan_prepare_pipeline = pipeline::OpFactories&#123;</span><br><span class="line">            std::<span class="built_in">move</span>(scan_prepare_op),</span><br><span class="line">            std::<span class="built_in">make_shared</span>&lt;pipeline::NoopSinkOperatorFactory&gt;(context-&gt;<span class="built_in">next_operator_id</span>(), <span class="built_in">id</span>()),</span><br><span class="line">    &#125;;</span><br><span class="line">    context-&gt;<span class="built_in">add_pipeline</span>(scan_prepare_pipeline);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// scan_op.</span></span><br><span class="line">    <span class="keyword">auto</span> scan_op = std::<span class="built_in">make_shared</span>&lt;pipeline::OlapScanOperatorFactory&gt;(context-&gt;<span class="built_in">next_operator_id</span>(), <span class="keyword">this</span>,</span><br><span class="line">                                                                       std::<span class="built_in">move</span>(scan_ctx_factory));</span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">init_runtime_filter_for_operator</span>(scan_op.<span class="built_in">get</span>(), context, rc_rf_probe_collector);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pipeline::<span class="built_in">decompose_scan_node_to_pipeline</span>(scan_op, <span class="keyword">this</span>, context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在执行此函数前，已经使用 <a href="https://szza.github.io/2023/07/02/Pipeline/MorselQueue_1/#convert-scan-range-to-morsel-queue-factory">convert-scan-range-to-morsel-queue-factory</a> 函数为每个输入分配了一个 MorselQueueFactory。</p><p>下面需要将每个 OlapScanNode 分解为 Operators，后续再根据 pipeline_dop，生成 pipeline_dop 个 PipelineDrivers，而这 pipeline_dop 个 PipelineDrivers 要么共享一个 MorselQueue，要么每个 PipelineDriver 都分配一个 MorselQueue，具体情况由 MorselQueueFactory::is_shared()d函数来确定：</p><ul><li>SharedMorselQueueFactory::is_shared() 为 true</li><li>IndividualMorselQueueFactory::is_shared() 为 false</li></ul><p>在 <em>shared_morsel_queue</em> 为 true 时，共享同一个 MorselQueue 的 OlapScanOperators，也需要共享同一个 OlapScanContext。此时，会忽略 <em>OlapScanContextFactory::get_or_create</em> 的传入参数 driver_sequence，只创建一个 OlapScanContext 对象。 反之，则创建 pipeline_dop 个 OlapScanContext。逻辑和 <em>MorselQueueFactory::create</em> 函数类似。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">OlapScanContextPtr <span class="title">OlapScanContextFactory::get_or_create</span><span class="params">(<span class="type">int32_t</span> driver_sequence)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK_LT</span>(driver_sequence, _dop);</span><br><span class="line">    <span class="comment">// ScanOperators sharing one morsel use the same context.</span></span><br><span class="line">    <span class="type">int32_t</span> idx = _shared_morsel_queue ? <span class="number">0</span> : driver_sequence;</span><br><span class="line">    <span class="built_in">DCHECK_LT</span>(idx, _contexts.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_contexts[idx] == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        _contexts[idx] = std::<span class="built_in">make_shared</span>&lt;OlapScanContext&gt;(_scan_node, _dop, _shared_scan, _chunk_buffer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> _contexts[idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="OlapScanContext"><a href="#OlapScanContext" class="headerlink" title="OlapScanContext"></a>OlapScanContext</h2><p>OlapScanContextFactory 的构造函数中会根据是否 <em>shared_morsel_queue</em> 的值为 <strong>_contexts</strong> 数组初始化合理大小。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">OlapScanContextFactory</span>(vectorized::OlapScanNode* <span class="type">const</span> scan_node, <span class="type">int32_t</span> dop,</span><br><span class="line">                       <span class="type">bool</span> shared_morsel_queue, <span class="type">bool</span> shared_scan,</span><br><span class="line">                       ChunkBufferLimiterPtr chunk_buffer_limiter)</span><br><span class="line">        : _scan_node(scan_node),</span><br><span class="line">          _dop(dop),</span><br><span class="line">          _shared_morsel_queue(shared_morsel_queue),</span><br><span class="line">          _shared_scan(shared_scan),</span><br><span class="line">          _chunk_buffer(shared_scan ? BalanceStrategy::kRoundRobin : BalanceStrategy::kDirect,</span><br><span class="line">                        dop, std::<span class="built_in">move</span>(chunk_buffer_limiter)),</span><br><span class="line">          _contexts(shared_morsel_queue ? <span class="number">1</span> : dop) &#123;&#125;</span><br></pre></td></tr></table></figure><p>OlapScanContext 字段大致分为以下三部分。</p><ul><li><p>part1: 待读取的数据元信息</p><p>_conjunct_ctxs: 是本次的 SQL 查询中 <strong>where</strong> 后的 AND predicates，以及某些查询条件改写后<br>_not_push_down_conjuncts: 是无法下推到存储层的判断条件<br>_key_ranges: 是本次查询范围<br>_dict_optimize_parser: 用于低基数优化，rewrite 谓词</p></li><li><p>part2: 用于 shared_scan 机制</p></li><li><p>part3: 用于防止本次查询的数据在 SQL 执行过程中被删除了，事先增加一次引用计数</p></li></ul><p>OlapScanContext 字段如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OlapScanContext</span> <span class="keyword">final</span> : <span class="keyword">public</span> ContextWithDependency &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// part1: meta data</span></span><br><span class="line">    vectorized::OlapScanNode* _scan_node;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;ExprContext*&gt; _conjunct_ctxs;</span><br><span class="line">    vectorized::OlapScanConjunctsManager _conjuncts_manager;</span><br><span class="line">    <span class="comment">// The conjuncts couldn&#x27;t push down to storage engine</span></span><br><span class="line">    std::vector&lt;ExprContext*&gt; _not_push_down_conjuncts;</span><br><span class="line">    std::vector&lt;std::unique_ptr&lt;OlapScanRange&gt;&gt; _key_ranges;</span><br><span class="line">    vectorized::DictOptimizeParser _dict_optimize_parser;</span><br><span class="line">    ObjectPool _obj_pool;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// part2: For shared_scan mechanism</span></span><br><span class="line">    <span class="keyword">using</span> ActiveInputKey = std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt;;</span><br><span class="line">    <span class="keyword">using</span> ActiveInputSet = phmap::parallel_flat_hash_set&lt;</span><br><span class="line">            ActiveInputKey, <span class="keyword">typename</span> phmap::Hash&lt;ActiveInputKey&gt;, <span class="keyword">typename</span> phmap::EqualTo&lt;ActiveInputKey&gt;,</span><br><span class="line">            <span class="keyword">typename</span> std::allocator&lt;ActiveInputKey&gt;, NUM_LOCK_SHARD_LOG, std::mutex, <span class="literal">true</span>&gt;;</span><br><span class="line">    BalancedChunkBuffer&amp; _chunk_buffer;</span><br><span class="line">    ActiveInputSet _active_inputs;</span><br><span class="line">    <span class="type">bool</span> _shared_scan;</span><br><span class="line"></span><br><span class="line">    std::atomic&lt;<span class="type">bool</span>&gt; _is_prepare_finished&#123;<span class="literal">false</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// parrt3: avoid to be deleted beacuse of compactions, </span></span><br><span class="line">    <span class="comment">//         increase reference in perpare stage</span></span><br><span class="line">    std::vector&lt;TabletSharedPtr&gt; _tablets;</span><br><span class="line">    std::vector&lt;std::vector&lt;RowsetSharedPtr&gt;&gt; _tablet_rowsets;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="capture-tablet-rowsets"><a href="#capture-tablet-rowsets" class="headerlink" title="capture_tablet_rowsets"></a>capture_tablet_rowsets</h3><p>StarRocks 中 Operators&#x2F;ExecNode 的执行流程基本都是 <code>prepare -&gt; open -&gt; get_next -&gt; close</code>。<br>而 <em>OlapScanContext::capture_tablet_rowsets</em> 会在 OlapScanPrepareOperator::prepare 中执行，<u>防止在 SQL 执行过程中（即 get_next 函数读取数据过程中）tablet&#x2F;rowset 被删除</u>。函数本身是比较简单:</p><ol><li>基于 <em>scan_range-&gt;tablet_id</em> 从 TabletManger 中获得 tablet</li><li>再基于 <em>scan_range-&gt;version</em> 从 tablet 中获得本次需要查询的 rowsets</li></ol><p>代码如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">OlapScanContext::capture_tablet_rowsets</span><span class="params">(<span class="type">const</span> std::vector&lt;TInternalScanRange*&gt;&amp; olap_scan_ranges)</span> </span>&#123;</span><br><span class="line">    _tablet_rowsets.<span class="built_in">resize</span>(olap_scan_ranges.<span class="built_in">size</span>());</span><br><span class="line">    _tablets.<span class="built_in">resize</span>(olap_scan_ranges.<span class="built_in">size</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; olap_scan_ranges.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">        <span class="keyword">auto</span>* scan_range = olap_scan_ranges[i];</span><br><span class="line">        <span class="type">int64_t</span> version = <span class="built_in">strtoul</span>(scan_range-&gt;version.<span class="built_in">c_str</span>(), <span class="literal">nullptr</span>, <span class="number">10</span>);</span><br><span class="line">        <span class="comment">//1. 获得 tablet</span></span><br><span class="line">        <span class="built_in">ASSIGN_OR_RETURN</span>(TabletSharedPtr tablet, vectorized::OlapScanNode::<span class="built_in">get_tablet</span>(scan_range));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Capture row sets of this version tablet.</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 2. 获得 rowset</span></span><br><span class="line">            <span class="function">std::shared_lock <span class="title">l</span><span class="params">(tablet-&gt;get_header_lock())</span></span>;</span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(tablet-&gt;<span class="built_in">capture_consistent_rowsets</span>(<span class="built_in">Version</span>(<span class="number">0</span>, version), &amp;_tablet_rowsets[i]));</span><br><span class="line">            Rowset::<span class="built_in">acquire_readers</span>(_tablet_rowsets[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        _tablets[i] = std::<span class="built_in">move</span>(tablet);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="OlapScanPrepareOperator"><a href="#OlapScanPrepareOperator" class="headerlink" title="OlapScanPrepareOperator"></a>OlapScanPrepareOperator</h2><p>OlapScanPrepareOperator 内就一个 OlapScanContext 字段</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OlapScanPrepareOperator</span> <span class="keyword">final</span> : <span class="keyword">public</span> SourceOperator &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">OlapScanPrepareOperator</span>(OperatorFactory* factory, <span class="type">int32_t</span> id,</span><br><span class="line">                            <span class="type">const</span> string&amp; name, <span class="type">int32_t</span> plan_node_id,</span><br><span class="line">                            <span class="type">int32_t</span> driver_sequence, OlapScanContextPtr ctx)</span><br><span class="line">        : <span class="built_in">SourceOperator</span>(factory, id, name, plan_node_id, driver_sequence), </span><br><span class="line">          _ctx(std::<span class="built_in">move</span>(ctx)) &#123;</span><br><span class="line">        _ctx-&gt;<span class="built_in">ref</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~OlapScanPrepareOperator::~<span class="built_in">OlapScanPrepareOperator</span>() &#123;</span><br><span class="line">       <span class="keyword">auto</span>* state = <span class="built_in">runtime_state</span>();</span><br><span class="line">       <span class="keyword">if</span> (state == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">           <span class="keyword">return</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       _ctx-&gt;<span class="built_in">unref</span>(state);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">Status <span class="title">prepare</span><span class="params">(RuntimeState* state)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">close</span><span class="params">(RuntimeState* state)</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">has_output</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">is_finished</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">StatusOr&lt;vectorized::ChunkPtr&gt; <span class="title">pull_chunk</span><span class="params">(RuntimeState* state)</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    OlapScanContextPtr _ctx;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="pull-chunk"><a href="#pull-chunk" class="headerlink" title="pull_chunk"></a>pull_chunk</h3><p>顾名思义，在 OlapScanPrepareOperator 中需要完成的是准备工作，在这里完成的给每个 SourceOperator::_morsel_queue 检测本次所需读取的 tablets&#x2F;rowsets 是否存在，存在则将其赋值给 _morsel_queue。</p><p>pull_chunk 执行完，OlapScanPrepareOperator 的生命周期就结束了，会进入下一个算子 NoopSinkOperator：<strong>PipelineDriver 检测到 OlapScanPrepareOperator 算子完成后就会将其结果 push 到 NoopSinkOperator 中</strong>。</p><p>由 OlapScanPrepareOperator 和 OpenSacnOperator 共享一个 OlapScanContext，因此 OlapScanPrepareOperator 的下一个算子 NoopSinkOperator::push_chunk 没有任何操作，因为只要 OlapScanPrepareOperator::pull_chunk 执行完毕，则 OpenSacnOperator 的前置依赖就完成了，就可以开始执行：即从存储层中读数据。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">OlapScanPrepareOperator::prepare</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(SourceOperator::<span class="built_in">prepare</span>(state));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_ctx-&gt;<span class="built_in">prepare</span>(state));</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_ctx-&gt;<span class="built_in">capture_tablet_rowsets</span>(_morsel_queue-&gt;<span class="built_in">olap_scan_ranges</span>()));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">StatusOr&lt;vectorized::ChunkPtr&gt; <span class="title">OlapScanPrepareOperator::pull_chunk</span><span class="params">(RuntimeState* state)</span> </span>&#123;</span><br><span class="line">    Status status = _ctx-&gt;<span class="built_in">parse_conjuncts</span>(state, <span class="built_in">runtime_in_filters</span>(), <span class="built_in">runtime_bloom_filters</span>());</span><br><span class="line"></span><br><span class="line">    _morsel_queue-&gt;<span class="built_in">set_key_ranges</span>(_ctx-&gt;<span class="built_in">key_ranges</span>());</span><br><span class="line">    _morsel_queue-&gt;<span class="built_in">set_tablets</span>(_ctx-&gt;<span class="built_in">tablets</span>());</span><br><span class="line">    _morsel_queue-&gt;<span class="built_in">set_tablet_rowsets</span>(_ctx-&gt;<span class="built_in">tablet_rowsets</span>());</span><br><span class="line"></span><br><span class="line">    _ctx-&gt;<span class="built_in">set_prepare_finished</span>();</span><br><span class="line">    <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        _ctx-&gt;<span class="built_in">set_finished</span>();</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">Status <span class="title">NoopSinkOperator::push_chunk</span><span class="params">(RuntimeState* state, <span class="type">const</span> vectorized::ChunkPtr&amp; chunk)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;和 Morsel 有关的 SourceOperator 的类继承关系如下：&lt;br&gt;&lt;img src=&quot;https://github.com/szza/szza.github.io.images/blob/master/StarRocks/Pipeline-OlapScanO</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Morsel 和 OlapScanOperator (1)</title>
    <link href="https://szza.github.io/2023/07/02/Pipeline/MorselQueue_1/"/>
    <id>https://szza.github.io/2023/07/02/Pipeline/MorselQueue_1/</id>
    <published>2023-07-02T08:00:02.000Z</published>
    <updated>2023-09-26T02:32:20.543Z</updated>
    
    <content type="html"><![CDATA[<p>MorselQueue 用于存放本次待读取的数据源 Morsels 集合，继承派生体系如下：</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-morsel-3.svg?raw=true" alt="Morsel-Queue"></p><h3 id="convert-scan-range-to-morsel-queue"><a href="#convert-scan-range-to-morsel-queue" class="headerlink" title="convert_scan_range_to_morsel_queue"></a>convert_scan_range_to_morsel_queue</h3><p><code>convert_scan_range_to_morsel_queue</code> 函数将本次带查询的数据源 <code>scan_ranges</code> 转换成 <code>std::vector&lt;pipeline::Morsel&gt;</code> 对象 <code>morsels</code>，并根据是否能开启 <code>Tablet</code> 选择具体的 MorselQueue 子类。</p><p>因此，区别在于 <code>morsels</code> 在 MorselQueue 内部怎么划分。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;pipeline::MorselQueuePtr&gt; <span class="title">OlapScanNode::convert_scan_range_to_morsel_queue</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::vector&lt;TScanRangeParams&gt;&amp; scan_ranges, </span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> node_id, <span class="type">int32_t</span> pipeline_dop,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">bool</span> enable_tablet_internal_parallel, </span></span></span><br><span class="line"><span class="params"><span class="function">        TTabletInternalParallelMode::type tablet_internal_parallel_mode,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">size_t</span> num_total_scan_ranges)</span> </span>&#123;</span><br><span class="line">    pipeline::Morsels morsels;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; scan_range : scan_ranges) &#123;</span><br><span class="line">        morsels.<span class="built_in">emplace_back</span>(std::<span class="built_in">make_unique</span>&lt;pipeline::ScanMorsel&gt;(node_id, scan_range));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// None tablet to read shouldn&#x27;t use tablet internal parallel.</span></span><br><span class="line">    <span class="keyword">if</span> (morsels.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::FixedMorselQueue&gt;(std::<span class="built_in">move</span>(morsels));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Disable by the session variable shouldn&#x27;t use tablet internal parallel.</span></span><br><span class="line">    <span class="keyword">if</span> (!enable_tablet_internal_parallel) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::FixedMorselQueue&gt;(std::<span class="built_in">move</span>(morsels));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> scan_dop;</span><br><span class="line">    <span class="type">int64_t</span> splitted_scan_rows;</span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> could, _could_tablet_internal_parallel(</span><br><span class="line">                                        scan_ranges, pipeline_dop,</span><br><span class="line">                                        num_total_scan_ranges,</span><br><span class="line">                                        tablet_internal_parallel_mode,</span><br><span class="line">                                        &amp;scan_dop, &amp;splitted_scan_rows));</span><br><span class="line">    <span class="keyword">if</span> (!could) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::FixedMorselQueue&gt;(std::<span class="built_in">move</span>(morsels));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Split tablet physically.</span></span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="type">bool</span> ok, _could_split_tablet_physically(scan_ranges));</span><br><span class="line">    <span class="keyword">if</span> (ok) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::PhysicalSplitMorselQueue&gt;(</span><br><span class="line">                std::<span class="built_in">move</span>(morsels), scan_dop, splitted_scan_rows);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::LogicalSplitMorselQueue&gt;(</span><br><span class="line">            std::<span class="built_in">move</span>(morsels), scan_dop, splitted_scan_rows);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="could-tablet-internal-parallel"><a href="#could-tablet-internal-parallel" class="headerlink" title="_could_tablet_internal_parallel"></a>_could_tablet_internal_parallel</h3><p>变量 <code>enable_tablet_internal_parallel</code> 为 true 时，只是建议开启 tablet 并行，能不能真开启还要使用 <em>_could_tablet_internal_parallel</em> 函数根据实际多个因素判断。</p><ul><li><p>主键模型开启了持久化索引 use_pk_index 为 false</p></li><li><p>tablet_internal_parallel_mode 默认值是 TTabletInternalParallelMode::AUTO，如果不是主动设置为 FORCE_SPLIT，并且实际的读取的 num_total_scan_ranges  &gt;&#x3D; 本次 Pipeline 的并行度 pipeline_dop， 也返回 false</p><p>  如果 num_total_scan_ranges &gt;&#x3D; pipeline_dop，则说明当前有非常多的 tablet 待读取，不应该再把划分，否则会导致很多竞争。</p></li><li><p>统计本次需要读取的行数 num_table_rows</p><p>  config::tablet_internal_parallel_max_splitted_scan_bytes，默认是 512M，是单次从一个 segment 文件中读取的最大字节数，_estimated_scan_row_bytes 本次要读取的所有字段类型的大小（即一行数据的大小），二者相除的结果 splitted_scan_rows 即单次从 segment 文件中读取的最大行数。</p><p>  再将 <strong>splitted_scan_rows</strong> 限制在 <em>[min_splitted_scan_rows, max_splitted_scan_rows]</em> 区间，</p><p>  先估计本次的 <strong>scan_dop</strong> &#x3D; num_table_rows &#x2F; splitted_scan_rows，再将 scan_dop 限制到 [1, pipeline_dop] 区间。</p><p>  只要 scan_dop &gt; pipeline_dop 或者 config::tablet_internal_parallel_min_scan_dop 本函数就返回 true。</p></li></ul><p>因此，如果函数返回 false 上层就直接启用 FixedMorselQueue 来粗存储本次数据源 Morsels，返回 true 则会使用 SplitMorseQueue。</p><p><em>scan_dop</em>, <em>splitted_scan_rows</em> 两个参数输出后再作为 SplitMorselQueue 的参数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">StatusOr&lt;<span class="type">bool</span>&gt; OlapScanNode::_could_tablet_internal_parallel(</span><br><span class="line">        <span class="type">const</span> std::vector&lt;TScanRangeParams&gt;&amp; scan_ranges,</span><br><span class="line">        <span class="type">int32_t</span> pipeline_dop, <span class="type">size_t</span> num_total_scan_ranges,</span><br><span class="line">        TTabletInternalParallelMode::type tablet_internal_parallel_mode,</span><br><span class="line">        <span class="type">int64_t</span>* scan_dop, <span class="type">int64_t</span>* splitted_scan_rows) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (_olap_scan_node.use_pk_index) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">bool</span> force_split = tablet_internal_parallel_mode == TTabletInternalParallelMode::type::FORCE_SPLIT;</span><br><span class="line">    <span class="comment">// The enough number of tablets shouldn&#x27;t use tablet internal parallel.</span></span><br><span class="line">    <span class="keyword">if</span> (!force_split &amp;&amp; num_total_scan_ranges &gt;= pipeline_dop) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> num_table_rows = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; tablet_scan_range : scan_ranges) &#123;</span><br><span class="line">        <span class="built_in">ASSIGN_OR_RETURN</span>(TabletSharedPtr tablet,</span><br><span class="line">             <span class="built_in">get_tablet</span>(&amp;(tablet_scan_range.scan_range.internal_scan_range)));</span><br><span class="line">        num_table_rows += <span class="built_in">static_cast</span>&lt;<span class="type">int64_t</span>&gt;(tablet-&gt;<span class="built_in">num_rows</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// splitted_scan_rows is restricted in the range [min_splitted_scan_rows, max_splitted_scan_rows].</span></span><br><span class="line">    *splitted_scan_rows = config::tablet_internal_parallel_max_splitted_scan_bytes / _estimated_scan_row_bytes;</span><br><span class="line">    *splitted_scan_rows =</span><br><span class="line">            std::<span class="built_in">max</span>(config::tablet_internal_parallel_min_splitted_scan_rows,</span><br><span class="line">                     std::<span class="built_in">min</span>(*splitted_scan_rows, config::tablet_internal_parallel_max_splitted_scan_rows));</span><br><span class="line">    <span class="comment">// scan_dop is restricted in the range [1, dop].</span></span><br><span class="line">    *scan_dop = num_table_rows / *splitted_scan_rows;</span><br><span class="line">    *scan_dop = std::<span class="built_in">max</span>&lt;<span class="type">int64_t</span>&gt;(<span class="number">1</span>, std::<span class="built_in">min</span>&lt;<span class="type">int64_t</span>&gt;(*scan_dop, pipeline_dop));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (force_split) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> could = *scan_dop &gt;= pipeline_dop || *scan_dop &gt;= config::tablet_internal_parallel_min_scan_dop;</span><br><span class="line">    <span class="keyword">return</span> could;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="FixedMorselQueue"><a href="#FixedMorselQueue" class="headerlink" title="FixedMorselQueue"></a>FixedMorselQueue</h2><p>顾名思义，<code>FixedMorselQueue</code> 存储是固定数据量的 Morsels，<code>FixedMorselQueue::_morsels</code> 都是 ScanMorsel 对象（不是 ScanMorsel 的子类），即是以 tablet 为级别，后续 TabletReader 要从存储层查询该 _morsels[i] 指向的数据时，是需要 FullScan。</p><p>当从 OlapScanOperator 从存储层获得数据后，才会调用 <code>FixedMorselQueue::set_tablet_rowsets</code> 函数将数据赋值给 <code>_tablet_rowsets</code>，进而 ScanOperator::pull 就可以从 <code>FixedMorselQueue::try_get</code> 函数从 _tablet_rowsets 中获得数据，</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FixedMorselQueue</span> <span class="keyword">final</span> : <span class="keyword">public</span> MorselQueue &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">FixedMorselQueue</span><span class="params">(Morsels&amp;&amp; morsels)</span></span></span><br><span class="line"><span class="function">            : _morsels(std::move(morsels)), _num_morsels(_morsels.size()), _pop_index(<span class="number">0</span>) &#123;</span>&#125;</span><br><span class="line">    ~<span class="built_in">FixedMorselQueue</span>() <span class="keyword">override</span> = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::vector&lt;TInternalScanRange*&gt; <span class="title">olap_scan_ranges</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">set_tablet_rowsets</span><span class="params">(<span class="type">const</span> std::vector&lt;std::vector&lt;RowsetSharedPtr&gt;&gt;&amp; tablet_rowsets)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">        _tablet_rowsets = tablet_rowsets;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">num_original_morsels</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; </span><br><span class="line">        <span class="keyword">return</span> _num_morsels; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">max_degree_of_parallelism</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; </span><br><span class="line">        <span class="keyword">return</span> _num_morsels; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">empty</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; </span><br><span class="line">        <span class="keyword">return</span> _unget_morsel == <span class="literal">nullptr</span> &amp;&amp; _pop_index &gt;= _num_morsels; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">StatusOr&lt;MorselPtr&gt; <span class="title">try_get</span><span class="params">()</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::string <span class="title">name</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; </span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;fixed_morsel_queue&quot;</span>; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Morsels _morsels;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> _num_morsels;</span><br><span class="line">    std::atomic&lt;<span class="type">size_t</span>&gt; _pop_index;</span><br><span class="line">    std::vector&lt;std::vector&lt;RowsetSharedPtr&gt;&gt; _tablet_rowsets;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="FixedMorselQueue-try-get"><a href="#FixedMorselQueue-try-get" class="headerlink" title="FixedMorselQueue::try_get"></a>FixedMorselQueue::try_get</h3><p>FixedMorselQueue 是有可能在多个 Pipeline 线程之间共享，即共享数据源，多个 Pipelines 同时从 FixedMorselQueue 获取数据源信息。而 FixedMorselQueue::_morsels 大小在构造函数已经确定，且 FixedMorselQueue 内部不会再细分每个 morsel（和 SplitMorselQueue 的对比），因此可以将 FixedMorselQueue 设计成 LookFree 的数据结构，因此使用 _pop_index 来指向当前已经分配的 morsel 就能满足要求。</p><p>在 FixedMorselQueue::try_get 中，通 <strong>std::move</strong> 将 _morsels[idx]、_tablet_rowsets[idx] 中的数据转移给上层，这样不会破坏 _morsels、_tablet_rowsets 结构，在多线程只读场景下就不用 mutex 保护。当 _pop_index &#x3D;&#x3D; _num_morsels, _tablet_rowsets 和 _morsels 就是大小为 _num_morsels 的空壳。如此，也就实现了 LookFree。</p><p>源码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;MorselPtr&gt; <span class="title">FixedMorselQueue::try_get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 和 QueryCache 有关</span></span><br><span class="line">    <span class="keyword">if</span> (_unget_morsel != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">move</span>(_unget_morsel);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> idx = _pop_index.<span class="built_in">load</span>();</span><br><span class="line">    <span class="comment">// prevent _num_morsels from superfluous addition</span></span><br><span class="line">    <span class="keyword">if</span> (idx &gt;= _num_morsels) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    idx = _pop_index.<span class="built_in">fetch_add</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (idx &lt; _num_morsels) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!_tablet_rowsets.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            _morsels[idx]-&gt;<span class="built_in">set_rowsets</span>(std::<span class="built_in">move</span>(_tablet_rowsets[idx]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">move</span>(_morsels[idx]);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="SplitMorselQueue"><a href="#SplitMorselQueue" class="headerlink" title="SplitMorselQueue"></a>SplitMorselQueue</h2><p>scan_dop 传递给 SplitMorselQueue::_degree_of_parallelism，后续用于生成 MorselQueueFactory。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SplitMorselQueue::<span class="built_in">SplitMorselQueue</span>(Morsels&amp;&amp; morsels,</span><br><span class="line">                                   <span class="type">int64_t</span> degree_of_parallelism,</span><br><span class="line">                                   <span class="type">int64_t</span> splitted_scan_rows)</span><br><span class="line">  : _morsels(std::<span class="built_in">move</span>(morsels)),</span><br><span class="line">    _num_original_morsels(_morsels.<span class="built_in">size</span>()),</span><br><span class="line">    _degree_of_parallelism(degree_of_parallelism),</span><br><span class="line">    _splitted_scan_rows(splitted_scan_rows) &#123;&#125;</span><br></pre></td></tr></table></figure><p>SplitMorselQueue 有两个子类，根据 _could_split_tablet_physically 函数来选择。只有在表类型是聚合模型（即 AGG_KEYS 或者 UNIQUE_KEYS）且数据尚未聚合完成（skip_aggr 为 false）时，该函数才会返回 false。</p><p>返回 true 时，选择 PhysicalSplitMorselQueue，否则选择 LogicalSplitMorselQueue 对象。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">StatusOr&lt;<span class="type">bool</span>&gt; OlapScanNode::_could_split_tablet_physically(<span class="type">const</span> std::vector&lt;TScanRangeParams&gt;&amp; scan_ranges) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="comment">// Keys type needn&#x27;t merge or aggregate.</span></span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(TabletSharedPtr first_tablet, <span class="built_in">get_tablet</span>(&amp;(scan_ranges[<span class="number">0</span>].scan_range.internal_scan_range)));</span><br><span class="line">    KeysType keys_type = first_tablet-&gt;<span class="built_in">tablet_schema</span>().<span class="built_in">keys_type</span>();</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> skip_aggr = <span class="built_in">thrift_olap_scan_node</span>().is_preaggregation;</span><br><span class="line">    <span class="keyword">return</span> keys_type == PRIMARY_KEYS || keys_type == DUP_KEYS ||</span><br><span class="line">           ((keys_type == UNIQUE_KEYS || keys_type == AGG_KEYS) &amp;&amp; skip_aggr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="PhysicalSplitMorselQueue-try-get"><a href="#PhysicalSplitMorselQueue-try-get" class="headerlink" title="PhysicalSplitMorselQueue::try_get"></a>PhysicalSplitMorselQueue::try_get</h3><p>StarRocks 中数据持久化后文件的基本单位是 Segment，一个 Tablet 数据组织结构是 Tablet&#x2F;Rowset&#x2F;Segment，每次从 Segment 中读取的行数是 _splitted_scan_rows，因此可以将 PhysicalSplitMorselQueue::try_get 分为两个部分:</p><ol><li><p>检测 _cur_segment 是否为空，以及 _cur_segment 是还有剩余可读数据</p><p> 如果没有，则需要从磁盘中能读取下一个 Segment 文件，将其加载到内存中，生成 SegemntIterator 对象 <strong>_segment_range_iter</strong>，再进行下一步</p>   <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;MorselPtr&gt; <span class="title">PhysicalSplitMorselQueue::try_get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (_tablet_idx &gt;= _tablets.<span class="built_in">size</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// When it hasn&#x27;t initialized any segment,</span></span><br><span class="line">    <span class="comment">// or _segment_idx exceeds the segments of the current rowset,</span></span><br><span class="line">    <span class="comment">// or current segment is empty or finished,</span></span><br><span class="line">    <span class="comment">// we should pick up the next segment and init it.</span></span><br><span class="line">    <span class="keyword">while</span> (!_has_init_any_segment </span><br><span class="line">           || _cur_segment() == <span class="literal">nullptr</span> </span><br><span class="line">           || _cur_segment()-&gt;<span class="built_in">num_rows</span>() == <span class="number">0</span> ||</span><br><span class="line">           !_segment_range_iter.<span class="built_in">has_more</span>()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!_next_segment()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">auto</span> status = _init_segment(); !status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">            <span class="comment">// Morsel_queue cannot generate morsels after errors occurring.</span></span><br><span class="line">            _tablet_idx = _tablets.<span class="built_in">size</span>();</span><br><span class="line">            <span class="keyword">return</span> status;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>当仍有待读取的数据，则通过 <em>_segment_range_iter</em> 获取下一个批次数据（即 _splitted_scan_rows 行），如果剩余的数据不足 _splitted_scan_rows 行，则将剩余的数据合并到当前批次，（合并）生成一个 PhysicalSplitScanMorsel 对象，其中本次读取的元信息 <strong>{rowset, segment_id, token_range}</strong> 精确指示了本次要读取的数据位置，最终在读取数据时，用于初始化 <em>OlapChunkSource::_params</em> 参数的 <strong>rowid_range_option</strong> 字段。</p><p> 这里的 _tablet_rowsets[_tablet_idx] 就不能用 std::move 赋值给 Morsel 了，因为其他线程也要使用。</p> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function">StatusOr&lt;MorselPtr&gt; <span class="title">PhysicalSplitMorselQueue::try_get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(_mutex)</span></span>;</span><br><span class="line">     <span class="comment">//... above code</span></span><br><span class="line"></span><br><span class="line">    vectorized::SparseRange taken_range;</span><br><span class="line">    _segment_range_iter.<span class="built_in">next_range</span>(_splitted_scan_rows, &amp;taken_range);</span><br><span class="line">    _num_segment_rest_rows -= taken_range.<span class="built_in">span_size</span>();</span><br><span class="line">    <span class="keyword">if</span> (_num_segment_rest_rows &lt; _splitted_scan_rows) &#123;</span><br><span class="line">        <span class="comment">// If there are too few rows left in the segment, take them all this time.</span></span><br><span class="line">        _segment_range_iter.<span class="built_in">next_range</span>(_splitted_scan_rows, &amp;taken_range);</span><br><span class="line">        _num_segment_rest_rows = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span>* scan_morsel = _cur_scan_morsel();</span><br><span class="line">    <span class="keyword">auto</span>* rowset = _cur_rowset();</span><br><span class="line">    <span class="keyword">auto</span> rowid_range = std::<span class="built_in">make_shared</span>&lt;vectorized::RowidRangeOption&gt;(</span><br><span class="line">            rowset-&gt;<span class="built_in">rowset_id</span>(),</span><br><span class="line">            rowset-&gt;<span class="built_in">segments</span>()[_segment_idx]-&gt;<span class="built_in">id</span>(),</span><br><span class="line">            std::<span class="built_in">move</span>(taken_range));</span><br><span class="line"></span><br><span class="line">    MorselPtr morsel = std::<span class="built_in">make_unique</span>&lt;PhysicalSplitScanMorsel&gt;(</span><br><span class="line">            scan_morsel-&gt;<span class="built_in">get_plan_node_id</span>(),</span><br><span class="line">            *(scan_morsel-&gt;<span class="built_in">get_scan_range</span>()), </span><br><span class="line">            std::<span class="built_in">move</span>(rowid_range));</span><br><span class="line">    morsel-&gt;<span class="built_in">set_rowsets</span>(_tablet_rowsets[_tablet_idx]);</span><br><span class="line">    _inc_num_splits(_is_last_split_of_current_morsel());</span><br><span class="line">    <span class="keyword">return</span> morsel;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="next-segment"><a href="#next-segment" class="headerlink" title="_next_segment"></a>_next_segment</h4><p>寻找下个 <em>segment</em> 是比较简单的，依次按照 segment_id&#x2F;rowset_id&#x2F;tablet_id 递增的顺序。比如，如果当前 rowset 的 segments 读取完，则 ++rowset_id，切换到当前 tablet 的下一个 rowset，如果当前 tablet 的所有 rowsets 都读取完毕，则 ++tablet_id，切换到下一个 tablet。</p><p>当 tablet_id &gt;&#x3D; _tablets.size()，_next_segment 函数返回 false，表示所有数据都已经读取完毕。</p><p>这部分代码比较简单。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Rowset* PhysicalSplitMorselQueue::_cur_rowset() &#123;</span><br><span class="line">    <span class="keyword">return</span> _tablet_rowsets[_tablet_idx][_rowset_idx].<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Segment* PhysicalSplitMorselQueue::_cur_segment() &#123;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; segments = _cur_rowset()-&gt;<span class="built_in">segments</span>();</span><br><span class="line">    <span class="keyword">return</span> _segment_idx &gt;= segments.<span class="built_in">size</span>() ? <span class="literal">nullptr</span> : segments[_segment_idx].<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> PhysicalSplitMorselQueue::_next_segment() &#123;</span><br><span class="line">    <span class="built_in">DCHECK</span>(_num_segment_rest_rows == <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (!_has_init_any_segment) &#123;</span><br><span class="line">        _has_init_any_segment = <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Read the next segment of the current rowset.</span></span><br><span class="line">        <span class="keyword">if</span> (++_segment_idx &gt;= _cur_rowset()-&gt;<span class="built_in">segments</span>().<span class="built_in">size</span>()) &#123;</span><br><span class="line">            _segment_idx = <span class="number">0</span>;</span><br><span class="line">            <span class="comment">// Read the next rowset of the current tablet.</span></span><br><span class="line">            <span class="keyword">if</span> (++_rowset_idx &gt;= _tablet_rowsets[_tablet_idx].<span class="built_in">size</span>()) &#123;</span><br><span class="line">                _rowset_idx = <span class="number">0</span>;</span><br><span class="line">                <span class="comment">// Read the next tablet.</span></span><br><span class="line">                ++_tablet_idx;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> _tablet_idx &lt; _tablets.<span class="built_in">size</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="inti-segment"><a href="#inti-segment" class="headerlink" title="_inti_segment"></a>_inti_segment</h4><p>初始化 segment 要复杂点。但是也可以大致分为两个步骤：</p><ol><li><p>加载元数据</p><p> 针对每个 Tablet 都有一个查询范围 **{_range_start_key, _Range_end_key}**，两边是开闭还是闭区间由 <strong>{_range_start_op, _range_end_op}</strong> 表示。比如，如果 _range_xxx_op 中包含等于操作即闭区间，否则是开区间，这两个符号定义如下:</p> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum class</span> <span class="title class_">RangeStartOperation</span> &#123; GT = <span class="number">0</span>, GE, EQ &#125;;</span><br><span class="line"><span class="keyword">enum class</span> <span class="title class_">RangeEndOperation</span> &#123; LT = <span class="number">0</span>, LE, EQ &#125;;</span><br></pre></td></tr></table></figure><p> 第一步主要是将 OlapScanRange 类型的 {_range_start_key, _range_end_key} 转化为 SeekRange 类型的 _tablet_seek_ranges，这样方便后续遍历。</p><p> 注意：这里的 <em>_range_start_key</em> 和 <em>_range_end_key</em> 都是 std::vector 类型，可能包含多个查询范围，比如 1 &lt; x &lt;&#x3D; 2, 10 &lt; y &lt; 20，而起始条件都在 _range_start_key 中，终止条件都在 _Range_end_key 中。</p><p> <strong>顺带提下</strong>，在读过程中，数据的内存分配方式基本都是基于内存池 MemPool。这个 MemPool 只是缓存作用，实际内部分配内存的操作是由 ChunkAllocator 完成，其分配内存特点是先在线程所在 core 上分配，如果线程所在 core 上分配的内存超过了限制（默认2G）则会 cross-core 分配，这样可以减少线程跨 core 通信。</p><p>因为数据读取的单位是 Segment，当 segment &#x3D;&#x3D; 0 即表示需要从一个新的 Rowset 中读取数据，因此需要先调用 Rowset::load 函数初始化 Rowset::_segments，来获悉所有 semgnet 信息。</p><p>如果，当前 rowset 没有可读的数据，则 return。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Status PhysicalSplitMorselQueue::_init_segment() &#123;</span><br><span class="line">   <span class="comment">// Load the meta of the new rowset and the index of the new segment。</span></span><br><span class="line">   <span class="keyword">if</span> (<span class="number">0</span> == _segment_idx) &#123;</span><br><span class="line">       <span class="comment">// Read a new tablet.</span></span><br><span class="line">       <span class="keyword">if</span> (<span class="number">0</span> == _rowset_idx) &#123;</span><br><span class="line">           _tablet_seek_ranges.<span class="built_in">clear</span>();</span><br><span class="line">           _mempool.<span class="built_in">clear</span>();</span><br><span class="line">           <span class="built_in">RETURN_IF_ERROR</span>(vectorized::TabletReader::<span class="built_in">parse_seek_range</span>(</span><br><span class="line">               _tablets[_tablet_idx], _range_start_op, _range_end_op,</span><br><span class="line">               _range_start_key, _range_end_key, </span><br><span class="line">               &amp;_tablet_seek_ranges, &amp;_mempool));</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">// Read a new rowset.</span></span><br><span class="line">       <span class="built_in">RETURN_IF_ERROR</span>(_cur_rowset()-&gt;<span class="built_in">load</span>());</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   _num_segment_rest_rows = <span class="number">0</span>;</span><br><span class="line">   _segment_scan_range.<span class="built_in">clear</span>();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">auto</span>* segment = _cur_segment();</span><br><span class="line">   <span class="comment">// The new rowset doesn&#x27;t contain any segment.</span></span><br><span class="line">   <span class="keyword">if</span> (segment == <span class="literal">nullptr</span> || segment-&gt;<span class="built_in">num_rows</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">       <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">//...</span></span><br></pre></td></tr></table></figure></li><li><p>step(1) 过后，得到可迭代的 <strong>_tablet_seek_ranges</strong>，下面就需要将其转化为在 Segment 中的所有读取范围，并合并到 <strong>_segment_scan_range</strong> 中。</p><p>而且 _segment_scan_range 中每一个 range 的起始位置 {lower_rowid, upper_rowid} 都待读取数据的行号，因此后续读取效率会非常高。 </p><p>比如找某个 key 在 segment 的上限位置，这是由于 _upper_bound_ordinal 函数：尝试将该 key 根据表的 short_keys 编码成 index_key，再在该 segment 中利用二分搜索定位到 key 在 segment 文件中的上限位置 <em>end</em>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">rowid_t</span> PhysicalSplitMorselQueue::_upper_bound_ordinal(Segment* segment, <span class="type">const</span> vectorized::SeekTuple&amp; key, <span class="type">bool</span> lower,</span><br><span class="line">                                                       <span class="type">rowid_t</span> end) <span class="type">const</span> &#123;</span><br><span class="line">    std::string index_key =</span><br><span class="line">            key.<span class="built_in">short_key_encode</span>(segment-&gt;<span class="built_in">num_short_keys</span>(), lower ? KEY_MINIMAL_MARKER : KEY_MAXIMAL_MARKER);</span><br><span class="line">    <span class="comment">// 定位到 key 在 segment 中的上限</span></span><br><span class="line">    <span class="keyword">auto</span> end_iter = segment-&gt;<span class="built_in">upper_bound</span>(index_key);</span><br><span class="line">    <span class="keyword">if</span> (end_iter.<span class="built_in">valid</span>()) &#123;</span><br><span class="line">        end = end_iter.<span class="built_in">ordinal</span>() * segment-&gt;<span class="built_in">num_rows_per_block</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> end;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以， <em>_upper_bound_ordinal</em> 函数也说明了step(1) 中将 OlapScanRange 转为 SeekTuple 类型的原因，因为 SeekTuple 包含每一行的 Schema，可以对查找的 key 基于 short_keys 进行编码。最后得到的 <code>_segment_scan_range</code> 即表征了 curr_segment 要读取的数据范围。</p><p>第二部分完整的代码如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"> Status PhysicalSplitMorselQueue::_init_segment() &#123;</span><br><span class="line">    <span class="comment">//...above code</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Find the rowid range of each key range in this segment.</span></span><br><span class="line">    <span class="keyword">if</span> (_tablet_seek_ranges.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        _segment_scan_range.<span class="built_in">add</span>(vectorized::<span class="built_in">Range</span>(<span class="number">0</span>, segment-&gt;<span class="built_in">num_rows</span>()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(segment-&gt;<span class="built_in">load_index</span>());</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; range : _tablet_seek_ranges) &#123;</span><br><span class="line">            <span class="type">rowid_t</span> lower_rowid = <span class="number">0</span>;</span><br><span class="line">            <span class="type">rowid_t</span> upper_rowid = segment-&gt;<span class="built_in">num_rows</span>();</span><br><span class="line"></span><br><span class="line">             <span class="comment">// 上限</span></span><br><span class="line">            <span class="keyword">if</span> (!range.<span class="built_in">upper</span>().<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                upper_rowid = _upper_bound_ordinal(segment,</span><br><span class="line">                                                   range.<span class="built_in">upper</span>(),</span><br><span class="line">                                                   !range.<span class="built_in">inclusive_upper</span>(),</span><br><span class="line">                                                   segment-&gt;<span class="built_in">num_rows</span>());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 下限</span></span><br><span class="line">            <span class="keyword">if</span> (!range.<span class="built_in">lower</span>().<span class="built_in">empty</span>() &amp;&amp; upper_rowid &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                lower_rowid = _lower_bound_ordinal(segment,</span><br><span class="line">                                                   range.<span class="built_in">lower</span>(),</span><br><span class="line">                                                   range.<span class="built_in">inclusive_lower</span>());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 在 segment 中， 一个可读取的 range 就产生了</span></span><br><span class="line">            <span class="keyword">if</span> (lower_rowid &lt;= upper_rowid) &#123;</span><br><span class="line">                _segment_scan_range.<span class="built_in">add</span>(vectorized::Range&#123;lower_rowid, upper_rowid&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    _segment_range_iter = _segment_scan_range.<span class="built_in">new_iterator</span>();</span><br><span class="line">    _num_segment_rest_rows = _segment_scan_range.<span class="built_in">span_size</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="MorselQueueFactory"><a href="#MorselQueueFactory" class="headerlink" title="MorselQueueFactory"></a>MorselQueueFactory</h2><p>MorselQueue 创建完后，就要准备创建 MorselQueueFactory。因为后续由 MorselQueueFactory 将 MorselQueue 分配给 PipelineDriver。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-morsel-2.svg?raw=true" alt="pipeline-morsel-2"></p><p>顾名思义，<strong>SharedMorselQueueFactory</strong> 即所有的 PipelineDrivers 共享一个 MorselQueue，此时就要求该 MorselQueue 具有较好的并发性能，比如FixedMorselQueue，而 IndividualMorselQueueFactory 则为每个 PipelineDriver 都分配一个 MorselQueue。</p><p>通过 Factory 创建 MorselQueue 的函数如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">MorselQueue* <span class="title">SharedMorselQueueFactory::create</span><span class="params">(<span class="type">int</span> driver_sequence)</span> <span class="keyword">override</span> </span>&#123; </span><br><span class="line">    <span class="keyword">return</span> _queue.<span class="built_in">get</span>(); </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 每个 PipelineDrvier 都有一个 driver_sequence</span></span><br><span class="line"><span class="function">MorselQueue* <span class="title">IndividualMorselQueueFactory::create</span><span class="params">(<span class="type">int</span> driver_sequence)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="built_in">DCHECK_LT</span>(driver_sequence, _queue_per_driver_seq.<span class="built_in">size</span>());</span><br><span class="line">    <span class="keyword">return</span> _queue_per_driver_seq[driver_sequence].<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="convert-scan-range-to-morsel-queue-factory"><a href="#convert-scan-range-to-morsel-queue-factory" class="headerlink" title="convert_scan_range_to_morsel_queue_factory"></a>convert_scan_range_to_morsel_queue_factory</h3><p>在创建 Factory 前，需要先由 <em>convert_scan_range_to_morsel_queue</em> 函数获得 MorselQueue，再根据 frontend 优化器是否设置了 <code>scan_ranges_per_driver_seq</code> 来做一些决策。</p><ul><li><p>大多数情况下，<code>scan_ranges_per_driver_seq</code> 都不为空，即每个 PipelineDriver 已经分配好了自己要读取的 scan_range，则直接使用 convert_scan_range_to_morsel_queue 函数每个 PipelineDriver 生成 MorselQueue，并添加到 pipeline::IndividualMorselQueueFactory 对象中暂存。</p></li><li><p>如果 <code>scan_ranges_per_driver_seq</code> 为空，则为全局要读取的数据范围 global_scan_ranges 创建对应的 MorselQueue。</p><p>MorselQueue::max_degree_of_parallelism() 表征同时支持的读取并行度，比如 FixedMorseQueue 的 max_degree_of_parallelism 即 _morsel_size，最多只允许 _morsel_size 一起读取。而 SplitMorselQueue 的 max_degree_of_parallelism 则是在 _could_tablet_internal_parallel 函数中计算出来的 scan_dop。</p><blockquote><p>到底是什么规模想要用 FixedMorselQueue</p></blockquote></li></ul><p>这部分代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;pipeline::MorselQueueFactoryPtr&gt; <span class="title">ScanNode::convert_scan_range_to_morsel_queue_factory</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::vector&lt;TScanRangeParams&gt;&amp; global_scan_ranges,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::map&lt;<span class="type">int32_t</span>, std::vector&lt;TScanRangeParams&gt;&gt;&amp; scan_ranges_per_driver_seq,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> node_id, <span class="type">int</span> pipeline_dop, </span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">bool</span> enable_tablet_internal_parallel,</span></span></span><br><span class="line"><span class="params"><span class="function">        TTabletInternalParallelMode::type tablet_internal_parallel_mode)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (scan_ranges_per_driver_seq.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> morsel_queue,</span><br><span class="line">                         <span class="built_in">convert_scan_range_to_morsel_queue</span>(</span><br><span class="line">                            global_scan_ranges, node_id, pipeline_dop,</span><br><span class="line">                            enable_tablet_internal_parallel,</span><br><span class="line">                            tablet_internal_parallel_mode,</span><br><span class="line">                            global_scan_ranges.<span class="built_in">size</span>()));</span><br><span class="line">        <span class="type">int</span> scan_dop = std::<span class="built_in">min</span>&lt;<span class="type">int</span>&gt;(std::<span class="built_in">max</span>&lt;<span class="type">int</span>&gt;(<span class="number">1</span>, </span><br><span class="line">                                                   morsel_queue-&gt;<span class="built_in">max_degree_of_parallelism</span>()), </span><br><span class="line">                                     pipeline_dop);</span><br><span class="line">        <span class="type">int</span> io_parallelism = scan_dop * <span class="built_in">io_tasks_per_scan_operator</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If not so much morsels, try to assign morsel uniformly among operators to avoid data skew</span></span><br><span class="line">        <span class="keyword">if</span> (scan_dop &gt; <span class="number">1</span> &amp;&amp; <span class="built_in">dynamic_cast</span>&lt;pipeline::FixedMorselQueue*&gt;(morsel_queue.<span class="built_in">get</span>()) &amp;&amp;</span><br><span class="line">            morsel_queue-&gt;<span class="built_in">num_original_morsels</span>() &lt;= io_parallelism) &#123;</span><br><span class="line">            <span class="keyword">auto</span> morsel_queue_map = <span class="built_in">uniform_distribute_morsels</span>(std::<span class="built_in">move</span>(morsel_queue), scan_dop);</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::IndividualMorselQueueFactory&gt;(</span><br><span class="line">                std::<span class="built_in">move</span>(morsel_queue_map), <span class="comment">/*could_local_shuffle*/</span> <span class="literal">true</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::SharedMorselQueueFactory&gt;(</span><br><span class="line">                std::<span class="built_in">move</span>(morsel_queue), scan_dop);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">size_t</span> num_total_scan_ranges = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, scan_ranges] : scan_ranges_per_driver_seq) &#123;</span><br><span class="line">            num_total_scan_ranges += scan_ranges.<span class="built_in">size</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        std::map&lt;<span class="type">int</span>, pipeline::MorselQueuePtr&gt; queue_per_driver_seq;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [dop, scan_ranges] : scan_ranges_per_driver_seq) &#123;</span><br><span class="line">            <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> queue,</span><br><span class="line">                             <span class="built_in">convert_scan_range_to_morsel_queue</span>(</span><br><span class="line">                                scan_ranges, node_id, pipeline_dop,</span><br><span class="line">                                enable_tablet_internal_parallel,</span><br><span class="line">                                tablet_internal_parallel_mode,</span><br><span class="line">                                num_total_scan_ranges));</span><br><span class="line">            queue_per_driver_seq.<span class="built_in">emplace</span>(dop, std::<span class="built_in">move</span>(queue));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::IndividualMorselQueueFactory&gt;(</span><br><span class="line">            std::<span class="built_in">move</span>(queue_per_driver_seq), <span class="comment">/*could_local_shuffle*/</span> <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下一部分从 SourceOperator 角度看怎么获取 Morsels 去存储层获取数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;MorselQueue 用于存放本次待读取的数据源 Morsels 集合，继承派生体系如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipel</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>COLUMBIA 查询优化器如何提升性能（上）</title>
    <link href="https://szza.github.io/2023/06/15/Paper/Columbia-Query-Optimizer-1/"/>
    <id>https://szza.github.io/2023/06/15/Paper/Columbia-Query-Optimizer-1/</id>
    <published>2023-06-15T02:20:00.000Z</published>
    <updated>2023-08-26T17:48:00.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>COLUMBIA 项目聚焦于效率：如何在不损害拓展性的前提下，使设计实现的 Columbia Query Optimizer 获得巨大的<em>性能</em>提升。</p><p>本项目是基于 Cascades Optimizer Framework 的 Top-Down 优化算法，并通过重构搜索空间和搜索算法来简化 Top-Down 优化器设计：通过实现两种裁剪技术（pruning techniques）取得了极大的性能提升。此外，通过增加友好的用户接口和广泛的跟踪支持（extensive tracing support）来提升本项目的可用性。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>尽管查询优化（query optimization）成为研究项目已经超过15年，但是 query optimizers 仍是关系数据库中最大最复杂模型之一，这使得他们的开发和变动成为困难且耗时的任务。随着现代数据库的需要发展，这一情形会变得更加复杂，因此催生了新的技术。</p><p>在过去的几年里，也开发了几代商业和研究性质的优化器，在拓展性和效率做出提升：</p><ol><li>第一代致力于可拓展的优化器技术，认识到在新数据模型（new data models）、查询类别（query class）、语言和评估技术（evaluation techniques）等方面存在需求。因此诞生了一些列项目，诸如 Exodus、Starburst，他们的目标是使优化器更加模块化，更易于拓展。他们使用到的技术包括 layering of components、基于规则的转化等。这些成果存在一些短处，比如增加拓展的复杂度、搜索性能以及更加偏向于于面向记录的数据模型(record-oriented data module)</li><li>第二代可拓展的优化器，诸如 Volcano optimizer generator，增加了更加复杂的搜索技术，更多地使用了物理属性来指导搜索以及更好地控制搜索策略来实现更好的搜索性能。虽然这些优化器在一定程度上更加灵活了，但是仍难以拓展</li><li>第三代优化器，诸如 Cascades、OPT++, EROC 和 METU，开始使用面向对象技术（object-oriented design）来简化实现、拓展和更改优化器，与之同时保持效率并且是的搜索策略更为灵活。这最新一代的优化器已经达到的复杂程度，已可以满足现代商业数据库系统的要求。这一点可以从他们的工业实现（Cascades by Microsoft and Tandem, EROC by NCR）也可以看出。</li></ol><p>按照<em>搜索策略</em>划分，这三代查询优化器可以被归位两类：</p><ol><li>Starburst style: bottom-up dynamic programming optimizers </li><li>Cascades style: top-down branch and bound rule-driven cost based optimizers</li></ol><p>bottom-up 优化算法当前广泛用于传统商业数据库系统中，因为至少在传统应用中被认为是有效的。但是由于 bottom-up 算法要求将原始问题分解为子问题，使其相比较 Top-down 算法，bottom-up 优化算法与生俱来就缺乏可拓展性。此外，为了在大查询中实现可以接受的性能，bottom-up 类算法中必须要用启发式（heuristics）策略。</p><p>尽管在此之前的 top-down 优化器实现已表明此类优化器难以实现和 DownTop相匹敌的性能，但是本论文认为 top-down 优化器在<em>效率</em>上和拓展能力一样有优势。因此为论证这一观点，本论文的剩余部分就是描述我们如何设计另一个 top-down 优化器: Columbia </p><p>Columbia 优化器在 Cascades Optimizer Framework 的基础上，广泛利用 C++ 面向对象的特性以及细心的工程师，来啊简化 top-down 算法，进而维持 top-down 拓展性的同时实现提升性能的目的，本论文算法只定义了少量关键的带有虚函数的抽象基类，根据这些基类来完整实现搜索策略。这些搜索策略调用这些基类的虚函数来执行具体地搜索，并基于成本（cost-based）对搜索空间进行裁剪。</p><p>因此，<em>从这些抽象基类派生新的子类并重写基类虚函数</em>，就可以轻松拓展优化器来操作其他的复杂数据模型、添加新的 operators 和转化规则。故而本文聚焦于关系数据模型中的优化，不再讨论优化器的拓展性。</p><p>为了，减少 CPU 和 Memory 的使用率，本论文的 Columbia 框架会使用几个工程技术来提升效率，诸如：</p><ul><li>一个快速的 hash function 来消除重复的表达式；</li><li>一个 group exepression 中 logical expressions 和 physical expressions 的分离</li><li>小而紧凑的数据结构</li><li>有效的算法来优化分组和输入</li><li>efficient way to handle enforcers (that is what</li></ul><p>Columbia 优化器提供了两个重要的技术：</p><ol><li><p><em>group pruning</em>：这个技术这极大地裁剪了搜索空间，并且毫不损害生成的执行计划。在低层次（low-level）物理计划生成前，优化器会先计算高层次（high-level）物理计划的代价（cost），这些提前计算的代价用于后续优化代价上限，本文后面将会展示在很多场景下，这些上限可以避免生成整个 group expressions，进而裁剪搜索空间中大量可能的查询计划。</p></li><li><p><em>global epsilon pruning</em>：这个技术通过生成可以接受的次优方案（close-to-optimal solutions）来裁剪搜索空间。当一个solution足够接近最优方案，那么这个优化目标就算完成了，进而许多其他的路径就可以忽略。</p></li></ol><h2 id="2-Terminology"><a href="#2-Terminology" class="headerlink" title="2. Terminology"></a>2. Terminology</h2><p>本章主要回顾查询优化文献中的术语和基本概念，这些也将用于描述 Columbia 框架的设计和实现。</p><h3 id="2-1-Query-Optimization"><a href="#2-1-Query-Optimization" class="headerlink" title="2.1. Query Optimization"></a>2.1. Query Optimization</h3><p>查询处理的目的是从 DML 提取出表达式，并基于数据库的数据进行评估。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-1.jpg?raw=true" alt="optimizer-1"></p><p>图1 展示了查询处理的步骤，</p><ol><li>DML 语句中的原始查询被解析成代数上的逻辑表达式树（logical expression tree），</li><li>接着这逻辑表达式树传递给查询优化器，将逻辑查询转换为物理计划：物理执行计划就可以在真正持有数据的数据结构上执行</li></ol><p>这个过程会执行两种转化：</p><ul><li><p><em>Logical transformations</em>：创建查询可能的逻辑形式（logical forms）</p></li><li><p><em>physical transformations</em>：选择一个特别的物理算法来实现一个逻辑算子（logical operator），比如使用 sort-merge join 来实现 logical join</p><p>  通常，这个过程会生成大量的执行计划来实现逻辑查询树，因此需要查询优化器主要关注的就是如何找到最优的执行计划，即代价最低的路径。只要选中一个最优物理计划，就会被传递给查询执行引擎（query execution engine）。查询执行引擎使用有序数据作为输入来执行物理计划，得到的查询到结果即整个输出。</p></li></ul><p>如果我们只关注用户层，那么查询处理过程就被隐藏在查询处理器的黑盒之中。用户提交SQL请求时，希望系统正确又快速输出结果。正确性（Correctness）是查询处理器的基本要求，而性能（performance）是查询处理器所需要的特性和主要关注点。从查询处理的系统层次看，查询优化器在数据库系统的高性能至关重要。</p><p>生成的物理计划中，包含了大量能完成正确性的执行计划，但是具有迥异的执行性能（execution performance），优化器的目标之一就是发现最佳执行性能的物理计划。<code>一个朴素的方法就是生成所有可能的路径，然后遍历选择代价最低的路径</code>。但是，遍历所有可能的路径的代价是极其高的，因此即便是非常简单的查询语句都会生成大量的路径，因此优化器必须以某种方式缩小搜索空间。</p><p>查询优化是个复杂的搜索问题，研究表名这个问题的简单版本就是NP-hard。一个搜索策略对于优化器成功与否至关重要。</p><h3 id="2-2-Logical-Operators-and-Query-Tree"><a href="#2-2-Logical-Operators-and-Query-Tree" class="headerlink" title="2.2. Logical Operators and Query Tree"></a>2.2. Logical Operators and Query Tree</h3><p>逻辑算子 <em>Logical operators</em> 属于高级（high level）算子，仅表征了数据转换关系，并不指定使用哪种具体的物理执行算法。在关系数据模型中，Logical operators 接受多个表作为输入，并产生单表输出。每个 logical operator 接受固定数量的输入（输入的数量叫做 <em>arity</em>），并有多个用于区分 operators 变体的参数。</p><p>有两个经典的 logical operators：</p><ul><li><em>GET Operator</em>：即Scan操作，他没有输入的table，并且有一个表名参数。GET Operator 从磁盘中获取数据，并输出给后续的Operators</li><li><em>EQJOIN Operator</em>：有两个输入table，即进行JOIN操作的左表、右表，输入的参数包含着和左表、右表相关的predicates。</li></ul><p>查询树（query tree） 是 query 的树形结构表征方式，并被用于优化器的输入。一般地，查询树会被表征为 logical operators 的树形结构，每个 TreeNode 都是一个 logical operator，有零个或者多个 logical operators 作为输入，这个 TreeNode 的子节点数量等于输入的 logical operators 的数量，也即 <em>arity</em>。这个查询树的叶结点即 <em>arity &#x3D; 0</em> 的 operators（比如 GET Operator）。</p><p>图-2 是个查询的树形表征的例子。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-2.jpg?raw=true" alt="optimizer-2"></p><p>query trees 用于指定执行 operators 的顺序，比如为了执行查询树上的 top operator，那他的输入就必须先执行。在图-2的例子中 EQJOIN operator 的两个输入，接受的就是两个 GET operators 的输出。而 EQJOIN 的输入参数，即 <code>Emp.dno=Dept.dno</code>，描述的就是 JOIN 的条件。而这个 EQJOIN 的输出即整个查询所需的结果。GET operators 没有输入，因此他们就是叶节点，用于产生本次查询评估所需的数据源，而 GET operator 的输入参数表征的是所需读取表的表名，比如 Empt、Dept。</p><h3 id="2-3-Physical-Operators-and-Execution-Plan"><a href="#2-3-Physical-Operators-and-Execution-Plan" class="headerlink" title="2.3. Physical Operators and Execution Plan"></a>2.3. Physical Operators and Execution Plan</h3><p>Physical operators 表征的实现特定数据操作的具体算法。在数据库中，对于一个 logical operators，通常存在一个或者多个 physical operators 实现。</p><ul><li>EQJOIN logical operator 可以使用 nested-loops、sort-merge join 或者其他算法来啊实现，而具体的算法也可以使用不同的 physical operator来实现，比如 nested-loops 一般是用 LOOP-JOIN physical operator实现，而 sort-merge 算法一般是用 MERGE-JOIN physical operator实现。</li><li>GET logical operator 的经典实现算法是按照表的存储顺序进行 scan，一般是使用 FILE_SCAN physcail operator。</li></ul><p>将查询树中的 logical operators 替换为 physical operators 就产生了一棵 physical operators 树，一般叫做执行计划（<em>Execution Plan</em>）。图-3 展示了由图-2查询计划生成的两个执行计划。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-3.jpg?raw=true" alt="optimizer-3"></p><p>执行计划具体说明了如何评估查询（evaluate the query）：每个执行计划都有一个执行成本，对应着 cost model 和catalog infomation。对于一个指定查询，优化器生成的最优执行计划会作为查询执行引擎的输入，执行引擎会基于数据库系统中的数据执行整个算法来产生本次查询的输出结果。</p><h3 id="2-4-Groups"><a href="#2-4-Groups" class="headerlink" title="2.4. Groups"></a>2.4. Groups</h3><p>给定的查询可以由另一个在逻辑上等价的查询树来表征：如果两个查询树在任何主流的数据库上的输出都完全相同，则他们是 <em>逻辑上等价的</em>。通常，每一个查询树都有一个或者多个执行计划来实现查询树并产生完全相同的结果，那么这些执行计划就是逻辑上等价的。</p><p>图-4 展示了几个逻辑等价的查询树以及实现这些查询树产生逻辑等价的执行计划。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-4.jpg?raw=true" alt="optimizer-4"></p><p>如图-4所示，我们使用 $\Join$ 符号来表征 EQJOIN operator，$\Join_L$ 表征 LOOPS_JOIN operator，$\Join_M$ 表征 MERGE_JOIN。出于简洁的目的，使用参数表征 GET，加上下标F表征 FILE_SCAN，比如图-4中使用 $C$ 表征 GET(“C”)，用 $C_F$ 表征 FILE_SCAN(“C”)。</p><p>图4(a) 和 图4(b) 是两个逻辑等价的查询树，差别只在于 logical operator 的顺序；(a-i) 个 (a-ii)是两个逻辑等价的执行计划，他们的区别在于使用不同的JOIN算法。</p><p>那么我就可以使用 <em>expressions</em> 来表征查询树和执行计划（以及他们的子节点）：一个 expression 由一个 operator 和它的零个或者多个输入组成，根据 operator 的类型这个 expression 也被区分为 logical expression 和 physical expression，因此查询树即 <em>logical expressions</em>，执行计划即 <em>physcical expressions</em>。</p><p>考虑到一个 logical expression 就存在大量逻辑等价的 logical expressions 以及生成的 physical expressions，如果将他们都放入到一个 <em>group</em> 中并定义他们的共同特征（common characteristics）就变得非常有用。</p><p><em>Group</em> 是一组逻辑等价的 exprssions 集合。<code>一般地，一个 group 包含所有逻辑等价的 logical expressions，以及基于他们生成的逻辑等价的 physical expressions</code>。显然，group 中的每个 logical expression 对应的 physical expressions 不止一个。图-5展示的 group 包含了图-4中表达式的以及其他的等价表达式，</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-5.jpg?raw=true" alt="optimizer-5"></p><p>我们通常用其中一个 logical expressions 来表示一个 <em>group</em>，比如 $(A \Join B) \Join C$，或直接使用 $[ABC]$。图-5 中展示了 $[ABC]$ group 中所有等价的逻辑表达式及部分物理表达式。从图-5中可以看到，即便是逻辑表达式也存在大量等价的表达形式。</p><p>为了减少 group 中表达式的数量，引入 <em>Multi-Expressions</em>。一个  <em>Multi-Expressions</em> 有一个 logical&#x2F;physical operator，并将 groups 作为输入。 multi-expression 和 expression 不同点在于输入： 前者以 groups 作为输入，后者以其他 expressions 作为输入。比如 Multi-expression $[A \Join B] \Join [C]$ 表示 EQJOIN operator 的输入是 $[A \Join B]$ 和  $[C]$ 两个 group。由于在一个 group 中鲜有等价的 multi-expression，因此能极大得节省搜索空间。</p><p>图-6 展示了 group [ABC] 中等价的 <em>Multi-Expressions</em>，相比较图-5 中 Expression 的数量更少。 也就说通过使用 <em>Multi-Expressions</em>，就可以将 group 重新定义为一系列等价 <em>Multi-Expressions</em> 的集合。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-6.jpg?raw=true" alt="optimizer-6"></p><p>在查询的通用处理过程中，在生成最终结果前会先产生许多中间结果，即许多tuples的集合。而中间结果就是通过计算一个 group 对应的执行计划得到的。换言之，group 就对应着中间结果，而这些groups被叫为 <em>intermediate groups</em>，而生成最终结果的group，就叫做 <em>final group</em>。</p><p>The Logical properties of a group are defined as the logical properties of the result, regardless of how the result is physically computed and organized. These properties include the cardinality (number of tuples), the schema, and other properties. Logical properties apply to all expressions in a group</p><h4 id="logical-properties"><a href="#logical-properties" class="headerlink" title="logical properties"></a>logical properties</h4><p>一个group中的所有expressions共享一个 <em>logical properties</em>，它被定义为这个group输出结果的逻辑属性，而不在乎结果实际上的计算、组织方式。 <em>logical properties</em> 包括：</p><ul><li>cardinality: tuples 的数量，即行数</li><li>schema</li><li>其他属性</li></ul><h3 id="2-5-The-Search-Space"><a href="#2-5-The-Search-Space" class="headerlink" title="2.5. The Search Space"></a>2.5. The Search Space</h3><p><em>search space</em> 表示给定初始查询的逻辑查询树和物理计划。为了节省搜索空间，将 search space 表征为 group 集合，每个 group 都将其他 groups 作为输入，而最上层的 group 也就是 final group(root group)，它对应着初始查询的最终结果。 图-7 展示了一个查询的初始搜索空间(initial search space)。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-7.jpg?raw=true" alt="optimizer-7"></p><p>在 initial search space 中，每个 group 仅包含一个源自于 initial query tree 的 logical expression。</p><blockquote><p>也就是说，在生成初始搜索空间后，每个 group 需要基于已有的 logical expression 生成逻辑等价的新表达式。</p></blockquote><p>在图-7 中，最上层的 group $[ABC]$ 就是该查询的最终输出，即 final group，它就是图-7中三个 join 的最终结果。</p><p>我们可以从一个 <em>initial search space</em> 获得一个 <em>initial query tree</em>。query tree 上的每个节点（node）都对应着搜索空间中每个 group 的 Multi-expression 上的 operator。</p><p>比如，fig-7 中有 final group $[ABC]$ ，它由 $EQJOIN$ operator 和 $[AB], [C]$ 两个输入 groups 组成。我们可以获得这么一个 query tree：以 EQJOIN 作为最上层的 operator，输入的 Operator 源于 $[AB], [C]$  两个 groups，然后分别递归 $[AB], [C]$ 两个 groups 直到遇到没有输入的groups，即叶子组。</p><p>从 initial search space 派生出来的 query tree 就刚好是 initial query tree。换言之，initial search space 表征了 initial query tree。</p><p>在优化的过程中， 每个 group 会生成大量逻辑上等价的 logical expressions 和 physical expressions，进而导致搜索空间急剧膨胀。与此同时，在生成 physical expressions 的过程中，这些 physical expressions 的执行代价（ execution costs）也都会被计算出来。在某种意义上，生成所有的 physical expressions 就是优化器的目标，然后从中找到代价最低的 physical expression即可。但是为了生成所有 physical expressions，就必须先构造出所有的 logical expressions，这是因为physical expression 只是 logical expression 的一种实现。</p><p>一个完全被膨胀的搜索空间被叫作 final search space，即表示了一个查询的所有逻辑上等价的 expressions。</p><p>实际上，使用递归的方式可以从 final search space 获得所有可能的 query tree 和 exec plan，就像使用递归方式从 initial serach space 获得 initial query tree。 在搜索空间中，每个 Multi-expressions 上的 operator 对应着着 query tree 上的一个 operator node 或者一个执行计划。</p><p>由于搜索空间中的一个 group 就包含了大量逻辑上等价的表达式，那么 final search space 也会呈现了大量的 query trees 和 execution plans。</p><p>表-1 显示了由 N 个表 JOIN 得到的完整逻辑搜索空间（仅显示了 logical expressions 的数量）。比如， 4 个表进行 JOIN 的逻辑搜索空间就有15个 groups，包含了 54 个 logical expressions，呈现了120个query trees。</p><p>从表-1可以看出，即便只考虑 logical expressions，搜索空间的大小也会随着 JOIN 的表增多而呈现指数趋势增长。而 logical expressions 的数量取决于 logical operator 有多少种算法实现。比如当前搜索空间中有 N 个 logical expressions，并且数据库系统支持 M (M &gt;&#x3D; 1) 种  join 算法实现，那么搜索空间就将会有 $M * N$ 个 logical expressions，也就说 physical expressions 的数量不会少于 logical expressions 的数量。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-table-1.jpg?raw=true" alt="optimizer-table-1"></p><h3 id="2-6-Rules"><a href="#2-6-Rules" class="headerlink" title="2.6. Rules"></a>2.6. Rules</h3><p><em>rule</em> 描述得是如何将一个表达式转化为一个在逻辑上等价的新表达式。因此，许多优化器会通过使用 rules 来对一个 initial query 生成一系列逻辑上等价的表达式，达到扩充 initial search space 的目的。</p><p>每个 rule 都会被定义为一个pair:</p><ul><li><em>pattern</em>: 定义的是输入的 logical expressions 的结构，即什么样的输入表达式可以应用这条 rule（注意: rule 仅能用应用于 logical expressions），</li><li><em>subsitute</em>: 定义的是输入表达式在应用这条规则之后，输出结果的结构</li></ul><p>当扩充搜索空间时，优化器会审视每个 logical expression 并检查 rules set 中是否存在 rule 的 pattern 能与该表达式相匹配。如果存在，则会根据 rule 中 substitute 定义的输出表达式结构，应用这条规则来生成新的逻辑上等价的表达式。</p><p>Cascades 使用表达式来表示 pattern 和 substitues: 其中 pattern 总是 logical expressions，而 subsitutes 即可以是 logical expressions 也可以是 physical expressions。</p><p>rules 的两种通用类型是:</p><ul><li><em>Transformation rules</em>: 当 substitute 是 logical expression 时， rule 被叫做 transformation rules。</li><li><em>implementation rules</em>: 当 substitute 是 physical expression 时， rule 被叫做 implementation rules。</li></ul><p>如图-8，$EQJOIN_LTOR$ 就是一种 transformation rule，$EQJOIN_MERGEJOIN$ 就是一种 implementation rules。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/optimizer-8.jpg?raw=true" alt="optimizer-8"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ABSTRACT&quot;&gt;&lt;a href=&quot;#ABSTRACT&quot; class=&quot;headerlink&quot; title=&quot;ABSTRACT&quot;&gt;&lt;/a&gt;ABSTRACT&lt;/h2&gt;&lt;p&gt;COLUMBIA 项目聚焦于效率：如何在不损害拓展性的前提下，使设计实现的 Columbia</summary>
      
    
    
    
    
    <category term="Papers" scheme="https://szza.github.io/tags/Papers/"/>
    
  </entry>
  
  <entry>
    <title>Overview: StarRocks Pipeline Query Executor</title>
    <link href="https://szza.github.io/2023/05/07/Pipeline/Overview/"/>
    <id>https://szza.github.io/2023/05/07/Pipeline/Overview/</id>
    <published>2023-05-07T08:00:02.000Z</published>
    <updated>2023-09-26T02:32:28.794Z</updated>
    
    <content type="html"><![CDATA[<p>如图-1是 StarRocks Pipeline 的整体执行结构:</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-1.svg?raw=true" alt="pipeline-1"></p><p>对比论文中 Morsel-Driven Parallelism[1] 第三节中的 figure-5 与 StarRocks Pipeline 实现中，概念映射关系大致如下：</p><ul><li>QEPObject 即 PipelineDriverPoller，负责将前置依赖都已经 Ready 的 Pipeline 传递给 Dispatcher</li><li>Task 即 PipelineDriver，是可执行任务单元，由两部分组成：输入（Morsel） + 处理流（PipelineJob）。</li><li>Dispatcher 即 DriverQueue，是存储 PipelineDriver 的任务队列，可以根据优先级（Resource Group）或者 FIFO 方式任务分发</li><li><em>Morsel List</em> 即 MorselQueue，根据优化器，自动选择不同的 MorselQueue</li></ul><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-5.jpg?raw=true" alt="figure-5"> </p><h2 id="GlobalDriverExecutor"><a href="#GlobalDriverExecutor" class="headerlink" title="GlobalDriverExecutor"></a>GlobalDriverExecutor</h2><p>所有的任务都是在一组固定的线程池 <code>GlobalDriverExecutor::_thread_pool</code> 中执行。默认是使用当前CPU的核数 <em>CpuInfo::num_cores()<em>，也可以设置参数</em>config::pipeline_exec_thread_pool_thread_num</em> 指定线程池数目。 在 <code>GlobalDriverExecutor::initialize</code> 函数中启动 _max_executor_threads 个线程，函数入口 是 <code>GlobalDriverExecutor::work_thread</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// in ExecEnv::_init(const std::vector&lt;StorePath&gt;&amp; store_paths)</span></span><br><span class="line">std::unique_ptr&lt;ThreadPool&gt; driver_executor_thread_pool;</span><br><span class="line">_max_executor_threads = CpuInfo::<span class="built_in">num_cores</span>();</span><br><span class="line"><span class="keyword">if</span> (config::pipeline_exec_thread_pool_thread_num &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    _max_executor_threads = config::pipeline_exec_thread_pool_thread_num;</span><br><span class="line">&#125;</span><br><span class="line">_max_executor_threads = std::<span class="built_in">max</span>&lt;<span class="type">int64_t</span>&gt;(<span class="number">1</span>, _max_executor_threads);</span><br><span class="line"><span class="built_in">RETURN_IF_ERROR</span>(<span class="built_in">ThreadPoolBuilder</span>(<span class="string">&quot;pip_executor&quot;</span>) <span class="comment">// pipeline executor</span></span><br><span class="line">                        .<span class="built_in">set_min_threads</span>(<span class="number">0</span>)</span><br><span class="line">                        .<span class="built_in">set_max_threads</span>(_max_executor_threads)</span><br><span class="line">                        .<span class="built_in">set_max_queue_size</span>(<span class="number">1000</span>)</span><br><span class="line">                        .<span class="built_in">set_idle_timeout</span>(MonoDelta::<span class="built_in">FromMilliseconds</span>(<span class="number">2000</span>))</span><br><span class="line">                        .<span class="built_in">build</span>(&amp;driver_executor_thread_pool));</span><br><span class="line">_driver_executor = <span class="keyword">new</span> pipeline::<span class="built_in">GlobalDriverExecutor</span>(<span class="string">&quot;pip_exe&quot;</span>, std::<span class="built_in">move</span>(driver_executor_thread_pool), <span class="literal">false</span>);</span><br><span class="line">_driver_executor-&gt;<span class="built_in">initialize</span>(_max_executor_threads);</span><br></pre></td></tr></table></figure><h2 id="Morsel"><a href="#Morsel" class="headerlink" title="Morsel"></a>Morsel</h2><p>Morsel 是 PipelineDriver 的输入。StarRocks 中一个 Morsel 的结构如下：</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-morsel-1.svg?raw=true" alt="pipeline-morsel-1"></p><p>顶层基类 <em>Morsel</em> 中的 <code>_from_version</code> 是为了实现 Query Cache，只需要从文件系统中增量读取 <code>[_from_version, version]</code> 部分的数据，而 <code>[0, _from_version)</code> 部分的数据就可以从 Lrucache 中读取，其中<code>_version</code> 存储在子类 ScanMorsel 中。</p><p>基类 <em>ScanMorsel</em> 更加具体化地存储了本次要读取的数据元信息 <code>&#123;_tablet_id, _version&#125;</code>。如果 Morsel 可以进一步在划分，根据划分方式派生了两个子类。</p><h3 id="OlapScanNode-convert-scan-range-to-morsel-queue"><a href="#OlapScanNode-convert-scan-range-to-morsel-queue" class="headerlink" title="OlapScanNode::convert_scan_range_to_morsel_queue"></a>OlapScanNode::convert_scan_range_to_morsel_queue</h3><p>如下代码，是将本次待查询的 <code>scan_ranges</code> 根据 Pipeline 并行度 <code>pipeline_dop</code> 转化为 OlapScanOperator 中待查询数据的元信息，即 <code>Morsel</code>对象。流程如下：</p><ol><li><p>先将 <em>scan_ranges</em> 一一对应的方式转化为 ScanMorsel</p></li><li><p>如果不开启 tablet 内并行，则使用 FixedMorselQueue 数据结构来存储本次 query 待处理的数据源 <code>Morsels</code></p><p> <code>enable_tablet_internal_parallel</code> 默认值是 true，是个 SessionVariable，用户在每次查询中都可以更改该值。即便该值为 true，也不一定真会进行子划分， 由 Morsel-Driven Parallelism[1] 论文可知，Morsel Size 不建议太小，否则会带因为多线程竞争导致性能惩罚。因此 <code>_could_tablet_internal_parallel</code> 函数会基于本次查询的数据量进行估计，判断是否真需要开启。</p></li><li><p>如果开启，则每个 Morsel Size 估计在 <code>splitted_scan_rows</code> 左右。</p><p> 具体的划分方式由 <code>_could_split_tablet_physically</code> 函数来确定。</p></li></ol><p>这个函数是在构建 Pipelines 的过程中：数据源划分好后，一个 MorselQueue 和一个 Pipeline 构成一个 PipelineDriver。一个完整的 Scan 任务被划分为 pipline_dop 个 OlapScanOperator 并行执行。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;pipeline::MorselQueuePtr&gt; <span class="title">OlapScanNode::convert_scan_range_to_morsel_queue</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::vector&lt;TScanRangeParams&gt;&amp; scan_ranges, <span class="type">int</span> node_id, <span class="type">int32_t</span> pipeline_dop,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">bool</span> enable_tablet_internal_parallel, TTabletInternalParallelMode::type tablet_internal_parallel_mode,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">size_t</span> num_total_scan_ranges)</span> </span>&#123;</span><br><span class="line">    pipeline::Morsels morsels;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; scan_range : scan_ranges) &#123;</span><br><span class="line">        morsels.<span class="built_in">emplace_back</span>(std::<span class="built_in">make_unique</span>&lt;pipeline::ScanMorsel&gt;(node_id, scan_range));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// None tablet to read shouldn&#x27;t use tablet internal parallel.</span></span><br><span class="line">    <span class="keyword">if</span> (morsels.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::FixedMorselQueue&gt;(std::<span class="built_in">move</span>(morsels));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Disable by the session variable shouldn&#x27;t use tablet internal parallel.</span></span><br><span class="line">    <span class="keyword">if</span> (!enable_tablet_internal_parallel) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::FixedMorselQueue&gt;(std::<span class="built_in">move</span>(morsels));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> scan_dop;</span><br><span class="line">    <span class="type">int64_t</span> splitted_scan_rows;</span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> could,</span><br><span class="line">                     _could_tablet_internal_parallel(scan_ranges, pipeline_dop, num_total_scan_ranges,</span><br><span class="line">                                                     tablet_internal_parallel_mode, &amp;scan_dop, &amp;splitted_scan_rows));</span><br><span class="line">    <span class="keyword">if</span> (!could) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::FixedMorselQueue&gt;(std::<span class="built_in">move</span>(morsels));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Split tablet physically.</span></span><br><span class="line">    <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="type">bool</span> ok, _could_split_tablet_physically(scan_ranges));</span><br><span class="line">    <span class="keyword">if</span> (ok) &#123;</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::PhysicalSplitMorselQueue&gt;(std::<span class="built_in">move</span>(morsels), scan_dop, splitted_scan_rows);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::LogicalSplitMorselQueue&gt;(std::<span class="built_in">move</span>(morsels), scan_dop, splitted_scan_rows);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="MorselQueueFactory"><a href="#MorselQueueFactory" class="headerlink" title="MorselQueueFactory"></a>MorselQueueFactory</h3><p>MorselQueueFactory 的集成关系如下：<br><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-morsel-2.svg?raw=true" alt="pipeline-morsel-2"></p><p><code>IndividualMorselQueueFactory</code> 是针对每个 pipeline 都创建一个 MorselQueue。而 <code>SharedMorselQueueFactory</code> 即在多个 pipeline 之间共享一个 MorselQueue。</p><p><code>convert_scan_range_to_morsel_queue_factory</code> 函数是为 Pipeline 创建数据源 MorselQueue。<code>scan_ranges_per_driver_seq</code> 参数是由 front-end（fe）优化器生成的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusOr&lt;pipeline::MorselQueueFactoryPtr&gt; <span class="title">ScanNode::convert_scan_range_to_morsel_queue_factory</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::vector&lt;TScanRangeParams&gt;&amp; global_scan_ranges,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::map&lt;<span class="type">int32_t</span>, std::vector&lt;TScanRangeParams&gt;&gt;&amp; scan_ranges_per_driver_seq, <span class="type">int</span> node_id,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> pipeline_dop, <span class="type">bool</span> enable_tablet_internal_parallel,</span></span></span><br><span class="line"><span class="params"><span class="function">        TTabletInternalParallelMode::type tablet_internal_parallel_mode)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (scan_ranges_per_driver_seq.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> morsel_queue,</span><br><span class="line">                         <span class="built_in">convert_scan_range_to_morsel_queue</span>(global_scan_ranges, node_id, pipeline_dop,</span><br><span class="line">                                                            enable_tablet_internal_parallel,</span><br><span class="line">                                                            tablet_internal_parallel_mode, global_scan_ranges.<span class="built_in">size</span>()));</span><br><span class="line">        <span class="type">int</span> scan_dop = std::<span class="built_in">min</span>&lt;<span class="type">int</span>&gt;(std::<span class="built_in">max</span>&lt;<span class="type">int</span>&gt;(<span class="number">1</span>, morsel_queue-&gt;<span class="built_in">max_degree_of_parallelism</span>()), pipeline_dop);</span><br><span class="line">        <span class="type">int</span> io_parallelism = scan_dop * <span class="built_in">io_tasks_per_scan_operator</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If not so much morsels, try to assign morsel uniformly among operators to avoid data skew</span></span><br><span class="line">        <span class="keyword">if</span> (scan_dop &gt; <span class="number">1</span> &amp;&amp; <span class="built_in">dynamic_cast</span>&lt;pipeline::FixedMorselQueue*&gt;(morsel_queue.<span class="built_in">get</span>()) &amp;&amp;</span><br><span class="line">            morsel_queue-&gt;<span class="built_in">num_original_morsels</span>() &lt;= io_parallelism) &#123;</span><br><span class="line">            <span class="keyword">auto</span> morsel_queue_map = <span class="built_in">uniform_distribute_morsels</span>(std::<span class="built_in">move</span>(morsel_queue), scan_dop);</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::IndividualMorselQueueFactory&gt;(std::<span class="built_in">move</span>(morsel_queue_map),</span><br><span class="line">                                                                            <span class="comment">/*could_local_shuffle*/</span> <span class="literal">true</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::SharedMorselQueueFactory&gt;(std::<span class="built_in">move</span>(morsel_queue), scan_dop);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">size_t</span> num_total_scan_ranges = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, scan_ranges] : scan_ranges_per_driver_seq) &#123;</span><br><span class="line">            num_total_scan_ranges += scan_ranges.<span class="built_in">size</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        std::map&lt;<span class="type">int</span>, pipeline::MorselQueuePtr&gt; queue_per_driver_seq;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [dop, scan_ranges] : scan_ranges_per_driver_seq) &#123;</span><br><span class="line">            <span class="built_in">ASSIGN_OR_RETURN</span>(<span class="keyword">auto</span> queue, <span class="built_in">convert_scan_range_to_morsel_queue</span>(</span><br><span class="line">                                                 scan_ranges, node_id, pipeline_dop, enable_tablet_internal_parallel,</span><br><span class="line">                                                 tablet_internal_parallel_mode, num_total_scan_ranges));</span><br><span class="line">            queue_per_driver_seq.<span class="built_in">emplace</span>(dop, std::<span class="built_in">move</span>(queue));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;pipeline::IndividualMorselQueueFactory&gt;(std::<span class="built_in">move</span>(queue_per_driver_seq),</span><br><span class="line">                                                                        <span class="comment">/*could_local_shuffle*/</span> <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="MorselQueue"><a href="#MorselQueue" class="headerlink" title="MorselQueue"></a>MorselQueue</h3><p>MorselQueue 的继承体系如下。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-morsel-3.svg?raw=true" alt="pipeline-morsel-3"></p><h2 id="DriverQueue"><a href="#DriverQueue" class="headerlink" title="DriverQueue"></a>DriverQueue</h2><p>DriverQueue 的继承派生关系如下：</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-driver-queue-1.svg?raw=true" alt="pipeline-driver-queue-1"></p><p><em>QuerySharedDriverQueue</em> 是由于多级反馈队列远离实现，没有指定资源组的 query 都会进行这个队列中。<em>WorkGroupDriverQueue</em> 是针对设置 {cpu, mem} 资源限制 的 query，都是在 <code>GlobalDriverExecutor</code> 中初始化。</p><p>在 StarRocks Be(backend) 中是同时存在两个 GlobalDriverExecutor 对象，不同之处是分别用于实例化 QuerySharedDriverQueue 和 WorkGroupDriverQueue。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GlobalDriverExecutor::<span class="built_in">GlobalDriverExecutor</span>(std::string name, std::unique_ptr&lt;ThreadPool&gt; thread_pool,</span><br><span class="line">                                           <span class="type">bool</span> enable_resource_group)</span><br><span class="line">        : <span class="built_in">Base</span>(std::<span class="built_in">move</span>(name)),</span><br><span class="line">          _driver_queue(enable_resource_group ? std::<span class="built_in">unique_ptr</span>&lt;DriverQueue&gt;(std::<span class="built_in">make_unique</span>&lt;WorkGroupDriverQueue&gt;())</span><br><span class="line">                                              : std::<span class="built_in">make_unique</span>&lt;QuerySharedDriverQueue&gt;()),</span><br><span class="line">          _thread_pool(std::<span class="built_in">move</span>(thread_pool)),</span><br><span class="line">          _blocked_driver_poller(<span class="keyword">new</span> <span class="built_in">PipelineDriverPoller</span>(_driver_queue.<span class="built_in">get</span>())),</span><br><span class="line">          _exec_state_reporter(<span class="keyword">new</span> <span class="built_in">ExecStateReporter</span>()) &#123; &#125;</span><br></pre></td></tr></table></figure><h2 id="PipelineDriverPoller"><a href="#PipelineDriverPoller" class="headerlink" title="PipelineDriverPoller"></a>PipelineDriverPoller</h2><p>轮询判断某个 blocked_pipeline_driver 前置依赖是否已经 ready，ready 则加入 <code>_driver_queue</code>。</p><h2 id="PipelineDriver"><a href="#PipelineDriver" class="headerlink" title="PipelineDriver"></a>PipelineDriver</h2><p>执行单元，在每次执行前后会更新统计信息，Executor 会基于统计信息进行下一次调度。</p><p>StarRocks Pipeline 的设计还是挺复杂的，比 Morsel-Driven Parallelism[1] 论文做了很多的优化。后续再针对每个具体的数据结构进行分析。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>[1] <a href="https://db.in.tum.de/~leis/papers/morsels.pdf">Morsel-Driven Parallelism</a></li><li>[2] <a href="https://zhuanlan.zhihu.com/p/573181686">StarRocks Pipeline 执行框架（上)</a></li><li>[3] <a href="https://zhuanlan.zhihu.com/p/575526096">StarRocks Pipeline 执行框架（下)</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如图-1是 StarRocks Pipeline 的整体执行结构:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/szza/szza.github.io.images/blob/master/StarRocks/pipeline-1.svg?raw</summary>
      
    
    
    
    <category term="Pipeline" scheme="https://szza.github.io/categories/Pipeline/"/>
    
    
    <category term="StarRocks" scheme="https://szza.github.io/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>Hyper-Pipelining Query Execution(下)</title>
    <link href="https://szza.github.io/2023/05/03/Paper/Hyper-Pipelining-Query-Execution-2/"/>
    <id>https://szza.github.io/2023/05/03/Paper/Hyper-Pipelining-Query-Execution-2/</id>
    <published>2023-05-03T02:08:23.000Z</published>
    <updated>2023-08-26T17:48:00.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-X100-A-Vectorized-Query-Processor"><a href="#4-X100-A-Vectorized-Query-Processor" class="headerlink" title="4. X100: A Vectorized Query Processor"></a>4. X100: A Vectorized Query Processor</h2><p>上一篇翻译了 <a href="https://szza.github.io/2023/05/01/Paper/Hyper-Pipelining-Query-Execution-1">Hyper-Pipelining Query Execution</a> 上半部分，核心思想就是 RDBMS 和 MonetDB 的优缺点。后半部分，就是如何从零开始设计新的查询处理引擎 X100。</p><p>新的 X100 查询处理引擎目标主要有三个：</p><ol><li>高性能：以高 CPU 效率处理大数据量查询</li><li>拓展性：能够拓展到其他应用领域，比如 data-mining、multi-media retrieval等，并且能通过拓展代码在这些领域也能实现同样高的效率</li><li>伸缩性：能随着最低存储层次结构（比如磁盘）的大小进行伸缩</li></ol><p>为了实现我们的目标，X100 必须与整个计算机架构中的瓶颈进行博弈：</p><ol><li><p>Disk: X100 的 ColumnBM <u>I&#x2F;O 子系统</u>面向高效的顺序数据访问。为降低对带宽的要求，它使用了垂直分段的数据布局（vertically fragmented data layout），在某些情况下，这种布局通过轻量级数据压缩得到了增强。</p></li><li><p>RAM: 与 I&#x2F;O 类似，RAM 的访问路线是 memory-to-cache 和 cache-to-memory，其中可能会包含与硬件相关的优化，比如使用 SSE 指令预取（Prefetching）数据以及一些汇编指令来移动数据。</p></li><li><p>Cache: CPU Cache 是唯一与内存带宽无关的地方。</p><p>基于向量化处理（<em>vectorized processing</em>）模型，我们使用 Volcano-like execution pipeline。</p><p>本文把比较小（比如 1000个值）的能留在 CPU Cache 的数据块(chunk)，叫 “vectors”，这也是 X100 查询执行的基本单位。X100查询处理算子都是 cache-conscious：因为会把巨大的数据集分割成 cache-chunk，只会在 cache 中进行随机访问。</p></li><li><p>CPU: 先让编译器生成 loop-pipelined 代码。为进一步提高 CPU 吞吐（主要是减少 <code>mix</code> 指令中 LOAD&#x2F;STOR 的次数），X100 也包含为整个表达式子树而不是单个函数编译向量化原语（<em>vectorized primitives</em>）的工具。目前，此编译是静态引导的，但它最终可能成为优化器强制执行的运行时活动（比如 LLVM JIT）。</p></li></ol><p>为了保持本文的重点，我们仅简要描述磁盘存储问题，也是因为 ColumnBM Buffer Manager 仍在开发中。 在我们所有的实验中，X100 使用 MonetDB 作为其存储管理器（如图-5 所示），它在 in-memory BATs 上运行。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-5.jpg?raw=true" alt="Hyper-Pipelining-5"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;4-X100-A-Vectorized-Query-Processor&quot;&gt;&lt;a href=&quot;#4-X100-A-Vectorized-Query-Processor&quot; class=&quot;headerlink&quot; title=&quot;4. X100: A Vectorized </summary>
      
    
    
    
    
    <category term="Papers" scheme="https://szza.github.io/tags/Papers/"/>
    
  </entry>
  
  <entry>
    <title>Hyper-Pipelining Query Execution(上)</title>
    <link href="https://szza.github.io/2023/05/01/Paper/Hyper-Pipelining-Query-Execution-1/"/>
    <id>https://szza.github.io/2023/05/01/Paper/Hyper-Pipelining-Query-Execution-1/</id>
    <published>2023-05-01T13:58:02.000Z</published>
    <updated>2023-08-26T17:48:00.952Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>在计算密集型（compute-intensive）的应用领域中，数据库系统在现代 CPU 上往往只能实现较低的 IPC（Instructions-Per-Cycle）效率。基于这一问题，本文的主要工作分为如下两个方面：</p><ol><li><p>通过 TPCH benchmark，深入分析 IPC 效率不高的原因，即为什么每个周期（Cycle）执行的指令（Instructions）非常少。通过对不同的关系型数据库和 MonetDB[1] 进行分析，得到了一个设计查询处理器（Query Processor）的新指南。</p></li><li><p>本文的第二部分， 基于上述分析得到的查询处理器设计指南，如何为我们的 MonetDB 设计新的查询引擎 X100。</p><p> 表面上， X100 类似于基于 Volcano 模型设计的引擎，关键区别在于 X100 所有的执行都是基于矢量处理 （vector processing）的概念，使得 X100 引擎的 CPU 效率非常高。</p></li></ol><p>我们在 TPCH benchmark 输入数据为 100GB 的版本上评估了 MonetDB&#x2F;X100 的性能，结果显示其原始执行能力（即未经过调优）比以前的技术实现高出一到两个数量级。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>现代 CPU 每秒可以执行大量计算，但前提是能够找到大量不存在依赖关系的任务，才利用其并行执行能力。在过去的十年里硬件飞速发展，这使得 CPU 以最大吞吐量运行（full throughput）和最小吞吐量（minimal throughput）运行时之间的速度差异可能存在着一个数量级。</p><p>那么大家就期望查询密集型工作负载（workload），比如 decision support, OLAP, data-mining 等，这些应用场景中都存在着大量不相关的计算，那么此时就应该让 Modern-CPUs 有机会发挥出接近最优的 IPC 效率。</p><p>然而研究却表名当前数据库在这些应用场景中，在 Modern-Cpus 上实现的 IPC 效率非常低。这就让人感到困惑。因此本文详细研究了在查询密集型应用场景中，关系数据库是如何与 Modern super-scalar（Hyper-Pipelined） CPUs 交互的，尤其是在 TPCH benchmark 场景中。</p><p>从该调查研究中我们得到的主要结论是：<strong>绝大多数 DBMSs 采用的架构阻碍了编译器使用最关键的性能优化技术（即 Pipeline），从而导致 CPU 效率低下</strong>。比如，在 Modern-CPUs 的流水线技术(Pipelined Prcoessing)架构下，非常火的 Volcano 模型的最通用实现，执行过程中数据传递方式是 <code>tuple-at-a-time</code>（即一次传输一个tuple），1）不仅会产生高额的解释开销（interpretation overhead），还会阻止编译器让 CPU 并行的机会。</p><p>除此之外，我们也分析了内存数据库 MonetDB 的性能，这是由本文作者团队使用 MIL 语言开发的数据库。MonetDB&#x2F;MIL 的执行模型是 <code>Column-at-a-time</code>，因此不会有 <code>tuple-at-a-time</code> 执行模型中的解释开销问题（即被分摊了）。然而，它使用全列具体化（Full Column Materialization）的策略会导致在查询执行过程中产生大量数据。比如，我们就发现在 Decision Support 应用场景中，MonetDB&#x2F;MIL 就被内存带宽严重限制，导致 CPU 效率急剧下降。</p><blockquote><p>Materialization: 在这表达的语义是 “具体化”</p></blockquote><p>因此，我们任务应该将 MonetDB 的 <code>Coumn-at-a-time</code> 执行流程和 Volcano 模型 Pipeline 实现中的增量具体化（Incremental Materialization）技术结合起来。我们从零为 MonetDB 设计并实现了一个新的查询处理引擎，即 X100，它使用的是向量化查询处理模型（<strong>vectorized</strong> query processing model）。</p><h2 id="2-How-CPUs-Work"><a href="#2-How-CPUs-Work" class="headerlink" title="2. How CPUs Work"></a>2. How CPUs Work</h2><p>如图-1 显示了过去十年中每年最快的 CPU（按照 MHz 衡量 ）、最高性能，以及当年最先进的芯片制造技术。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-1.jpg?raw=true" alt="Hyper-Pipelining-1"></p><p>CPU MHz 提升的根本原因是芯片制造工艺规模的进步，通常每18个月缩小1.4倍（又称摩尔定律）。制造规模每缩小一倍，晶体管数量就会增加一倍（1.4 的平方），晶体管也会缩小一倍，布线距离和信号延迟也会缩小 1.4 倍。</p><p>因此，人们会期望 CPU MHz 随着反向信号（inverted singal）延迟的增加而增加，但是图1显示时钟速度已经进一步增加。</p><blockquote><p>这句话不太理解，翻译不好：Thus one would expect CPU MHz to increase with inverted signal latencies, but Figure 1 shows that clock speed has increased even further.</p></blockquote><p>这主要是由 <strong>Pipelining</strong> 技术完成的：<u>将 CPU 指令的工作划分为多个阶段，减少每个阶段的工作量意味着可以提高 CPU 频率</u>。1988 年的 Intel 80386 CPU 需要一个（或多个）周期才能执行一条指令，而 1993 年的 Pentium 已经有 5 级流水线，1999 年的 PentiumIII 增加到 14 级，而 2004 年的 Pentium4 有 31 级流水线。</p><p>但是 Pipeines 技术引入了两个风险： <strong>(1)</strong> 如果一条指令需要前一条指令的结果，则不能立即将其推入 pipeline，必须等到前一条指令（或其大部分）通过 pipeline，（即前一条指令执行完）； <strong>2）</strong> 在 <u>IF-a-THEN-b-ELSE-c</u> 条件分支代码中，CPU 必须要预测 a 的计算结果是 true or false。它可能预测为 false，并在 a 之后将 c 放入 pipeline 之中。经过许多阶段后，当 a 的计算结果出现了，CPU 可能确定自己前面猜错了（mispredicted the branch），那么就需要 Flush  Pipeline（即丢弃 Pipeline 中所有待执行的指令），然后重新将分支 b 的指令填充到 pipeline 中。很明显，Pipeline 越长，被丢弃的指令就越多，性能惩罚也就越高。</p><p>对应到数据库系统，依赖于数据的分支是无法预测的（比如在选择性不是很高也不是很低的数据上进行分支预测），并且会显著降低查询执行速度。</p><p>此外，Super-scalar CPUs（又名 Hyper-Pipelined CPUs）提供了并行执行多条指令（前提是他们之间是不存在依赖关系）的可能性。也就说，CPU 不是只有一条，而是有多条 Pipelines。因此，在每个指令周期，新的指令可以被放入到每个 Pipeline 中，只要他们与所有正在的指令之间不存在依赖关系。因此，Super-scalar CPUs 的 IPC &gt; 1。 图 1 显示了现实世界中 CPU 性能比 CPU 频率增长得更快，就是因为这个原因。</p><p>Modern-CPUs 总是会以不同的方式进行平衡。</p><ul><li>Intel Itanium2 具有多个并行 Pipelines 的 VLIW （<strong>V</strong>ery <strong>L</strong>arge <strong>I</strong>nstruction <strong>W</strong>ord）处理器，它只有非常少的 7-stage Pipeline，但是在一个指令周期内能执行多达 6 个指令，因此它的拥有一个相对低的时钟速度，为 1.5GHz。</li><li>相比之下，Intel Itanium4 拥有长达 31-stage Pipeline，拥有 3.6GHz 的时钟速度，但是一个指令周期却最多只能执行3个指令。</li></ul><p>无论使用哪种方式，为了达到 CPU 理论上的最大吞吐量， Itanium2 在任何时刻都需要 7 * 6 &#x3D; 42 个没有依赖关系的指令，而 Itanium4 却需要 31 * 3 &#x3D; 93 个。由于不总是能找到满足最大吞吐量的条件，因此许多程序使用 Itanium2 的计算资源效果比 Itanium4 更好，这解释了为什么在 benchmark 中，尽管时钟速度差异很大，但两种 CPU 的性能表现却相似。</p><p>绝大多数编程语言并不会要求程序员在他们的代码中显式指定哪些指令（或者表达式）之间不存在依赖关系，因此。编译器优化（<em>compiler optimizations</em>）对于获得良好的 CPU 利用率就变得至关重要。其中最重要的技术就是 <em>loop pipelining</em>，一个由多个相互依赖的算子（F(), G()）组成的算子从</p><p>$F(A[0])$, $G(A[0])$, $F(A[1])$, $G(A[1])$, …$F(A[N])$, $G(A[N])$</p><p>转化成</p><p>$F(A[0])$, $F(A[1])$, $F(A[2])$, …$F(A[N])$, $G(A[0])$, $G(A[1])$, $G(A[2])$, …$G(A[N])$</p><blockquote><p>即将两两相互依赖的算子变成不依赖的</p></blockquote><p>假设: F() 的 Pipeline 依赖延迟是 2 cycles，且当 G(A[0]) 送入 Pipeline 执行时，F(A[0]) 的执行结果已经可用。</p><p>在 Itanium2 处理器上，compiler optimizations 的重要性甚至更强:</p><ul><li>因为编译器必须要在编译期<u>找到可以进入不同 Pipelines 的指令</u>，而其他 CPUs 可以通过乱序执行（<em>Out-of-Order</em> Execution）在运行完成这项任务。由于 Itanium2 不需要任何复杂的逻辑来查找 Out-of-Order Execution 的机会，因此它可以包含更多的 Pipelines 来完成实际工作。</li><li>此外，Itanium2 还有个叫做 <strong>branch predication</strong> 的特性，可以用于消除 <em>branch mispredictions</em>（允许并行执行 THEN 和 ELSE 两个分支，并在条件 a 的计算结果确定后，立即丢弃错误分支的执行结果）。而检测 <u>branch predication</u> 的机会也是编译器的任务。</li></ul><p>图-2 展示了查询 <code>SELECT oid FROM table WHERE col &lt; X</code> 的 mirco-benchmark，其中 X 是均匀随机分布在 <code>[0, 100]</code> 区间，并且我们从 0 到 100 变动着 X。<br>由于分支预测错误，像 AthlonMP 这样的普通 CPU 显示出大约 50% 的最坏情况行为。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-2.jpg?raw=true" alt="Hyper-Pipelining-2"></p><p>通过采纳 [17] 中的建议，通过巧妙地重写代码，将分支预测转换为 boolean 计算（即predicated 的变体）。尽管这个重写后的代码与分支选择性无关了，但是却引入了更高的均摊成本（average cost）。然而有趣的是，在 Itanium2 处理器上，”branch” 版本却有着更高的效率，并且也和分支选择性无关，这是因为编译器将分支转化为硬件预测（hardware-predicated）代码。</p><p>最后，我们也应该提以下片上缓存（on-chip cache，即 L1, L2）对 CPU 吞吐量的重要性。CPU 执行的所有指令中大约 30% 会有内存加载（memory load）和写入内存（memory store）操作，即需要访问 DRAM 芯片中的数据，而这些 DRAM 芯片距离主板上的CPU有几英寸，这对内存延迟施加了大约 50ns 的物理下限，（即 CPU 访问 DRAM 中的数据至少有 50ns 的物理延迟）。在频率为 3.6G 的 Itanium4 CPUs 上，这个 50ns 的最小延迟（还是理想情况下）就会转化为 180个等待周期，因此只有当程序访问的内存绝大多数都已经缓存在 L1&#x2F;L2 等高速缓存中时，Modern-CPUs 才有机会以其最大吞吐量运行。</p><p>最近的数据库研究表明，内存访问成本（cache misses）严重损害了 DBMS 的性能，并且如果使用缓存敏感型（cache-conscious）数据结构，比如 cache-aligned B-Trees，或者使用 <strong>column-wise</strong> 数据布局（比如 PAX 、MonetDB 中的 DSM），就可以显著改善数据库性能。此外，将随机内存访问模型（random memory access patterns）限制在某一个区域，使其适合 CPU 缓存，这样的查询处理算法（例如 radix-partitioned hash-join 算法）也是可以极大提高数据查询性能。</p><p>总的来说， Modern-CPUs 已经变成一个高度复杂的设备，处理器的指令吞吐量可能会相差几个数量级，这主要取决于一下四个因素：</p><ol><li>memory loads 和 memory stores 的 cache 命中率</li><li>分支的数量以及他们是否能被预测</li><li>编译器和 CPU 平均能检测到的不相关指令数量</li></ol><p>研究表名，即便是在商业数据库中，查询执行引擎的 IPC 也才 0.7，也就是说每个指令周期执行的指令少于1个。相比之下，科学计算（例如矩阵乘法）或多媒体处理却可以从 Modern-CPUs 中获得的平均 IPC 高达 2。因此我们认为数据库不应该表现得这么糟糕，特别是在需要检查数百万 tuples 并计算表达式的大规模分析任务中。这些任务具有大量的独立性，应该能够完全填满 CPUs 所能提供的所有 Pipelines。因此，本文目标是调整数据库架构，尽可能将其暴露给编译器和 CPU，从而显着提高查询处理吞吐量。</p><h2 id="3-Micro-benchmark-TPCH-Q1"><a href="#3-Micro-benchmark-TPCH-Q1" class="headerlink" title="3. Micro-benchmark: TPCH Q1"></a>3. Micro-benchmark: TPCH Q1</h2><p>虽然我们总体上以查询处理的 CPU 效率为目标，但我们首先关注表达式计算（expression calculation），放弃更复杂的关系操作（比如 JOIN）以简化我们的分析。我们选择 TPCH benchmark Q1（如图-3所示）来进行分析，因为在我们测试的所有 RDBMSs 上，该 Query 都是CPU 密集型的（CPU-bound）。此外，这个Q1的执行计划非常简单，以至于几乎不需要优化和花哨的 JOIN 实现。因此，所有数据库都在一个公平的竞争环境中运行，并主要突出它们计算表达式的效率。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-3.jpg?raw=true" alt="Hyper-Pipelining-3"></p><p>TPCH benchmark 运行在 1G 大小的数据仓库上，这个大小可以通过 <code>Scaling Factor</code> (SF) 来调节。Q1 是对大小为 SF * 6M tuples 的表 <em>lineitem</em> 进行 scan，几乎选择了该表的所有的数据（SF * 5.9M tuples），并计算了多个 fixed-point 十进制表达式：两个 column-to-const 减法，一个 column-to-const 加法，三个 column-to-column 乘法以及8个聚合计算（四个 SUM，三个 AVG和一个 COUNT）。聚合分组是针对两个单字符列（two single-character column），并仅产生四个唯一的组合，因此通过小的 hashtable 就能高效完成，不需要额外的 IO，甚至不需要 CPU 缓存命中。</p><p>下面，我们先分析Q1在关系型数据库上的性能，然后分析在 MonetDB&#x2F;MIL 上的性能，最后是通过 hand-coded 实现的性能。</p><h3 id="3-1-Q1-on-Relational-Database-Systems"><a href="#3-1-Q1-on-Relational-Database-Systems" class="headerlink" title="3.1 Q1 on Relational Database Systems"></a>3.1 Q1 on Relational Database Systems</h3><p>从 RDBMSs 早期开始，他们的查询执行功能就是通过实现物理关系代数（Physical Relational Algebra）来提供的，这通常遵循 Volcano 流水线处理模型。然而，关系代数的参数有很高的自由度。比如，即使是一个简单的 ScanSelect(R, b, P) 也只能在查询时（query-time）才能完全了解:</p><ul><li>输入关系 R 的格式（列数、列类型和记录偏移量，</li><li>布尔选择表达式 b (可以是任何形式），以及</li><li>定义输出关系的 projection 表达式 P 的列表（每个表达式的复杂度都是任意的)</li></ul><p>实际上，为了处理所有可能的 (R,b,P)，DBMS 开发者必须实现一个可以处理任意复杂度表达式的表达式解释器（expression interpreter）。</p><p>这样一个 interpreter 的问题在于做有用功的成本（即执行 query 中出现的表达式）仅仅占整个查询执行成本（total query execution cost）的一小部分，尤其是当 interpretation 的粒度是 tuple 时更为严重。我们可以在表-2 中看到这种情况，该表显示了 SF&#x3D;1 时，MySQL-4.1 执行 TPCH Q1 时的 gprof 记录。 </p><ul><li>cum: 第一列是第二列的累加和</li><li>excl: 第二列显示函数所消耗的时间占总执行时间百分比，不包括该函数调用其他函数所花费的时间。</li><li>calls: 第三列显示该函数的调用次数 </li><li>第四列和第五列显示每次调用函数的平均指令数，以及实现的 IPC</li></ul><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-table-2.jpg?raw=true" alt="Hyper-Pipelining-table-2"></p><p>从表-2可得如下两个结论：</p><ol><li><p>耗时组成： 完成所有“工作”（表-2中以粗体显示）的五个操作仅相当于总执行时间的 10%。另外 28% 的时间用于聚合操作中 HashTable 的创建和查询，还有剩余的 62% 的时间消耗在 <code>rec_get_nth_field</code> 等函数上，用于将产生的结果复制给用户。而其他因素，比如锁的开销（pthread_mutex_unlock, mutex_test_and_set）或者 buffer page 的开销（buf_frame_align）似乎可以忽略不计。</p></li><li><p>“Item” 操作的成本与查询的计算工作相呼应。比如，<code>Item_func_plus::val</code> 函数每次执行都消耗 38 个指令。这个性能记录是在配备了 MIPS R1200 CPU 的SGI机器上获得的，该机器可以在一个指令周期执行 3 个整数或浮点指令和一次 load&#x2F;store，平均操作延迟约为 5 cycles。</p><p>一个简单的 “+” 算法用 RISC 指令实如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">plus</span><span class="params">(<span class="type">double</span> src1, <span class="type">double</span> src2)</span> </span>&#123;</span><br><span class="line"> LOAD src1, reg1</span><br><span class="line"> LOAD src2, reg2</span><br><span class="line"> ADD reg1, reg2, reg3</span><br><span class="line"> STOR dst, reg3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该代码中的限制因素是三个 LOAD&#x2F;STOR 指令，因此 MIPS 处理器每 3 个周期才能可以执行一次加法操作。而 MYSQL 执行一次 <em>Item_func_plus::val</em> 所需的周期是是 <strong>#ins&#x2F;IPC &#x3D; 38&#x2F;0.8 &#x3D; 49 cycles</strong>。</p><p>对于如此高昂的成本，一个解释就是没有 <em>loop pipelining</em>，因此这个加法是由四个存在依赖关系的指令组成，必须彼此等待。由于指令平均延迟为 5 cycles，这就解释了大约 20cycles 的成本，49 cycles 中的剩余其他 cycels 则消耗在函数之间的跳转、函数的入栈出栈。</p><blockquote><p>我觉得这解释有点牵强</p></blockquote></li></ol><p>MYSQL 以 “tuple-at-a-time” 策略执行表达式的结果有两点影响：</p><ol><li><em>Item_func_plus::val</em> 只执行一次加法，阻碍了编译器创建 <em>pipelined loop</em>。因为一个操作（比如这里的一次加法操作）的指令是具有高度依赖的，必须生成空的 pipeline slot 来等待（甚至停顿等待）指令延迟，以至于 loop 的成本变成 20cycles 而不是 3cycles。</li><li>函数调用的成本（大约 20cycles）只能在一次操作中分摊，这使得该操作成本翻倍。</li></ol><p>总而言之，<strong>tuple-at-a-time</strong> 即一次只针对一个数据进行操作，导致无法 pipelined loop + 无法分摊成本。</p><p>此外，我们也在知名的商业数据库上测试了相同的查询 Q1，如表-1 第一行所示。虽然我们没有该产品的源码，无法获得 gprof 性能记录，但是该 RDBMS 的查询评估成本和 MYSQL 是极其相似的。表-1的下半部分是从 TPC 网站获取的一些官方 TPCH Q1 结果。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-table-1.jpg?raw=true" alt="Hyper-Pipelining-table-1"></p><h3 id="3-2-Q1-on-MonetDB-MIL"><a href="#3-2-Q1-on-MonetDB-MIL" class="headerlink" title="3.2 Q1 on MonetDB&#x2F;MIL"></a>3.2 Q1 on MonetDB&#x2F;MIL</h3><p>MonetDB&#x2F;MIL 是由本论文作者团队开发的，因使用垂直分片（vertical fragmentation），按列存储表（storing tables column-wise）而知名。</p><p>我们使用 MonetDB&#x2F;MIL SQL frontend 将 TPCH Q1 转化为 MIL 语言后再执行。表-3显示了 20个 MIL 调用情况，它们总共占用了 99% 以上的查询运行时间。基于 TPCH Q1，MonetDB&#x2F;MIL 是明显快于 MYSQL 和同一机器上的商业 DBMS，并且和表-1中已公布的 TPCH 结果也具有竞争力。然而，仔细观察表-3会发现，几乎所有 MIL 操作都是内存密集型（Memory-bound）而不是CPU密集型操作（CPU-bound），即受限于内存而无法充分利用 CPU 资源。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-table-3.jpg?raw=true" alt="Hyper-Pipelining-table-3"></p><p>在将 TPCH 数据集的规模系数 $SF &#x3D; 0.001$ 时，再运行相同的查询计划，表 <strong>lineitem</strong> 所有使用到的列和产生的中间结果（intermediate results）此时都都能填充到 CPU Cache 中，这就消除了CPU和内存之间的流量，然后，MonetDB&#x2F;MIL 的速度几乎是原来的两倍。</p><p>表-3的第 2 列和第 4 列显示的是各个 MIL 操作实现的 bandwidth（BW，以 MB&#x2F;s 为单位），同时计算了输入 BAT（Binary Association Table） 的大小和生成的输出 BAT。</p><ul><li>在 SF&#x3D;1 时，MonetDB 带宽上限卡在 500MB&#x2F;s，这是在该硬件上可持续的最大带宽</li><li>在 SF&#x3D;0.001 时，能够完全在 CPU 缓存中运行，此时带宽上限可以达到 1.5GB&#x2F;s。</li></ul><p>对于乘法 <code>[*]()</code>，bandwidth 只有 500 MB&#x2F;s 意味着 tuples 速度是 20M&#x2F;s （16 个字节输入，8 个字节输出），因此在我们的 1533 MHz CPU 上每个乘法需要 75 cycles，这比 MySQL 还要拉胯。</p><p>因此，MonetDB&#x2F;MIL 的 <strong>column-at-a-time</strong> 策略表现出两面性：</p><ul><li><p>优点： MonetDB 不容易遇到 MySQL 的问题，即 90% 的查询执行时间都消耗在 “tuple-at-a-time” 模型的解释开销上。</p><p> 这是因为乘法是操作整个 BATs (这是个数组，其 layout 在编译时就已知)，那么编译器能够使用 loop-pipelining 技术，使得这些运算具有很高的 CPU 效率，具体体现在表-3 SF&#x3D;0.001 的结果中。</p></li><li><p>缺点：Full Materialization</p><p> 当基于大量 tuples 进行复杂逻辑表达式计算时，查询将为表达式中的每个函数 materialize 整个结果列。然而，这样的中间结果对于整个查询而言并不是必要的，它只是作为表达式中其他函数的输入。比如。在一个查询计划中，聚合操作是最顶层的算子（即执行计划的根节点），那么最终输出的结果大小甚至可以忽略不计（比如TPCH Q1）。在这种情况下，MIL 产生的中间数据远多于实际所需的，导致非常高的带宽消耗（即所需的带宽也远多于实际所需的）。</p><p> 而这个问题在 Volcano-like 查询执行引擎中并不存在，它可以一次性完成选择、计算和聚合，而不具体化任何数据（即不会产生无用的中间数据）。</p></li></ul><p><strong>所以就是要结合 Volcano-like 和 MonetDB 各自的优点重新设计新的 X100。</strong></p><h3 id="3-3-Q1-Baseline-Performance"><a href="#3-3-Q1-Baseline-Performance" class="headerlink" title="3.3 Q1 Baseline Performance"></a>3.3 Q1 Baseline Performance</h3><p>为了获得现代硬件对 Q1 等问题的处理能力的 baseline，我们将其实现为 MonetDB 中的一个 UDF，如图 4 所示，该 UDF 仅在查询涉及的那些列中传递。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/Hyper-Pipelining-4.jpg?raw=true" alt="Hyper-Pipelining-4"></p><p>从 表-1 可以看出这个 UDF 实现（标记为“hand-code”）居然将查询成本降低到了 0.22s。 然而，表-1也可以看出，新的 X100 查询处理器（见下一篇博客）能够达到此 UDF 版本的 2 倍以内（也就是虽然慢了一倍，但还是算很快，毕竟编译器自动生成的肯定比不上大佬手写的）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;在计算密集型（compute-intensive）的应用领域中，数据库系统在现代 CPU 上</summary>
      
    
    
    
    
    <category term="Papers" scheme="https://szza.github.io/tags/Papers/"/>
    
  </entry>
  
  <entry>
    <title>Radix-Join Cluster Algorithm</title>
    <link href="https://szza.github.io/2023/04/22/Paper/Radix-Join/"/>
    <id>https://szza.github.io/2023/04/22/Paper/Radix-Join/</id>
    <published>2023-04-22T02:12:01.000Z</published>
    <updated>2023-08-26T17:48:00.952Z</updated>
    
    <content type="html"><![CDATA[<p>现在很多 JOIN 算法在进行 JOIN 操作之前，会先将输入划分成多个 clusters&#x2F;partitions，再在每个 cluster 内部进行 JOIN，以便使用多线程等来加速 JOIN。现在主流的分区算法大都是基于 radix-cluster algorithm[1] 及其衍生对输入进行分区。</p><blockquote><p>现在的 join 算法为提高性能，基本都是想着如何充分发挥硬件的特性，比如线程，NUMA 内存分配特性，SIMD，TLB entries、cache lines等。</p></blockquote><p>本文只是作为后续 JOIN 算法的一个铺垫，因此主要介绍 radix-cluster algorithm 本身，其他部分可参考原文[1]。</p><h2 id="PARTITIONED-HASH-JOIN"><a href="#PARTITIONED-HASH-JOIN" class="headerlink" title="PARTITIONED HASH-JOIN"></a>PARTITIONED HASH-JOIN</h2><p>Shatdal et al.[2] 提出了一种在 main-memory 下 Grace Join 算法的变体。</p><p>该算法先基于一个 hash-number 将两个输入划分都分别为 H 个不同的 clusters，使得每个分区都能纳入 memory cache，这种方式比常规基于 bucket-chained hash join 性能更好。该算法简单明了，直接使用了一个分簇算法(clustering-algorithm)： <strong>只扫描输入一次，并将每个被扫描的 tuple 插入到输出中一个 cluster</strong></p><p>如图-8所示，将左侧的输入随机的划分到 H 个单独的 cluster 中。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-1.jpg?raw=true" alt="radix-join-1"></p><p>这个算法，问题就出在随机上，因为会破坏内存访问的局部性，这点从图-8可以看出，输出的H个 clusters 和输入分布基本没啥关系。而且由于需要把每个 cluster 都尽可能纳入 memory-cache 中，就需要 H 尽可能大，使得产生的每个 cluster 就会尽可能小才能一次性纳入cpu cache。那么当 H 非常大时，又有两个因素会导致性能退化：</p><ul><li>如果 H 超过 TLB entries 的数量，那么每次访问内存（memory reference）都会产生一次 TLB miss；</li><li>如果 H 超过了 L1 or L2 可用的 cache lines 数量，cache thrashing 现象就会出现，进而导致 cache miss 次数激增。</li></ul><p>为解决这两个问题，提出了 Radix-Cluster Algorithm ，使得即便H非常大，也具有非常低的随机访问，进而提高性能。</p><h2 id="Radix-Cluster-Algorithm"><a href="#Radix-Cluster-Algorithm" class="headerlink" title="Radix-Cluster Algorithm"></a>Radix-Cluster Algorithm</h2><p>如图 9 所示，radix-cluster algorithm 使用多个阶段（论文中叫 pass）将输入划分为 H 个 clusters，</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-2.jpg?raw=true" alt="radix-join-2"></p><p>下面会先阐述下算法，然后以图-9为例进行说明算法。</p><p>radix-clustering 算法是基于某列生成的整数 hash value 的低 $B$ bits 上实现的：<br>该算法有连续的 P 个 pass ，每个 pass 都基于输入 tuple 的 $B_p$ 个 bits 对输入进行分区，且该 $B_p$ 个 bits 的位置是从最左侧开始计算的 $\sum_1^pB_p$ bits。</p><p>比如图-9中 $B &#x3D; 3$，其中 $P&#x3D;2$，$B_1 &#x3D; 2$，$B_2&#x3D;1$：</p><ul><li>第一个 pass 先使用 $B_1$ bits，目前总共使用的是从最左侧开始计算的 $2&#x3D;\sum^{p&#x3D;1}_1B_p$ 个 bits 进行对一个 pass 输入进行分区；</li><li>第二个 pass 再使用 $B_2$ bits，目前总共使用的是从最左侧开始计算的 $3&#x3D;\sum^{p&#x3D;2}_1B_p$ 个 bits 对第二个 pass 输入进行分区</li></ul><blockquote><p>第二个 pass 是在第一个 pass 的基础上再进行分区，因此看似只使用了一个 bit，实际上包含了第一个 pass 中两个bits的影响，因此说第二个 pass 使用从最左侧开始的 3 个 bits也没问题。</p></blockquote><p>radix-cluster 算法创建的 clusters 数量 $H &#x3D; \prod^p_1 H_p$，其中后一个 pass 会基于上一个 pass 输出的每个 cluster 继续子划分为 $H_p &#x3D; 2^{B_p}$ 个新的 cluster。</p><p>因此当算法开始时，整个输入就被视为一个完整的 cluster，第一个 pass 就被划分为 $H_1 &#x3D; 2^{B_1}$ 个新的 clusters，然后在下一个 pass 继续基于 $H_1$ 个 clusters 再次划分，每个 cluster 又产生 $H_2 &#x3D; 2^{B_2}$ 个新的 clusters，因此两个 pass 就一共产生了 $H_1 * H_2$ 个 clusters。</p><p>特别地，当 $P &#x3D; 1$ 时，radix-cluster 算法即类似上述简单明了的划分算法。</p><blockquote><ul><li>为什么说 radix-cluster 算法在 H 很大时局部性更好？这个观察图-9两个pass的输出应该能得出结论。</li><li>此外，为便于演示，在图-9所示的整数值表中没有使用哈希函数。然而，在实际中，即便是整数值，最好也使用一个hash函数，来确保值的所有位数都能发挥作用。</li></ul></blockquote><p>radix-cluster 算法有诸多好处：</p><ol><li>通过多个 pass 可以实现在具有非常大 H 的情况下，还可以将随机访问的 $H_x$ 数量保持在很低的水平。更具体地说，就是如果我们能保证 $H_x &#x3D; 2^{B_x}$ 同时小于 cache lines 的数量和 TLB entries 的数量，那么我们就可以在每个pass的分区中完全避免 TLB  miss 和 cache miss。</li><li>在基于某列（一般是 join-key cloumn）的 $B$ bits 进行 radix-clustering 之后，该列的hash值中具有相同 $B$ bits 的所有 tuples 表现出连续性，通常会形成每 $C&#x2F;2^B$ tuples 为一组的 chunks，其中 C 是输入的基数（cardinality）。因此，就没有必要使用额外的数据结构来记录这些 cluster 的边界：<strong>只需查看这些 clusters 的低 $B$ bits，就可以确定每个 cluster 的边界</strong>，这样就引入任何额外的开销。</li><li>此外，这种 radix-cluster 算法得到的输出还是基于 radix-bits 排序的。</li></ol><p>图-9 中：</p><ul><li>在第一个 pass 中，取最左侧 2 bits 来划分，能得到 $4 &#x3D; 2^2$ 个 clusters；</li><li>在第二个 pass 中，此时取从最左侧开始的 $3^{th}$ bit，对第一个 pass 输出的每个 cluster 再进子行划分，此时总共得到 $8 &#x3D; 2^1 * 4$ 个 clusters</li></ul><p>对输出的 clusters 进行观察可得：</p><ul><li>有界性：即不需要额外的数据结构就可以确定每个 cluster 的边界。比如，我们可以观察最终输出数组中的hash值的低 $B&#x3D;3$ bits 就能确定 <code>&#123;57, 17, 81, 75&#125;</code> 属于一个 cluster，而 96 和他们不是一个 cluster，并且这四个数字仍然保持原始输入中的顺序；</li><li>有序性：最终输出的8个cluster是基于 3bits 进行排序的，即按照 <code>000 --&gt; 001 --&gt;... --&gt; 111</code> 顺序递增</li></ul><h2 id="Experimental"><a href="#Experimental" class="headerlink" title="Experimental"></a>Experimental</h2><p>radix-cluster 算法有三个参数会对性能造成影响，${B, P, B_p}$，论文进行试验，保持其中一个参数不变，变化另外两个参数对算法进行量化分析。</p><h3 id="radix-bits"><a href="#radix-bits" class="headerlink" title="radix-bits"></a>radix-bits</h3><p>图-10展示了不同 CPU 架构下 1-pass 时不同 radix-bits 时执行时间分布细节。结论：</p><ul><li>纯CPU消耗的时间基本是恒定的，具体的数值在不同CPU架构上略有不同；</li><li>radix-bits 越小， memory 和 TLB 耗时越低，两者成正相关，即 radix-bits 增加，相应的耗时也会增加，比如当 radix-bits 超过 6 时，生成的 clusters 则超过了 TLB entries 的数量（$64 &#x3D; 2^6）$，此时造成的 TLB miss 次数增加了，对应的耗时也会激增。cache miss 也类似。</li></ul><blockquote><p>不同 CPU 的 TLB entries 和 cache lines 数量都不一样，所以图 10 显示的 radix-bits 影响不同；</p></blockquote><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-3.jpg?raw=true" alt="radix-join-3"></p><h3 id="multi-pass"><a href="#multi-pass" class="headerlink" title="multi-pass"></a>multi-pass</h3><p>图-11 展示了不同 passs 数量的影响。multipass radix-cluster 的核心思想是以增加 CPU 耗时来保证每个pass生成的 clusters 数量比较低，并降低内存耗。从图-11可得：</p><ul><li>在 radix-bits &gt; 6 时，即便通过 2-pass 设计，CPU 的耗时成本过高以至于无法避免 TLB 的耗时；</li><li>只有当 radix-bits &gt; 15 时，即 内存耗时超过 CPU 耗时，2-passes 才超过 1-pass<blockquote><p>by the way，关于这两点的原文不知道是我理解错了，还是原文写错了，似乎结论和图-11不匹配，且这两点就互相矛盾。原文如下：</p><ul><li>Obviously, the CPU costs are too high to avoid the TLB costs by using two passes with more than 6 radix-bits. </li><li>Only with more than 15 radix-bits (i.e., when the memory costs exceed the CPU costs) will two passes win over one pass</li></ul></blockquote></li></ul><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-4.jpg?raw=true" alt="radix-join-4"></p><p>注意：图-11 展示的仅是分区这一个操作的耗时，当分区数据增多这个耗时不可避免的增加，但是分区 + join 操作的总体耗时不一定会增加，甚至可能会锐减。这里引用论文[3]中的一个分区和join操作总体耗时的图，更能说明问题。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-4-1.jpg?raw=true" alt="radix-join-4-1"></p><p>论文认为唯一改善图-11中问题的方法是降低 CPU 开销，图12是论文 1-pass 的 radix-cluster 算法源码，multi-pass 也是类似，所做的一个优化（图-12中的右侧两行代码）就是去掉了两个函数调用：</p><ul><li>将 hashFcn 变成宏；</li><li>将 memcpy 替换为复制操作</li></ul><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-5.jpg?raw=true" alt="radix-join-5"></p><p>如图-13所示，优化之后，CPU 开销几乎降低了接近4倍，论文给出的两个理由是：</p><ul><li>some CPU cycles are saved;</li><li>the CPUs can benefit more from the internal parallel capabilities using speculative execution as the code has become simpler and parallelization options more predictable</li></ul><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/radix-join-6.jpg?raw=true" alt="radix-join-6"></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://ir.cwi.nl/pub/11143/11143B.pdf">Optimizing Main-Memory Join on Modern Hardware</a></li><li><a href>Cache Conscious Algorithms for Relational Query Processing</a></li><li><a href="https://15721.courses.cs.cmu.edu/spring2016/papers/kim-vldb2009.pdf">Sort vs. Hash Revisited: Fast Join Implementation on Modern Multi-Core CPUs</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;现在很多 JOIN 算法在进行 JOIN 操作之前，会先将输入划分成多个 clusters&amp;#x2F;partitions，再在每个 cluster 内部进行 JOIN，以便使用多线程等来加速 JOIN。现在主流的分区算法大都是基于 radix-cluster algori</summary>
      
    
    
    
    
    <category term="Papers" scheme="https://szza.github.io/tags/Papers/"/>
    
  </entry>
  
  <entry>
    <title>Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework</title>
    <link href="https://szza.github.io/2023/04/02/Paper/Morsel-Driven-Parallelism/"/>
    <id>https://szza.github.io/2023/04/02/Paper/Morsel-Driven-Parallelism/</id>
    <published>2023-04-02T13:58:02.000Z</published>
    <updated>2023-08-26T17:48:00.990Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>随着现代计算机架构的演进，与并行查询执行引擎中两个问题产生了矛盾：</p><ol><li>为了充分利用多核，所有的查询工作必须很快均匀地分布在数百个线程中才能实现良好的性能加速；</li><li>然而，由于现代 CPU out-of-order 的复杂性，即使有准确的数据统计，也很难将工作均匀分配</li></ol><p>因此，现有的针对 Volcano 的 <code>&quot;Plan Driven&quot;</code> 的并行方法遇到了负载均衡问题（load balancing） 和 上下文切换 （context switch）瓶颈，无法随着CPU架构的升级进行伸缩。许多多核架构面临的第三个问题就是 Memory controller 的去中心化，进而引起 NUMA（Non-Uniform Memory Access）问题。</p><p>因此，本文提出了一种 <code>&quot;Morsel Driven&quot;</code> 查询引擎执行框架，调度变成了一个细粒度的 runtime 任务，且能利用 NUMA 特性。Morsel- Driven 查询处理引擎接受输入数据的一小片段（”morsels”），然后将 morsels 调度给 work 线程，这些 work 线程运行着完整的 operator pipeline，直到遇到下一个 pipeline 才会中断。</p><p>每个 work 线程运行着一个 pipeline，pipeline 中填充着不同的 operators 来操作数据。只要输入 morsels，就会依次从 SourceOperator 向 SinkOperator 流去。</p><p>并行度（degree of parallelism, dop）并不是个固定值，是可以在查询执行期间弹性地更改，因此 dispatcher 可以对不同 morsels 的执行速度作出反应，也可以动态地调整资源以响应工作负载中的新查询。此外。dispatcher 是能感知到 NUMA-local morsels 和算子状态（operator state）的数据局部性，以便绝大多数任务执行发生了 NUMA-Local 内存上。</p><h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h2><p>硬件都朝着提升多核性能的方向发展，本文使用术语 “many-cores” 来描述具有数十上百线程的CPU架构。与此同时，每台服务器的内存容量能增加到几TB，这也带动了内存数据库系统的发展。在这样的系统中，查询处理不再受 I&#x2F;O 限制，并且可以真正利用多核的巨大并行计算资源。不幸的是，将 Memory Controller 转移至芯片中，以及将吞吐量拓展到几TB的巨大内存所需的内存访问分散化（decentralization of memory access）的趋势，产生的 NUMA。本质上，计算机本身已经成为一个网络，因为数据项的访问成本取决于数据和访问线程所在的芯片。因此，”many-cores” 并行化需要将 RAM 和cache 的层次结构纳入考虑范围，尤其要仔细考虑 RAM 的 NUMA 划分，以确保大部分线程在 NUMA-Local 数据上工作。</p><blockquote><p>核心思想就是如何减少跨 core 通信：每个线程尽量访问自己核上的数据。RocksDB 中有个数据d结构 <a href="https://github.com/facebook/rocksdb/blob/9a2a6db2a9c5e628b38a5c8cceb90e1e5dbc39a4/util/core_local.h#L23">CoreLocalArray</a>，给每个 core 分配一个对象，让线程访问数据时直接访问线程所在core，减少与 remote core 之间的跨核通信</p></blockquote><p>在此之前的并发模型是 <strong>Volcano</strong> 模型，这种模型中 operators 是没有并行度可言的。因为并行的概念被封装成 Exchange Operator，这个算子在多线程间路由数据流，每个线程都执行着查询计划中完全相同的 pipelined 部分。这种设计就是 <em>plan driven</em>: 基于统计数据优化器在生成执行计划的编译期就确定需要启动多少线程，为每个线程实例化一个查询算子（query operator）并通过 exchange operators 实现这些 operators 间的通信。</p><p>本文提出 <em>morsel driven</em> 查询执行框架，如 fig-1 是执行三表 join 查询 $R \Join_A S \Join_B T$ 的示意图，并行性是通过并行处理不同 cores 上的每个pipeline 实现的。如图所示，有红色和蓝色两个 pipelines。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-1.jpg?raw=true" alt="morsel-driven-1"></p><p>该框架的核心是调度机制（scheduling mechanism）即图中的 <em>dispatcher</em>，使得可以灵活地并行执行 operator pipleine，甚至可以在查询执行期间改变并行度。</p><p>一个 query 会划分成多个 segments，每个可执行的 segments 都会接受输入的一小部分（即 morsel）作为数据源，然后执行，直到遇到下一个 pipeline 才会输出具体的结果。</p><p>如 fig-1 中的红蓝所示，该 morsel 框架也支持 NUMA 局部处理：线程 T1 在一个 NUMA-Local 上输出输入，并且将其结果写入 NUMA-Local 存储区域，全程都没有跨 NUMA 结构。</p><p>fig-1 中的 <em>dispatcher</em> 运行着与机器相关的固定数量的线程，这样即便新的 queries 到来，也不会出现资源的过度消耗，并且这些工作线程与 cpu core 绑在一起，这样就不会因为操作系统将线程移动到其他CPU core 导致 NUMA 局部性失效。</p><blockquote><p>一般工作线程数和 <a href="https://en.cppreference.com/w/cpp/thread/thread/hardware_concurrency">std::thread::hardware_concurrency()</a> 函数返回值一致，而这个函数的返回值一般和机器有关。</p></blockquote><p>morsel-driven 的调度机制核心特性是 task 的分配在 runtime 时完成的，并且完全弹性的，即可以通过增加或者降低正在执行的查询的并行度，来处理运行时变化的 workloads，这样就能实现完美的负载均衡（load balancing）。</p><p>morsel-driven 框架的思想从调度拓展到整个查询执行框架，即所有的物理查询算子都必须在他们所有的执行阶段都能实现 morsel 级别（morsel-wise）的并行，比如 HashJoin 的 build 和 probe 阶段。根据 Amdahl 定律，这对实现 many-core 可伸缩性至关重要。</p><p>morsel-wise 框架的一个重要特性就是能感知到数据局部性（data locality），这个起始于输入 morsels 和输出 buffer 的的局部性，并且拓展到 operator state 的局部性（operator state，一般是数据结构，比如 Aggregator 中的 HashTable）。尽管 operator state 是个可能被任何 cores 都访问到的共享数据结构，但是 operator state 确实仍有高度的 NUMA 局部性。</p><p>在为了实现 load balance 时，会需要从其他 core 获取一小部分 morsels，这时才会发生 remote NUMA 访问，即损失了 NUMA 局部性。</p><p>也就是说，通过主要访问 NUMA-Local 内存，可以优化内存延迟（memory latency），并将可能减慢其他线程速度的 cross-socket 内存流量降到最低。</p><p>本文，主要贡献是以下三点：</p><ol><li><p>Morsel-driven query execution</p><p> 这是一个新的查新计算框架，与传统的 Volcano 模型的不同点主要是使用 work-stealing 方式在线程间动态分配任务。这可以防止由于负载不均衡（load imbalance）导致CPU资源未被使用，并且可以实现弹性，即可以随时在不同查询之间重新分配 CPU 资源。</p></li><li><p>一些并行算法。见后文的 HashJon、Aggregate、Sort 并行算法</p></li><li><p>将 NUMA-Awareness 融入到数据库的方法</p></li></ol><h2 id="2-MORSEL-DRIVEN-EXECUTION"><a href="#2-MORSEL-DRIVEN-EXECUTION" class="headerlink" title="2. MORSEL-DRIVEN EXECUTION"></a>2. MORSEL-DRIVEN EXECUTION</h2><p>使用 fig-1 中的 $\sigma(R) \Join \sigma(S) \Join \sigma(R)$ 来展示本文并行 pipeline 查询引擎的执行流程。假设 $R$ 是过滤之后最大的表，优化器将选择 $R$ 作为 HashJoin 的 probe 侧输入，而使用 $S$ 和 $T$ 来 build HashTable。</p><p>如fig-2左侧，根据 cost-based 优化器得到的查询计划由三条 pipelines 组成：</p><ol><li>扫描、过滤表 T 后，构建 T 的 HashTable $HT(T)$</li><li>扫描、过滤表 S 后，构建 S 的 HashTable $HT(S)$</li><li>扫描、过滤表 R 后，再 probe $HT(S)$ 和 $HT(T)$，将结果存在输出区域</li></ol><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-2.jpg?raw=true" alt="morsel-driven-2"></p><!-- HyPer 使用 JIT 技术生成高效的机器码（machine code）。每个 pipeline 都被编译到 code fragment，这实现了非常高的性能。此外，pipeline 中的 operators 也不会产生中间结果，这都已经由 VectorWise 实现了。 --><p>morsel-driven 框架中，代数计划的执行是由 <em>QEPobject</em> 来控制的，它会将可执行的 pipelines 传递给 <em>dispatcher</em>。因此，<em>QEPobject</em> 需要爱去检测数据的的前置依赖， 比如fig-2的例子中，只有在前两个 pipelines 执行完，3-rd pipeline 才能执行。在具体的每个 pipeline 中，<em>QEPobject</em> 会分配临时存储区（temporary storage areas），执行 pipeline 的并行线程会将结果写入到这个临时存储区。</p><p>在整个 pipeline 执行完后，临时存储区在逻辑上会被重新分割为同等大小的 morsels，这样后续的 pipeline 就可以从大小均等的新 morsels 上启动，而不是在 pipelines 之间保留 morsels 边界（容易导致数据倾斜）。任意时刻执行 pipelines 的线程数都受处理器硬件线程数量的限制，即上限是 <code>std::thread::hardware_concurrency()</code>。</p><p>为了写入 NUMUA-Local 并避免在输出中间结果时线程同步，<em>QEPobject</em> 为每个执行 pipeline 的 thread&#x2F;core 分配一个存储区域。</p><p>$HT(T)$ pipeline 的并行处理如 fig-3 所示。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-3.jpg?raw=true" alt="morsel-driven-3"></p><p>先重点关注第一阶段：每个线程先过滤输入 T，然后将过滤后得数据 tuples 存放在临时存储区。</p><p>在图中，有三个并行线程，每个线程一次操作一个 morsel。由于表 T 是以 morsel 为单位存储在多个 NUMA Node 的内存中，那么只要有可能（比如内存足够）那么 scheduler 就会将线程 T 所属的 NUMA Node 上的 morsel 分配给线程T。</p><p>比如在 fig-3 中颜色所表征的意思：在红色 Numa Node 上的 core 运行着红色线程，被赋予的任务就是处理红色 morsel。</p><p>只要线程 T 处理完了赋予的 morsel，要么被委托去执行其他任务（即work-steal 其他颜色的 morsels）或者获取同一个 Numa Node 上的 morsel（即相同颜色）来作为下一个任务。</p><p>fig-3 左侧标记了该 pipeline 被划分后的两个阶段。</p><ol><li><p>在第一阶段，过滤后的数据直接写入了 NUMA-Local 存储区域，也就是说对于每个 core 都有个单独存储区域来避免线程同步。</p><p>为了保持后续处理阶段的的 NUMA 局部性，在同一个socket上本地分配特定 core 的存储区域。即该core的存储区域总是在一个 socket 上分配。</p><blockquote><p>这里的 socket 是插槽。</p></blockquote></li><li><p>当表 T 的所有 morsels 在第一阶段都已经处理完，在第二阶段会被位于相同 core 上的线程再次扫描，并且插入一个指向 $HT(T)$ 的指针。</p></li></ol><p>之所以将构建 HashTable 分成两个阶段，是因为第一阶段完成后，数据的准确数据是已知的，就可以完美地确定全局 hashtable 的大小。这个大小确定的 gloabl hashtable 将会被系统中不同 NUMA Node 上的线程探测（probe）。因此，为避免竞争，这个 gloabl hashtable 就不应该位于特定的 NUMA 区域，而是应该分散在所有的 NUMA node上。由于许多线程都竞争着将输入插入 gloabl hashtable，那么必不可少地要实现一个 lock-free hashtable。</p><p>在 $HT(T)$ 和 $HT(S)$ 都构建完之后，probe pipeline 就可以被调度执行了。probe pipeline 的详细处理见 fig-4.</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-4.jpg?raw=true" alt="morsel-driven-4"></p><p>一个线程会向 dispatcher 请求任务，dispatcher 会在对应的 NUMA Node上 赋予该线程一个 morsel。也就是，如果线程位于红色 NUMA Node 上的 core，就会被分配表 R 在红色 NUMA Node 上的 morsel。Probe pipeline 的结果也会存储在 Numa 局部区域来保留后续处理阶段的局部性（这部分并没在图中画出）。</p><p>总得来说，morsel-driven 并行执行多个 pipelines 有点类似经典的 Volcano 模型实现，但是不同点在于 pipeline 是独立的，没有依赖的。也就是说，pipeline 共享数据结构并且 operators 能感知到并行执行的，因此最终必须执行线程同步（这一步需要通过有效的 lock-free 机制）。</p><p>未来可能的不同点，是执行 pipelines 的线程数也是完全弹性。也就是说，不仅在不同的 pipelines 之间的线程数不同，如 fig-2 所示，而且在查询执行期间，同一个 pipelien 内部也可能不同。</p><h2 id="3-DISPATCHER"><a href="#3-DISPATCHER" class="headerlink" title="3. DISPATCHER"></a>3. DISPATCHER</h2><p><em>dispatcher</em> 管控并将计算资源分配给并行的 pipelines。我们为每个机器提供的硬件线程（预）创建一个工作线程（work thread），并将每个工作线程永久地和他绑定在一起。</p><p>一个赋给 work thread 的 <code>task</code> 由两部分组成：pipeline job 和 pipeline job 的操作对象 morsel。由于 Task 的抢占发生在碎片边界，从而消除了可能代价高昂的中断机制。通过实验确定，morsel 大约在 100,000 个元组时，可以在即时弹性调整、负载平衡和低维护开销之间产生良好的权衡。</p><p>给指定 core 上运行的线程分配 Task 时，有三个主要目标:</p><ol><li>Locality: 保留 NUMA-Locality</li><li>Full elasticity: 关于查询的并行度，具有完全的弹性</li><li>Load balance: 要求所有参与 query pipeline 的核同时完成工作，防止先完成工作的 (fast)cores 等待其他的 (slow)cores。这个通过 worksteal 线程模型实现。</li></ol><p><em>dispatcher</em> 的架构如图 fig-5 所示，它维持了一个指向 pending pipeline jobs 的链表，这个链表中的 pipeline job 的前置依赖都已经处理完成。比如上面的 join 查询案例中，buidc pipeline job 会先插入到 pending jobs，只有在前两个 build pipelines 完成后，才会插入 proeb pipeline。正如前文所述，每个活跃的 queries 都是由 <em>QEPobject</em> 控制，它负责将可执行的 pipelines 传递给 <em>dispatcher</em>。 因此，<em>dispatcher</em> 只需要维护一个前置依赖都处理完成的 pipeline jobs 链表。</p><p>通常来说，<em>dispatcher</em> 的链表中包含的 pending pipeline jobs 是来自于并行执行的不同 queries，来适应 inter-query 的并行性。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-5.jpg?raw=true" alt="morsel-driven-5"></p><h3 id="3-1-Elasticity"><a href="#3-1-Elasticity" class="headerlink" title="3.1 Elasticity"></a>3.1 Elasticity</h3><p>通过 “morsel-at-a-time” 分发 pipeline jobs 来实现完全弹性并行性（fully elastic parallelism），允许根据服务质量模型智能调度这些查询间并行的 pipeline jobs。这样就能够在查询处理的任何阶段，优雅地降低长时间运行的查询Q1的并行度，以便优先考虑可能更重要的交互式查询Q2。一旦高优先级的 Q2 完成了，就会将时间片切给 Q2，这时候就可以给大多数甚至全部 cores 都分发 Q1 的 Tasks。会在 5.4 节展示弹性实验。</p><blockquote><p>当前的实现中，所有的查询都是相同优先级，因此线程是均匀分发给当前所有查询，基于优先级的调度机制不在本文介绍之列。</p></blockquote><p>对于每个 <strong>pipeline job</strong>，dispatcher 也为每个 pipeline job 维护了多个 moersls 链表，这是该 pipeline jobs 本次需要处理的数据源。对于每个 <em>core</em>，也存在一个单独的链表来实现局部性，比如对于 <code>core0</code> 上的任务请求一个 morsel，确保返回的 morsel 是来自于 <code>core0</code> 所在的 Numa Node 上。这两点可以从 fig-5 中的不同颜色看出。只要 <code>core0</code>  完成了分配的 morsel 及其 pipeline job 处理流程，就会请求一个新的任务，既可能来自于相同的 pipeline job，当然也可能不一定。这取决于正在执行的不同查询的不同 pipeline jobs 的优先级。比如，如果一个更高优先级的查询进入系统，那么就可能导致当前查询并行度降低。<code>&quot;Morsel-wise&quot;</code> 框架可以在不剧烈中断任务的情况下给不同的 pipeline jobs 重新分配不同的 cores。</p><h3 id="3-2-Implementation-Overview"><a href="#3-2-Implementation-Overview" class="headerlink" title="3.2 Implementation Overview"></a>3.2 Implementation Overview</h3><p>出于说明目的，fig-5 中我们直接给每个 core 都分配了一长串 morsels，但是实际上，我们为每个 core&#x2F;NUMA Node 都维护了一个存储区域并且按需将这个大的存储区域划分小的 morsels，即当 core 向 dispatcher 请求 Task 时。</p><p>此外，fig-5 中的 dispatcher 看起来像个独立运行的的线程，但是这会带来两个问题：</p><ol><li>dispatcher 本身需要一个 core 来运行，这可能会和执行 queries 的线程产生竞争；</li><li>因为 dispatcher 要分发任务，因此 dispatcher 本身可能会变成一个产生竞争的源泉（source of contention），成为性能热点，尤其当 morsels sized 被配置得特别小时</li></ol><p>因此，dispatcher 仅被实现为一个数据结构，dispatcher 的代码被 work thread 自己来执行，即由 work-thread 自己从 dispatcher 中取出 Task，那么dispatcher 就很自然地和这个 work thread 在一个 core 上执行。</p><blockquote><p>RocksDB 的 WriteThread 也是这个设计，WriteThread 本身就是 dispatcher 作用，并不会内部再启动一个线程来维护写入的 pending_writes。</p></blockquote><p>因此，基于 lock-free 实现 pipeline jobs queue 和 morsels queue，即便同时有多个查询工作线程同时向 dispatcher 请求 Task，也能降低竞争。类似地，QEPobject 被实现为被动状态机，即通过观察 pipeline 数据之间的依赖关系来推动查询进度，比如在 probe hashtable 之前必须先之前 buid hashtable。只要一个 pipeline job 执行完了，QEPobject 就会被调用，因为某些 Task 无法向 dispatcher 申请到新的 morsel，需要判断该完成的 pipelin job 是不是其他 pipeline jobs 的前置依赖。而此状态机，是在最初向 dispatcher 请求 Task 的 work thread 的不再使用的 core 上执行的。</p><p>除了能在任意时刻将一个 core 赋值给不同 queries 的能力（即 Elasticit），该 morsel-wise 处理流程也能保证 load balance 和 skew resistance。如果一个 core 完成了自己 NUMA-Local 上的所有 Morsels，则 dispatcher 会将 NUMA-Remote 上的 Morsels 分配给他，即 WorkSteal。在有些 NUMA 系统中，不是所有 NUMA Node 都是直连的，因此应该优先从较近的 NUMA-Node 上的 steal。尽管在正常的环境下，从 NUMA-Remote steal work 发生的概率很低，但是仍有必要去避免线程处于空闲状态。由于总是将结果写入 NUMA-Local 的存储区域，因此在 WorkSteal 场景下，coreA 从 coreB 窃取任务，执行完结果还是写入 coreA 的 NUMA-Local 区域。</p><p>目前主要讨论了 pipeline 的内部并行实现，但是我们的并行机制也支持多个 pipelines 并行。比如上面的三表 join 案例中，由于 HT(S) 和 HS(T) 之间没有依赖关系，可以同时并发执行。但是这种形式的并行带来的收益是有限的：因为独立没有依赖的关系的 pipelines 的数量是远小于 CPU cores 的数量，并且每个 pipeline 中的工作量通常也不相同。此外，pipelines 间并行可能会因为破坏 cache locality 导致性能降低。因此，当前的实现中会避免一个查询中同时并发执行多个 pipelines。在本文的JOIN案例中，会先执行 pipeline T，T 执行完了再将 pipeline S 添加到 dispatcher 的 pending pipeline jobs 中。</p><p>除了 Elasticity，本文的 morsel-driven 查询处理框架也实现了简单而又优雅地查询取消功能（query canceling）。无论是因为用户中止了查询，还是因为OOM等系统故障，被取消的查询会在 dispatcher 中被标记 marker。只要该 query 的一个 morsel 处理完，就会去检测 marker，因此很快该查询的所有 work threads 都会停止。这个方式比让操作系统去 kill 所有线程更加合理，可以去执行每个 work threads 的 CleanUp 操作（比如，释放内存等）。</p><h3 id="3-3-Morsel-Size"><a href="#3-3-Morsel-Size" class="headerlink" title="3.3 Morsel Size"></a>3.3 Morsel Size</h3><p>与 Vectorwise 和 IBM’s BLU 数据库不同，这些数据库以 vector 为单位在 operators 间传递，本文数据库不会因为 morsel 无法填充到 cache 中带来性能惩罚。Morsels 是用于将大型任务分解为小的、大小恒定的工作单元（work unit），这样便于 work steal。因此，Morsel 大小对于性能来说并不是很关键，它只需要足够大以分摊调度开销，同时提供良好的响应时间。在第五章会通过实验来衡量 morsel size 对查询 <code>select min(a) from R</code> 性能的影响。因为这个query非常简单，因此会尽可能突显出 work-stealing 数据结构的重要性。</p><p>fig-6 显示，在开销可以忽略不计的情况下，Morsel 大小应设置为尽可能小的值，在本例中，设置高于 1000 的值即可。尽管最优的设置依赖于硬件，但是很容易通过试验的方式获得。<br><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-6.jpg?raw=true" alt="morsel-driven-6"></p><p>在多核系统中，共享的数据结构即便是通过 LOCK-FREE 的方式实现，最终也很可能会成为性能瓶颈。然而，在我们的 WorkSteal 数据结构中，有许多方面因素可以阻止这个问题。</p><ol><li><p>在论文的实现中，完整的任务在最初就在所有的线程间完成分解，因此每个线程都临时拥有着一份 local range。由于我们将 cacheline 对齐到每个 range，因此在 cacheline 层不可能存在冲突。只有当 local range 处理完，尝试从另一个线程窃取 range 时才会发生冲突。</p></li><li><p>如果多个查询同时并发执行，对这个数据结构的压力则进一步减少。？？？</p></li><li><p>总是可以增加 morsel 的大小，来减少竞争</p><p> 这就导致非常小的几率访问 work-stealing 数据结构。即便在最坏的情况，morsel size 非常大会造成无法充分利用线程资源，但是如果当前系统有足够多的查询，则也不会影响系统的吞吐量。</p><p> 即一个查询虽然不会充分利用线程资源，多个查询一起就行了。</p></li></ol><h2 id="4-PARALLEL-OPERATOR-DETAILS"><a href="#4-PARALLEL-OPERATOR-DETAILS" class="headerlink" title="4. PARALLEL OPERATOR DETAILS"></a>4. PARALLEL OPERATOR DETAILS</h2><p>为了能够完整地并行每个 pipeline，pipeline 中的每个 operator 都需要满足：1）既能并行地读取 tuple；2）也需要能够并行地输出 tuple。在这一章，会讨论最重要的几个并行算子。</p><h2 id="4-1-HashJoin"><a href="#4-1-HashJoin" class="headerlink" title="4.1 HashJoin"></a>4.1 HashJoin</h2><p>正如第二节 fig-3 中所示，HashJoin 的 HashTable 的构建由两个阶段组成。</p><p>OuterJoin 是上述算法的小变动: 在每个 tuple 中，会额外分配一个 marker 来表征这个 tuple 是否已经有匹配了。来 probe 阶段如果有相匹配的就会设置该 marker，因此在设置该 marker 之前，先检查下该 marker 是否尚未被设置，有利于减少不必要的竞争。Semi&#x2F;Anti Joins 实现也是类似。</p><p>尽管 Balkesen 等[1]使用了大量的 single-operator benchmark 来表明一个高度优化的 radix-join 比 single-table join 达到个更高的性能。但是相比 radix-join，本文的 single-table join 具有以下特点：</p><ul><li>对于较大的输入表，single-table join 是可以完全 pipelined，因此可以使用更少的空间（因为可以就地处理 probe input）</li><li>是个 “good team player”</li><li>可以从倾斜的key分布中获益</li><li>对 tuple size 不敏感</li><li>没有硬件相关的参数</li></ul><p>由于上述实践中的优点，single-table join 在复杂查询中是要优于 radix-join。</p><blockquote><p>radix-join 可以参考我的另一篇博客: <a href>JOIN 分区算法：Radix-Cluster Algorithm</a>。但是我不太明白这里 single-table join 的含义，论文提及的几篇 HashJoin 论文都是 15721 中的论文，后续会再阅读一次，也可能会继续翻译，来加深理解。</p></blockquote><h3 id="4-2-Lock-Free-Tagged-Hash-Table"><a href="#4-2-Lock-Free-Tagged-Hash-Table" class="headerlink" title="4.2 Lock-Free Tagged Hash Table"></a>4.2 Lock-Free Tagged Hash Table</h3><p>本文 HashJoin 使用的 HashTable 有个优化：提前过滤（early-filter）。核心思想就是使用一个小的filter来标记 HashTable 的 bucket list（一个 bucket 实现为一个list），该 list 的所有元素都被 hash 来设置其中 1 bit。</p><p>如 fig-7 所示的插入过程，带插入的元素 <code>entry-&gt;hash</code> 基于某个算法预计算好，在 <code>insert</code> 函数中，需要基于 <code>entry-&gt;hash</code> 计算 entry 所属的 slot&#x2F;bucket。</p><p>并采用头插法，将 <code>entry-&gt;next = removeTag(old)</code>，其中 old 是 slot 当前的头节点，removeTag(old) 才是当前 head 节点真正地址。</p><p>完成上述操作后，就需要给当前首节点加上 Tag 信息:</p><ol><li>old &amp; TagMask 需要取出当前已有的 Tag 信息，其中 TagMask 即 <em>0xFF000000</em></li><li>计算新节点的 Tag 信息: tag(entry-&gt;hash)</li><li>将所有的的 Tag 信息存在 entry 的前 16bit 中</li></ol><p>结合起来，就是 fig-7 中第9行的计算公式。再通过 CAS 操作将 new 插入到 HashTable[slot] 中。</p><p><img src="https://github.com/szza/szza.github.io.images/blob/master/PaperReading/morsel-driven-7.jpg?raw=true" alt="morsel-driven-7"></p><p>这样就相当于首节点中使用 16 bit 就实现了一个微型 BloomFilter，可以在 O(1) 探测出来 unmatched 情况。相比较单独实现一个 BloomFilter 开销小很多，比如：</p><ol><li>没有带来多余的内存访问，而单独的 BloomFilter 会引入额外的内存访问，甚至多次 IO；</li><li>对于大表，一个单独的 BloomFilter 数据结构难以填充到 CPU Cache;</li><li>不依赖优化器决策，是否需要走 BloomFilter 索引；</li><li>除了 join，这对于聚合场景也是有效的</li></ol><p>实现中，我们对 HashTable 和 tuple 的存储区都使用 2MB 的 virtual memory page，这样的好处点：</p><p>降低了 TLB miss 的次数，page table 能保证填入到 L1 Cache，在 build 阶段产生的太多 kernel page 中断导致的拓展性问题也可以避免；</p><p>此外，我们使用 <code>mmap</code> 为 HashTable 分配内存。因为现代操作系统并不会立即分配内存，而是在第一次某个page有数据写入时才会触发。这样的好处是：1）不需要额外再添加一个阶段手动将 HashTable 内存初始化为 0；2）其次，HashTable 会自适应分布在 NUMA Node 上，因为这些 page 位于的 Numa Node，与首次写入该 page 的线程处在相同的 NUMA Node 上。</p><p>如果所有线程并发构建 HashTable，则会伪随机地分布在所有 Numa Node 上。如果只有来自单个 NUMA Node 上线程构建 HashTable，则该表就位于一个 Numa Node 上 – 这就是预期的情况。</p><blockquote><p>说实在的，我感觉这篇论文夸大了 Lock-Free 的作用，似乎在这篇论文中是神器，但是 Lock-Free 也是有适用场景的。</p></blockquote><h3 id="4-3-NUMA-Aware-Table-Partitioning"><a href="#4-3-NUMA-Aware-Table-Partitioning" class="headerlink" title="4.3 NUMA-Aware Table Partitioning"></a>4.3 NUMA-Aware Table Partitioning</h3><p>为了实现 NUMA-Local Table Scan，表必须在所有的 Memory Nodes 上。最直接的方式即 round-robin。更好的方式是使用一些重要属性列的 Hash 值来对表进行分区。这样的好处是，如果JOIN的两个表都以 join-key 进行分区，那么匹配的 tuples 就通常位于同一个 NUMA Node 上。尽管 work-stealing 和 load imbalance 还是可能导致 remote-Numa 内存访问，但是大多数参与 JOIN 的pair 还是来自于同一个 NUMA Node。</p><p>比如，经典的 TPCH benchmakr 中，<code>orders</code> 和 <code>lineitem</code> 两个表都是按照 <code>orderkey</code> 进行分区，那么这两个表在基于 <code>orderkey</code> 进行 join 时，就能有很好的优化。</p><p>比如 Doris&#x2F;StarRocks 针对这种情况，就提了个 Colocate Join 优化，他们在 TPCH 测试中这两个表的建表 SQL 如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> lineitem (</span><br><span class="line">    l_shipdate    <span class="type">DATE</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_orderkey    <span class="type">bigint</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_linenumber  <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">    l_partkey     <span class="type">int</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_suppkey     <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">    l_quantity    <span class="type">decimal</span>(<span class="number">15</span>, <span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_extendedprice  <span class="type">decimal</span>(<span class="number">15</span>, <span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_discount    <span class="type">decimal</span>(<span class="number">15</span>, <span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_tax         <span class="type">decimal</span>(<span class="number">15</span>, <span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_returnflag  <span class="type">VARCHAR</span>(<span class="number">1</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_linestatus  <span class="type">VARCHAR</span>(<span class="number">1</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_commitdate  <span class="type">DATE</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_receiptdate <span class="type">DATE</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_shipinstruct <span class="type">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_shipmode     <span class="type">VARCHAR</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    l_comment      <span class="type">VARCHAR</span>(<span class="number">44</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">)ENGINE<span class="operator">=</span>OLAP</span><br><span class="line">DUPLICATE KEY(`l_shipdate`, `l_orderkey`)</span><br><span class="line">COMMENT &quot;OLAP&quot;</span><br><span class="line">DISTRIBUTED <span class="keyword">BY</span> HASH(`l_orderkey`) BUCKETS <span class="number">96</span></span><br><span class="line">PROPERTIES (</span><br><span class="line">    &quot;replication_num&quot; <span class="operator">=</span> &quot;1&quot;,</span><br><span class="line">    &quot;colocate_with&quot; <span class="operator">=</span> &quot;lineitem_orders&quot;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orders  (</span><br><span class="line">    o_orderkey       <span class="type">bigint</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_orderdate      <span class="type">DATE</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_custkey        <span class="type">int</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_orderstatus    <span class="type">VARCHAR</span>(<span class="number">1</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_totalprice     <span class="type">decimal</span>(<span class="number">15</span>, <span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_orderpriority  <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_clerk          <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_shippriority   <span class="type">int</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    o_comment        <span class="type">VARCHAR</span>(<span class="number">79</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">)ENGINE<span class="operator">=</span>OLAP</span><br><span class="line">DUPLICATE KEY(`o_orderkey`, `o_orderdate`)</span><br><span class="line">COMMENT &quot;OLAP&quot;</span><br><span class="line">DISTRIBUTED <span class="keyword">BY</span> HASH(`o_orderkey`) BUCKETS <span class="number">96</span></span><br><span class="line">PROPERTIES (</span><br><span class="line">    &quot;replication_num&quot; <span class="operator">=</span> &quot;1&quot;,</span><br><span class="line">    &quot;colocate_with&quot; <span class="operator">=</span> &quot;lineitem_orders&quot;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ABSTRACT&quot;&gt;&lt;a href=&quot;#ABSTRACT&quot; class=&quot;headerlink&quot; title=&quot;ABSTRACT&quot;&gt;&lt;/a&gt;ABSTRACT&lt;/h2&gt;&lt;p&gt;随着现代计算机架构的演进，与并行查询执行引擎中两个问题产生了矛盾：&lt;/p&gt;
&lt;ol&gt;
&lt;li</summary>
      
    
    
    
    
    <category term="Papers" scheme="https://szza.github.io/tags/Papers/"/>
    
  </entry>
  
</feed>
